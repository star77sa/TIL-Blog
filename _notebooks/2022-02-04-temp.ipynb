{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ideal-dragon",
   "metadata": {},
   "source": [
    "# temp\n",
    "> temp\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [python]\n",
    "- image: images/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db2688-eeeb-487d-8aae-2311b5054ad6",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd265b95-2284-49a9-9941-3275f18d1b08",
   "metadata": {},
   "source": [
    "## IoU (Intersection over union)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb14f3d7-e8db-45d4-9f3e-72889350733a",
   "metadata": {},
   "source": [
    "- 2개 영역 사이의 중첩되는 정도를 측정.\n",
    "- 이는 Object detector가 실제 Ground truth와 예측결과(Prediction)가 얼마나 정확히 겹치는지를 계산하여 예측이 얼마나 잘 되는지를 측정."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0bdef8-f4b4-4466-8ee7-0b9f869019da",
   "metadata": {},
   "source": [
    "- Ground-truth를 데이터의 label값으로 생각하면 이해가 쉬움."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a4b94-089d-4f96-9f85-ba642cc8054d",
   "metadata": {},
   "source": [
    "## Average Precision (AP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c153f5e5-9af3-4a68-9d93-5a3b69c97d0f",
   "metadata": {},
   "source": [
    "- CNN의 모델 성능 평가 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc015c3a-8a9e-4b9d-8d87-b88ab27a2aad",
   "metadata": {},
   "source": [
    "- Precision  = TP/(TP+FP) 정확도. 검출 결과 중 옳게 검출한 비율\n",
    "- Recall = TP/(TP+FN) 재현율. 실제 옳게 검출된 결과물 중에서 옳다고 예측한 것의 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30969766-ba56-4a92-a164-4f338e52c84f",
   "metadata": {},
   "source": [
    "TP : 예측한 것중 정답인 것\n",
    "\n",
    "TP + FP : 예측한 것\n",
    "\n",
    "TP + FN : 실제 정답인 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857d9a3e-8449-401d-b6b0-93cc726fc723",
   "metadata": {},
   "source": [
    "- 일반적으로 Precision과 Recall은 서로 반비례 관계를 가진다.\n",
    "    \n",
    "    이 둘의 성능변화를 관측하기 위해 precision-recall 그래프를 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620c346f-eb58-4074-8929-9ff4de192541",
   "metadata": {},
   "source": [
    "- precision-recall 그래프는 어떤 알고리즘의 성능을 전반적으로 파악하기에는 좋으나 서로 다른 두 알고리즘의 성능을 정량적으로 비교하기에는 불편."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b3ac3-bf9c-4515-89c0-04b29e1096f6",
   "metadata": {},
   "source": [
    "- AP는 인식 알고리즘의 성능을 하나의 값으로 표현한 것으로 precision-recall 그래프에서 그래프 선 아래 쪽의 면적으로 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a6f1a-2bc0-48f4-bdfa-67ba67d847b8",
   "metadata": {},
   "source": [
    "- AP가 높으면 높을수록 그 알고리즘의 성능이 전체적으로 우수하다는 의미."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2674558a-3ac3-4d52-8706-81355d419918",
   "metadata": {},
   "source": [
    "**mAP** : 물체 클래스가 여러 개인 경우 각 클래스당 AP를 구한 다음에 그것을 모두 합한 다음 물체 클래스의 개수로 나눠줌으로 알고리즘의 성능을 평가."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b4c50-99c6-4dfe-9af0-5bbdce270fa3",
   "metadata": {},
   "source": [
    "### PASCAL VOC Challenge에서의 AP(Average Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fef781-9ee7-4af5-998a-1ef3ed4ca710",
   "metadata": {},
   "source": [
    "- PASCAL VOC는 object detection에서 널리 사용되는 데이터 셋\n",
    "\n",
    "- PACAL VOC Challenge의 경우, 모델의 예측과 ground truth의 IoU가 0.5보다 크면(IoU > 0.5) 모델의 예측이 올바르게 되었다고 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a26aa9-b88a-429c-ad66-84d9fad3c3b5",
   "metadata": {},
   "source": [
    "### MS COCO mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8168faa1-be51-445a-ad01-9134c39fe706",
   "metadata": {},
   "source": [
    "- SOTA(State of art) object detector 모델들은 주로 MS COCO에 대한 mAP 결과만을 제공하는 경향이 있음\n",
    "\n",
    "- MS COCO는 PASCAL VOC의 단일 IoU값 계산과는 다르게(IoU > 0.5) 다중 IoU에 대한 평균값을 계산\n",
    "\n",
    "- AP@[.5:.95]는 0.05의 단계 크기로 0.5부터 0.95까지의 IoU에 대한 평균 AP에 해당함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b771583-c258-41d5-9530-f47296833a02",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
