{
  
    
        "post0": {
            "title": "CNN",
            "content": ". import os import random import numpy as np import pandas as pd import matplotlib.pyplot as plt import time import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torch.utils.data import DataLoader, TensorDataset import torchvision.models as models from torchvision.utils import make_grid from torchsummary import summary device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;) # GPU 할당 # Colab torch, gpu 확인 print(&quot;Torch version:{}&quot;.format(torch.__version__)) print(&quot;cuda version: {}&quot;.format(torch.version.cuda)) print(&quot;cudnn version:{}&quot;.format(torch.backends.cudnn.version())) . Torch version:1.10.0+cpu cuda version: None cudnn version:None . ROOT = &quot;/content/drive/MyDrive&quot; DIR = &quot;product_classification&quot; # data 폴더와 ipynb 파일이 위치한 폴더명을 적으세요. PATH = os.path.join(ROOT, DIR) os.chdir(PATH) # 현재 프로젝트 PATH로 이동 # train, validation은 npy형태로 제공됩니다. X_train = np.load(&quot;Dataset/Train/X_train.npy&quot;) Y_train = np.load(&quot;Dataset/Train/Y_train.npy&quot;) X_val = np.load(&quot;Dataset/Valid/X_val.npy&quot;) Y_val = np.load(&quot;Dataset/Valid/Y_val.npy&quot;) X_test = np.load(&quot;Dataset/Test/X_test.npy&quot;) # 최종 제출할 prediction 결과에 사용할 데이터입니다. . BATCH_SIZE = 64 . X_train = torch.from_numpy(X_train).float() Y_train = torch.from_numpy(Y_train).long() X_val = torch.from_numpy(X_val).float() Y_val = torch.from_numpy(Y_val).long() X_test = torch.from_numpy(X_test).float() # Print data info print(f&quot;X_train shape: {X_train.shape}&quot;) print(f&quot;X_val shape: {X_val.shape}&quot;) train = TensorDataset(X_train, Y_train) val = TensorDataset(X_val, Y_val) # Train_Loader : mini batch 분할 train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True) val_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False) . Accuracy 계산 커스텀 함수 . def accuracy(outputs, labels): _, preds = torch.max(outputs, dim=1) return torch.tensor(torch.sum(preds == labels).item() / len(preds)) . class CNN(nn.Module): def __init__(self, num_classes): super(CNN, self).__init__() self.conv1 = nn.Sequential( nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), stride=(2, 2)), nn.BatchNorm2d(16), nn.ReLU() ) self.conv2 = nn.Sequential( nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=(2, 2)), nn.BatchNorm2d(32), nn.ReLU() ) self.conv3 = nn.Sequential( nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), stride=(2, 2)), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2, 2) ) self.lin = nn.Sequential( nn.Linear(7200, num_classes), ) def forward(self, x): out = self.conv1(x) out = self.conv2(out) out = self.conv3(out) out = out.flatten(start_dim=1) out = self.lin(out) return out # pytorch에서 제공하는 CNN module 사용하기 class Select_model(nn.Module): def __init__(self, model_name, num_classes=4, pretrained=False): super(Select_model, self).__init__() # Use a pretrained model if model_name == &quot;vgg&quot;: self.network = models.vgg16(pretrained=pretrained) # Replace last layer num_ftrs = self.network.classifier[6].in_features self.network.fc = nn.Linear(num_ftrs, num_classes) elif model_name == &quot;resnet&quot;: self.network = models.resnet18(pretrained=pretrained) # Replace last layer num_ftrs = self.network.fc.in_features self.network.fc = nn.Linear(num_ftrs, num_classes) elif model_name == &quot;googlenet&quot;: self.network = models.googlenet(pretrained=pretrained, aux_logits=False) # Replace last layer num_ftrs = self.network.fc.in_features self.network.fc = nn.Linear(num_ftrs, num_classes) def forward(self, xb): return self.network(xb) . model = CNN(num_classes=4) print(model) . CNN( (conv1): Sequential( (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2)) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (conv2): Sequential( (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2)) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (conv3): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2)) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (lin): Sequential( (0): Linear(in_features=7200, out_features=4, bias=True) ) ) . model = Select_model(&#39;resnet&#39;) print(model) . Select_model( (network): ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer2): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer3): Sequential( (0): BasicBlock( (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer4): Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (fc): Linear(in_features=512, out_features=4, bias=True) ) ) . Training . &quot;&quot;&quot; 2. hyperparameter를 바꿔봅시다! - 처음에 제공되는 값을 임의로 설정한 값입니다. 바꾸시고 돌리시면 됩니다! &quot;&quot;&quot; # learning rate : 모델의 학습 속도를 조절합니다. lr = 1e-10 # weight_decay : L2 regularization으로 모델의 overfitting을 방지합니다 weight_decay = 1e-10 # epoch : 전체 dataset을 몇번 학습 시킬지 조절해보세요 epochs = 2 # model 선택 ## net = CNN(num_classes=4).to(device) net = Select_model(&#39;resnet&#39;).to(device) # optimizer 선택 (gradient descent : model update 방법): SGD, Adam, RMSProp # pytorch에서 제공하는 optimizer : https://pytorch.org/docs/stable/optim.html opt = &quot;Adam&quot; if opt == &quot;SGD&quot;: optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay) elif opt == &quot;Adam&quot;: optimizer = optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=weight_decay) elif opt == &quot;RMSProb&quot;: optimizer = optim.RMSProb(net.parameters(), lr=lr, alpha = 0.9, momentum=0.9, weight_decay=weight_decay) # learning rate decay : 학습 도중 learning rate를 조절하는 technique # pytorch에서 제공하는 learning rate decay : https://pytorch.org/docs/stable/optim.html lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995) # epoch마다 x0.995 만큼 lr 감소 . # training train_loss_list = [] val_loss_list = [] train_correct_list = [] val_correct_list = [] result = {} # loss 함수 criterion = nn.CrossEntropyLoss() for epoch in range(1, epochs + 1): net.train() train_loss = 0 valLoss = 0 train_correct = 0 val_correct = 0 start_time = time.time() # training for batch_idx, (input, label) in enumerate(train_loader): input, label = input.to(device), label.to(device) optimizer.zero_grad() out = net(input) loss = criterion(out, label) train_loss += loss.item() loss.backward() optimizer.step() train_acc = accuracy(out, label) train_correct += train_acc # validation with torch.no_grad(): for batch_idx, (val_input, val_label) in enumerate(val_loader): net.eval() val_input, val_label = val_input.to(device), val_label.to(device) val_out = net(val_input) val_loss = criterion(val_out, val_label) val_acc = accuracy(val_out, val_label) valLoss += val_loss.item() val_correct += val_acc print(&quot;[=] EPOCH [{:}/{:}] TIME [{:.3}s]&quot;.format(epoch, epochs, time.time()-start_time) + &quot; | TRAIN_LOSS [{:.3}] TRAIN_ACC [{:.3}] VAL_LOSS [{:.3}] VAL_ACC [{:.3}] &quot;.format( train_loss / len(train_loader), train_correct / len(train_loader), valLoss / len(val_loader), val_correct/len(val_loader))) train_loss_list.append(train_loss / len(train_loader)) train_correct_list.append(train_correct.item() / len(train_loader)) val_loss_list.append(valLoss/len(val_loader)) val_correct_list.append(val_correct.item()/len(val_loader)) lr_scheduler.step() # learning rate schedular step # 결과 저장 result[&#39;train_loss&#39;] = train_loss_list result[&#39;train_acc&#39;] = train_correct_list result[&#39;val_loss&#39;] = val_loss_list result[&#39;val_acc&#39;] = val_correct_list total_result = [] total_result.append(result) . &#54617;&#49845;&#44208;&#44284; &#49884;&#44033;&#54868; . def plot_acc(total_result): train_acc = [x[&#39;train_acc&#39;] for x in total_result] val_acc = [x[&#39;val_acc&#39;] for x in total_result] plt.plot(*train_acc) plt.plot(*val_acc) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;accuracy&#39;) plt.legend([&#39;Training&#39;, &#39;Validation&#39;]) plt.title(&#39;Accuracy per epochs&#39;); plt.show() def plot_loss(total_result): train_loss = [x[&#39;train_loss&#39;] for x in total_result] val_loss = [x[&#39;val_loss&#39;] for x in total_result] plt.plot(*train_loss) plt.plot(*val_loss) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;loss&#39;) plt.legend([&#39;Training&#39;, &#39;Validation&#39;]) plt.title(&#39;Loss per epochs&#39;); plt.show() plot_acc(total_result) plot_loss(total_result) . # test 결과 확인 def predict_test(img, model): x = img.to(device) model.eval() y = model(x) _, pred = torch.max(y, dim=1) return pred # test data shape print(X_test.shape) # test data 예측결과 list로 저장 preds = [] for i in range(len(X_test)): pred = predict_test(X_test[i:i+1], net) preds.append(pred.item()) print(len(preds)) # 개수가 1120개가 맞는지 확인하세요! # DataFrame # id 추가 id = [i for i in range(len(X_test))] test_preds = {&#39;id&#39;: id, &#39;label&#39;: preds} . &#44208;&#44284;&#51228;&#52636; . # Make output directory : test data 결과 파일 저장 경로 SAVE_PATH = os.path.join(PATH, &quot;output&quot;) if not os.path.exists(SAVE_PATH): os.mkdir(SAVE_PATH) else: pass # Make submission file team = &quot;Big_Star&quot; # 이 밑은 수정하지 마세요. sub = pd.DataFrame(test_preds) sub.to_csv(os.path.join(SAVE_PATH, f&quot;./{team}_submission.csv&quot;), index=False) . . Case 2 . from torchvision import models . model_arch=&#39;vgg11&#39; num_classes=5 model = models.__dict__[model_arch](pretrained = True) in_features = model.classifier[6].in_features model.classifier[6] = nn.Linear(in_features, num_classes) model = model.to(device) .",
            "url": "https://star77sa.github.io/TIL-Blog/python/2021/11/12/pytotch-cnn.html",
            "relUrl": "/python/2021/11/12/pytotch-cnn.html",
            "date": " • Nov 12, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "분석 전 기본세팅",
            "content": ". &#54028;&#51068; . &#54028;&#51068; &#48520;&#47084;&#50724;&#44592; . data = pd.read_csv(&quot;G:/내 드라이브/bb/cc/data.csv&#39;) . &#54028;&#51068; &#45236;&#48372;&#45236;&#44592; . test.to_csv(&#39;test.csv&#39;, index = False) . 해당 소스코드가 있는 곳에 파일이 내보내진다. | . test.to_csv(&#39;G:/내 드라이브/Github/TIL-Blog/test.csv&#39;, index = False) . 해당 경로에 파일이 내보내진다. | . . &#44592;&#48376; &#46972;&#51060;&#48652;&#47084;&#47532; . import pandas as pd # pandas import numpy as np # numpy . import matplotlib.pyplot as plt # matplotlib import matplotlib import seaborn as sns # seaborn . . &#51204;&#52376;&#47532; . train / validation set split . train = pd.read_csv(&#39;https://bit.ly/fc-ml-titanic&#39;) . feature = [ &#39;Pclass&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;Fare&#39; ] . label = [ &#39;Survived&#39; ] . from sklearn.model_selection import train_test_split . test_size: validation set에 할당할 비율 (20% -&gt; 0.2) | shuffle: 셔플 옵션 (기본 True) | random_state: 랜덤 시드값 | . x_train, x_valid, y_train, y_valid = train_test_split(train[feature], train[label], test_size=0.2, shuffle=True, random_state=30) . &#44208;&#52769;&#52824; &#52376;&#47532; . from sklearn.impute import SimpleImputer . 1. &#49688;&#52824;&#54805; . 칼럼 1개 처리하는 경우 . train[&#39;Age&#39;].fillna(train[&#39;Age&#39;].mean()) . 칼럼 여러개 처리하는 경우 . imputer = SimpleImputer(strategy=&#39;median&#39;) ## 한번에 여러개 처리. median, mean ... result = imputer.fit_transform(train[[&#39;Age&#39;, &#39;Pclass&#39;]]) train[[&#39;Age&#39;, &#39;Pclass&#39;]] = result . 2. &#48276;&#51452;&#54805; . train = pd.read_csv(&#39;https://bit.ly/fc-ml-titanic&#39;) . 컬럼 1개 처리하는 경우 . train[&#39;Embarked&#39;].fillna(&#39;S&#39;) . 칼럼 여러개 처리하는 경우 . imputer = SimpleImputer(strategy=&#39;most_frequent&#39;) result = imputer.fit_transform(train[[&#39;Embarked&#39;, &#39;Cabin&#39;]]) train[[&#39;Embarked&#39;, &#39;Cabin&#39;]] = result . Label Encoding : &#47928;&#51088;&#47484; &#49688;&#52824;&#47196; &#48320;&#54872; . from sklearn.preprocessing import LabelEncoder . train[&#39;Embarked_num&#39;] = LabelEncoder().fit_transform(train[&#39;Embarked&#39;]) . train[&#39;Embarked_num&#39;].value_counts() . 2 646 0 168 1 77 Name: Embarked_num, dtype: int64 . &#50896; &#54635; &#51064;&#53076;&#46377; . pd.get_dummies(train[&#39;Embarked_num&#39;], prefix = &#39;Embarked&#39;) . Embarked_0 Embarked_1 Embarked_2 . 0 0 | 0 | 1 | . 1 1 | 0 | 0 | . 2 0 | 0 | 1 | . 3 0 | 0 | 1 | . 4 0 | 0 | 1 | . ... ... | ... | ... | . 886 0 | 0 | 1 | . 887 0 | 0 | 1 | . 888 0 | 0 | 1 | . 889 1 | 0 | 0 | . 890 0 | 1 | 0 | . 891 rows × 3 columns . &#51221;&#44508;&#54868; Normalize (&#52572;&#49567;&#44050; 0 &#52572;&#45824;&#44050; 1) . movie = {&#39;naver&#39;: [2, 4, 6, 8, 10], &#39;netflix&#39;: [1, 2, 3, 4, 5]} movie = pd.DataFrame(data=movie) . from sklearn.preprocessing import MinMaxScaler . min_max_movie = MinMaxScaler().fit_transform(movie) . pd.DataFrame(min_max_movie, columns=[&#39;naver&#39;, &#39;netflix&#39;]) . naver netflix . 0 0.00 | 0.00 | . 1 0.25 | 0.25 | . 2 0.50 | 0.50 | . 3 0.75 | 0.75 | . 4 1.00 | 1.00 | . &#54364;&#51456;&#54868; Standard Scaling (&#54217;&#44512; 0 &#54364;&#51456;&#54200;&#52264; 1) . from sklearn.preprocessing import StandardScaler . x = np.arange(10) # outlier 추가 x[9] = 1000 x = x.reshape(-1, 1) . scaled = StandardScaler().fit_transform(x) . round(scaled.mean(), 2), scaled.std() . (0.0, 1.0) . . &#44160;&#51613;, &#53916;&#45789; . Cross Validation . from sklearn.datasets import load_boston data = load_boston() df = pd.DataFrame(data[&#39;data&#39;], columns=data[&#39;feature_names&#39;]) df[&#39;MEDV&#39;] = data[&#39;target&#39;] from lightgbm import LGBMRegressor, LGBMClassifier from sklearn.metrics import mean_absolute_error, mean_squared_error from sklearn.model_selection import train_test_split x_train, x_test, y_train, y_test = train_test_split(df.drop(&#39;MEDV&#39;, 1), df[&#39;MEDV&#39;], random_state=42) . from sklearn.model_selection import KFold . n_splits = 5 kfold = KFold(n_splits=n_splits, shuffle = True, random_state=42) X = np.array(df.drop(&#39;MEDV&#39;, 1)) Y = np.array(df[&#39;MEDV&#39;]) lgbm_fold = LGBMRegressor(random_state=42) . i = 1 total_error = 0 for train_index, test_index in kfold.split(X): x_train_fold, x_test_fold = X[train_index], X[test_index] y_train_fold, y_test_fold = Y[train_index], Y[test_index] lgbm_pred_fold = lgbm_fold.fit(x_train_fold, y_train_fold).predict(x_test_fold) error = mean_squared_error(lgbm_pred_fold, y_test_fold) print(&#39;Fold = {}, prediction score = {:.2f}&#39;.format(i, error)) total_error += error i+=1 print(&#39;&#39;*10) print(&#39;Average Error: %s&#39; % (total_error / n_splits)) . Fold = 1, prediction score = 8.34 Fold = 2, prediction score = 10.40 Fold = 3, prediction score = 17.58 Fold = 4, prediction score = 6.94 Fold = 5, prediction score = 12.16 Average Error: 11.083201392666322 . Hyperparameter &#53916;&#45789; . 1. RandomizedSearchCV . params = { &#39;n_estimators&#39;: [200, 500, 1000, 2000], &#39;learning_rate&#39;: [0.1, 0.05, 0.01], &#39;max_depth&#39;: [6, 7, 8], &#39;colsample_bytree&#39;: [0.8, 0.9, 1.0], &#39;subsample&#39;: [0.8, 0.9, 1.0], } . 주요 Hyperparameter (LGBM) . random_state: 랜덤 시드 고정 값. 고정해두고 튜닝할 것! | n_jobs: CPU 사용 갯수 | learning_rate: 학습율. 너무 큰 학습율은 성능을 떨어뜨리고, 너무 작은 학습율은 학습이 느리다. 적절한 값을 찾아야함. n_estimators와 같이 튜닝. default=0.1 | n_estimators: 부스팅 스테이지 수. (랜덤포레스트 트리의 갯수 설정과 비슷한 개념). default=100 | max_depth: 트리의 깊이. 과대적합 방지용. default=3. | colsample_bytree: 샘플 사용 비율 (max_features와 비슷한 개념). 과대적합 방지용. default=1.0 | . from sklearn.model_selection import RandomizedSearchCV . n_iter 값을 조절하여, 총 몇 회의 시도를 진행할 것인지 정의합니다. . (회수가 늘어나면, 더 좋은 parameter를 찾을 확률은 올라가지만, 그만큼 시간이 오래걸립니다.) . clf = RandomizedSearchCV(LGBMRegressor(), params, random_state=42, cv=3, n_iter=25, scoring=&#39;neg_mean_squared_error&#39;) clf.fit(x_train, y_train) . RandomizedSearchCV(cv=3, estimator=LGBMRegressor(), n_iter=25, param_distributions={&#39;colsample_bytree&#39;: [0.8, 0.9, 1.0], &#39;learning_rate&#39;: [0.1, 0.05, 0.01], &#39;max_depth&#39;: [6, 7, 8], &#39;n_estimators&#39;: [200, 500, 1000, 2000], &#39;subsample&#39;: [0.8, 0.9, 1.0]}, random_state=42, scoring=&#39;neg_mean_squared_error&#39;) . clf.best_score_ . -13.707228623244996 . clf.best_params_ . {&#39;subsample&#39;: 0.9, &#39;n_estimators&#39;: 2000, &#39;max_depth&#39;: 6, &#39;learning_rate&#39;: 0.01, &#39;colsample_bytree&#39;: 0.8} . lgbm_best = LGBMRegressor(n_estimators=2000, subsample=0.8, max_depth=7, learning_rate=0.01, colsample_bytree=0.8) lgbm_best_pred = lgbm_best.fit(x_train, y_train).predict(x_test) . 2. GridSearchCV . 모든 매개 변수 값에 대하여 완전 탐색을 시도합니다. | 따라서, 최적화할 parameter가 많다면, 시간이 매우 오래걸립니다. | . params = { &#39;n_estimators&#39;: [500, 1000], &#39;learning_rate&#39;: [0.1, 0.05, 0.01], &#39;max_depth&#39;: [7, 8], &#39;colsample_bytree&#39;: [0.8, 0.9], &#39;subsample&#39;: [0.8, 0.9,], } . from sklearn.model_selection import GridSearchCV . grid_search = GridSearchCV(LGBMRegressor(), params, cv=3, n_jobs=-1, scoring=&#39;neg_mean_squared_error&#39;) . grid_search.fit(x_train, y_train) . GridSearchCV(cv=3, estimator=LGBMRegressor(), n_jobs=-1, param_grid={&#39;colsample_bytree&#39;: [0.8, 0.9], &#39;learning_rate&#39;: [0.1, 0.05, 0.01], &#39;max_depth&#39;: [7, 8], &#39;n_estimators&#39;: [500, 1000], &#39;subsample&#39;: [0.8, 0.9]}, scoring=&#39;neg_mean_squared_error&#39;) . grid_search.best_score_ . -13.598939419010335 . grid_search.best_params_ . {&#39;colsample_bytree&#39;: 0.8, &#39;learning_rate&#39;: 0.05, &#39;max_depth&#39;: 7, &#39;n_estimators&#39;: 500, &#39;subsample&#39;: 0.8} . lgbm_best = LGBMRegressor(n_estimators=500, subsample=0.8, max_depth=7, learning_rate=0.05, colsample_bytree=0.8) lgbm_best_pred = lgbm_best.fit(x_train, y_train).predict(x_test) . . Model . CatBoost + &#50696;&#49884; . from catboost import CatBoostRegressor # 캣부스트 회귀 from catboost import CatBoostClassifier # 캣부스트 분류 . model = CatBoostRegressor() model.fit(X_train, y_train, silent=True) pred = model.predict(X_test) rmse = (np.sqrt(np.mean(mean_squared_error(y_test, pred)))) rmse . Random Forest . from sklearn.ensemble import RandomForestRegressor from sklearn.ensemble import RandomForestClassifier . rf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123,max_depth=6) rf.fit(X_train, y_train) . XG BOOST, LightGBM . from xgboost import XGBRegressor from xgboost import XGBClassifier from lightgbm import LGBMRegressor from lightgbm import LGBMClassifier . . &#54217;&#44032;&#51216;&#49688; . RMSE . from sklearn.metrics import mean_squared_error rmse = (np.sqrt(np.mean(mean_squared_error(y_test, pred)))) rmse . Accuracy . from sklearn.metrics import accuracy_score accuracy = accuracy_score(y_test, predicted) .",
            "url": "https://star77sa.github.io/TIL-Blog/python/2021/11/02/Setting.html",
            "relUrl": "/python/2021/11/02/Setting.html",
            "date": " • Nov 2, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Pandas",
            "content": "import pandas as pd import numpy as np df = pd.read_csv(&#39;http://bit.ly/ds-korean-idol&#39;) . &#51221;&#47148; . Index &#48324;&#47196; &#51221;&#47148; . &#50724;&#47492;&#52264;&#49692; &#51221;&#47148; df.sort_index() . df.sort_index() . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . &#45236;&#47548;&#52264;&#49692; &#51221;&#47148; df.sort_index(ascending=False) . df.sort_index(ascending=False) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . . Column&#48324;&#47196; &#51221;&#47148; . &#50724;&#47492;&#52264;&#49692; &#51221;&#47148; df.sort_values(by=&#39;&#53412;&#39;) . df.sort_values(by=&#39;키&#39;) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . . &#45236;&#47548;&#52264;&#49692; &#51221;&#47148; df.sort_values(by=&#39;&#53412;&#39;, ascending=False) . df.sort_values(by=&#39;키&#39;, ascending=False) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . . &#48373;&#49688;&#51221;&#47148; df.sort_values(by=[&#39;&#53412;&#39;,&#39;&#48652;&#47004;&#46300;&#54217;&#54032;&#51648;&#49688;&#39;], ascending=False) . df.sort_values(by=[&#39;키&#39;,&#39;브랜드평판지수&#39;], ascending=False) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . . . &#49440;&#53469; . Column &#49440;&#53469; df[&#39;&#51060;&#47492;&#39;] . df[&#39;이름&#39;] . 0 지민 1 지드래곤 2 강다니엘 3 뷔 4 화사 5 정국 6 민현 7 소연 8 진 9 하성운 10 태연 11 차은우 12 백호 13 JR 14 슈가 Name: 이름, dtype: object . . &#48276;&#50948;&#49440;&#53469; . &#45800;&#49692; index&#50640; &#45824;&#54620; &#48276;&#50948; &#49440;&#53469; df[:3] . df[:3] . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . . loc . df.loc[:, &#39;이름&#39;] . 0 지민 1 지드래곤 2 강다니엘 3 뷔 4 화사 5 정국 6 민현 7 소연 8 진 9 하성운 10 태연 11 차은우 12 백호 13 JR 14 슈가 Name: 이름, dtype: object . . df.loc[3:8, [&#39;이름&#39;, &#39;생년월일&#39;]] . 이름 생년월일 . 3 뷔 | 1995-12-30 | . 4 화사 | 1995-07-23 | . 5 정국 | 1997-09-01 | . 6 민현 | 1995-08-09 | . 7 소연 | 1998-08-26 | . 8 진 | 1992-12-04 | . . iloc (position&#51004;&#47196; &#49353;&#51064;) . df.iloc[:, [0,2]] . 이름 소속사 . 0 지민 | 빅히트 | . 1 지드래곤 | YG | . 2 강다니엘 | 커넥트 | . 3 뷔 | 빅히트 | . 4 화사 | RBW | . 5 정국 | 빅히트 | . 6 민현 | 플레디스 | . 7 소연 | 큐브 | . 8 진 | 빅히트 | . 9 하성운 | 스타크루이엔티 | . 10 태연 | SM | . 11 차은우 | 판타지오 | . 12 백호 | 플레디스 | . 13 JR | 플레디스 | . 14 슈가 | 빅히트 | . . df.iloc[1:5, 1:4] . 그룹 소속사 성별 . 1 빅뱅 | YG | 남자 | . 2 NaN | 커넥트 | 남자 | . 3 방탄소년단 | 빅히트 | 남자 | . 4 마마무 | RBW | 여자 | . . Boolean Indexing - &#51312;&#44148;&#51012; &#54876;&#50857;&#54620; &#49353;&#51064; . df[&#39;키&#39;] &gt; 180 . 0 False 1 False 2 False 3 False 4 False 5 False 6 True 7 False 8 False 9 False 10 False 11 True 12 False 13 False 14 False Name: 키, dtype: bool . . Boolean Index로 받은 Index를 활용해서 True인 값만 색인해 낼 수 있다. . df[df[&#39;&#53412;&#39;] &lt; 170] . df[df[&#39;키&#39;] &lt; 170] . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . . df[df[&#39;&#53412;&#39;] &gt; 180][&#39;&#51060;&#47492;&#39;] . df[df[&#39;키&#39;] &gt; 180][&#39;이름&#39;] . 6 민현 11 차은우 Name: 이름, dtype: object . . df.loc[df[&#39;&#53412;&#39;]&gt;180, &#39;&#51060;&#47492;&#39;] * &#51060; &#48169;&#48277;&#51012; &#45908; &#52628;&#52380; . df.loc[df[&#39;키&#39;]&gt;180, &#39;이름&#39;] . 6 민현 11 차은우 Name: 이름, dtype: object . . df.loc[ df[&#39;키&#39;] &gt; 180, [&#39;이름&#39;, &#39;키&#39;]] . 이름 키 . 6 민현 | 182.3 | . 11 차은우 | 183.0 | . . isin&#51012; &#54876;&#50857;&#54620; &#49353;&#51064; . isin을 활용한 색인은 내가 조건을 걸고자 하는 값이 내가 정의한 list에 있을 때만 색인하려는 경우에 사용 . my_condition = [&#39;플레디스&#39;, &#39;SM&#39;] . df[&#39;소속사&#39;].isin(my_condition) . 0 False 1 False 2 False 3 False 4 False 5 False 6 True 7 False 8 False 9 False 10 True 11 False 12 True 13 True 14 False Name: 소속사, dtype: bool . . df.loc[ df[&#39;소속사&#39;].isin(my_condition) ] . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . . df.loc[df[&#39;소속사&#39;].isin(my_condition), &#39;소속사&#39;] . 6 플레디스 10 SM 12 플레디스 13 플레디스 Name: 소속사, dtype: object . . . &#44208;&#52769;&#44050; &#49353;&#51064; . info() 로 NaN 값, 즉 빠진 데이터가 어디에 있는지 쉽게 요약정보로 확인할 수 있습니다. | . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype -- -- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB . . Boolean 인덱싱으로 True가 return 되는 값이 NaN이라는 것을 알 수 있습니다. | . df[&#39;그룹&#39;].isnull() . 0 False 1 False 2 True 3 False 4 False 5 False 6 False 7 False 8 False 9 False 10 False 11 False 12 False 13 False 14 False Name: 그룹, dtype: bool . . NaN이 아닌 값에 대하여 Boolean 인덱싱 | . df[&#39;그룹&#39;].notnull() . 0 True 1 True 2 False 3 True 4 True 5 True 6 True 7 True 8 True 9 True 10 True 11 True 12 True 13 True 14 True Name: 그룹, dtype: bool . . NaN 값만 색출해내기 | . df[&#39;그룹&#39;][df[&#39;그룹&#39;].isnull()] . 2 NaN Name: 그룹, dtype: object . . df.loc[df[&#39;그룹&#39;].notnull(), [&#39;키&#39;,&#39;혈액형&#39;]] . 키 혈액형 . 0 173.6 | A | . 1 177.0 | A | . 3 178.0 | AB | . 4 162.1 | A | . 5 178.0 | A | . 6 182.3 | O | . 7 NaN | B | . 8 179.2 | O | . 9 167.1 | A | . 10 NaN | A | . 11 183.0 | B | . 12 175.0 | AB | . 13 176.0 | O | . 14 174.0 | O | . . . &#48373;&#49324; . - 다음과 같이 복사하면 안된다. . new_df = df . new_df.head() . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . . hex(id(new_df)) . &#39;0x2698eeab640&#39; . hex(id(df)) . &#39;0x2698eeab640&#39; . 참조하고 있는 메모리 주소가 같음. . 원본 데이터를 유지 시키고, 새로운 변수에 복사할 때는 copy()를 사용 . df.copy() . copy_df = df.copy() hex(id(copy_df)) . &#39;0x2698efbd4c0&#39; . . &#54665;, &#50676; &#52628;&#44032; . row&#51032; &#52628;&#44032; . dictionary 형태의 데이터를 만들어 준다음 append() 함수를 사용하여 데이터를 추가할 수 있다. 반드시, ignore_index=True 옵션을 같이 추가해 주셔야 에러가 안난다. . | 또한, append() 한 뒤 다시 df에 대입해줘야 변경한 값이 유지 됩니다. . | . df = df.append({&#39;이름&#39;: &#39;테디&#39;, &#39;그룹&#39;: &#39;테디그룹&#39;, &#39;소속사&#39;: &#39;끝내주는소속사&#39;, &#39;성별&#39;: &#39;남자&#39;, &#39;생년월일&#39;: &#39;1970-01-01&#39;, &#39;키&#39;: 195.0, &#39;혈액형&#39;: &#39;O&#39;, &#39;브랜드평판지수&#39;: 12345678}, ignore_index=True) . column&#51032; &#52628;&#44032; . df[&#39;국적&#39;] = &#39;대한민국&#39; . 만약, 값을 변경하고 싶다면, loc 함수를 활용해서 변경 . df.loc[ df[&#39;이름&#39;]==&#39;지드래곤&#39;, &#39;국적&#39;] = &#39;korea&#39; . df.head() . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 국적 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | 대한민국 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | korea | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | 대한민국 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | 대한민국 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | 대한민국 | . . df = pd.read_csv(&#39;https://bit.ly/ds-korean-idol&#39;) . . &#53685;&#44228;&#44050; . &#53685;&#44228;&#52824; &#50836;&#50557; df.describe() . df.describe() . 키 브랜드평판지수 . count 13.000000 | 1.500000e+01 | . mean 175.792308 | 5.655856e+06 | . std 5.820576 | 2.539068e+06 | . min 162.100000 | 2.925442e+06 | . 25% 174.000000 | 3.712344e+06 | . 50% 177.000000 | 4.668615e+06 | . 75% 179.200000 | 7.862214e+06 | . max 183.000000 | 1.052326e+07 | . . 산술이 가능한 수치형 데이터만 요약이 된걸 볼 수 있다. . &#52572;&#49548; min, &#52572;&#45824; max . df[&#39;키&#39;].min() . 162.1 . df[&#39;키&#39;].max() . 183.0 . &#54633;&#44228; sum . df[&#39;키&#39;].sum() . 2285.3 . &#54217;&#44512; mean . df[&#39;키&#39;].mean() . 175.7923076923077 . &#51473;&#50521;&#44050; median . df[&#39;키&#39;].median() . 177.0 . &#52572;&#48712;&#44050; mode . df[&#39;키&#39;].mode() . 0 178.0 dtype: float64 . &#48516;&#49328; var, &#54364;&#51456;&#54200;&#52264; std . 분산은 편차 제곱의 평균 . 표준편차는 분산의 루트 . df[&#39;키&#39;].var() . 33.879102564102595 . df[&#39;키&#39;].std() . 5.820575793175672 . &#44079;&#49688; count . df[&#39;키&#39;].count() . 13 . . &#54588;&#48279;&#53580;&#51060;&#48660; (pivot_table) . 피벗테이블은 엑셀의 피벗테이블과 동일 | 데이터 열 중에서 두 개의 열을 각각 행 인덱스, 열 인덱스로 사용하여 데이터를 조회하여 펼쳐놓은 것을 의미 | 왼쪽에 나타나는 인덱스를 행 인덱스, 상단에 나타나는 인덱스를 열 인덱스라고 부른다 | . pd.pivot_table(df, index=&#39;소속사&#39;, columns = &#39;혈액형&#39;, values=&#39;키&#39;) . 혈액형 A AB B O . 소속사 . RBW 162.1 | NaN | NaN | NaN | . YG 177.0 | NaN | NaN | NaN | . 빅히트 175.8 | 178.0 | NaN | 176.60 | . 스타크루이엔티 167.1 | NaN | NaN | NaN | . 커넥트 180.0 | NaN | NaN | NaN | . 판타지오 NaN | NaN | 183.0 | NaN | . 플레디스 NaN | 175.0 | NaN | 179.15 | . . aggfunc에는 추가 계산 옵션 (np.sum, np.mean) - 기본값은 평균 . pd.pivot_table(df, index = &#39;그룹&#39;, columns = &#39;혈액형&#39;, values = &#39;브랜드평판지수&#39;, aggfunc = np.sum)# 코드를 입력해 주세요 . 혈액형 A AB B O . 그룹 . 뉴이스트 NaN | 3301654.0 | NaN | 8263929.0 | . 마마무 7650928.0 | NaN | NaN | NaN | . 방탄소년단 15731595.0 | 8073501.0 | NaN | 7495750.0 | . 빅뱅 9916947.0 | NaN | NaN | NaN | . 소녀시대 3918661.0 | NaN | NaN | NaN | . 아스트로 NaN | NaN | 3506027.0 | NaN | . 아이들 NaN | NaN | 4668615.0 | NaN | . 핫샷 4036489.0 | NaN | NaN | NaN | . . . &#44536;&#47353;&#48324; &#53685;&#44228;(groupby) . groupby는 데이터를 그룹으로 묶어 분석할 때 활용한다. | . groupby와 함께 . count() - 갯수 | sum() - 합계 | mean() - 평균 | var() - 분산 | std() - 표준편차 | min()/max() - 최소값, 최대값 | . df.groupby(&#39;소속사&#39;).count() . 이름 그룹 성별 생년월일 키 혈액형 브랜드평판지수 . 소속사 . RBW 1 | 1 | 1 | 1 | 1 | 1 | 1 | . SM 1 | 1 | 1 | 1 | 0 | 1 | 1 | . YG 1 | 1 | 1 | 1 | 1 | 1 | 1 | . 빅히트 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 스타크루이엔티 1 | 1 | 1 | 1 | 1 | 1 | 1 | . 커넥트 1 | 0 | 1 | 1 | 1 | 1 | 1 | . 큐브 1 | 1 | 1 | 1 | 0 | 1 | 1 | . 판타지오 1 | 1 | 1 | 1 | 1 | 1 | 1 | . 플레디스 3 | 3 | 3 | 3 | 3 | 3 | 3 | . . 산술 통계는 자동으로 산술통계가 가능한 열만 출력됩니다. . df.groupby(&#39;그룹&#39;).mean() . 키 브랜드평판지수 . 그룹 . 뉴이스트 177.766667 | 3.855194e+06 | . 마마무 162.100000 | 7.650928e+06 | . 방탄소년단 176.560000 | 6.260169e+06 | . 빅뱅 177.000000 | 9.916947e+06 | . 소녀시대 NaN | 3.918661e+06 | . 아스트로 183.000000 | 3.506027e+06 | . 아이들 NaN | 4.668615e+06 | . 핫샷 167.100000 | 4.036489e+06 | . . 특정 열만 출력하고 싶다면? . df.groupby(&#39;그룹&#39;)[&#39;키&#39;].mean() . 그룹 뉴이스트 177.766667 마마무 162.100000 방탄소년단 176.560000 빅뱅 177.000000 소녀시대 NaN 아스트로 183.000000 아이들 NaN 핫샷 167.100000 Name: 키, dtype: float64 . . Multi-Index(&#48373;&#54633; &#51064;&#45937;&#49828;) . Multi-Index &#51201;&#50857; . 행 인덱스를 복합적으로 구성하고 싶은 경우는 인덱스를 리스트로 만들어 줍니다. . df.groupby([&#39;혈액형&#39;,&#39;성별&#39;]).mean() . 키 브랜드평판지수 . 혈액형 성별 . A 남자 175.140 | 7591755.20 | . 여자 162.100 | 5784794.50 | . AB 남자 176.500 | 5687577.50 | . B 남자 183.000 | 3506027.00 | . 여자 NaN | 4668615.00 | . O 남자 177.875 | 3939919.75 | . . Multi-Index &#45936;&#51060;&#53552; &#54532;&#47112;&#51076;&#51012; &#54588;&#48279; &#53580;&#51060;&#48660;&#47196; &#48320;&#54872; . Multi-Index로 된 데이터프레임을 피벗테이블 형태로 다시 변환해 줄 수 있습니다. . df2 = df.groupby([&#39;혈액형&#39;,&#39;성별&#39;]).mean() . df2.unstack(&#39;혈액형&#39;) . 키 브랜드평판지수 . 혈액형 A AB B O A AB B O . 성별 . 남자 175.14 | 176.5 | 183.0 | 177.875 | 7591755.2 | 5687577.5 | 3506027.0 | 3939919.75 | . 여자 162.10 | NaN | NaN | NaN | 5784794.5 | NaN | 4668615.0 | NaN | . . df2.unstack(&#39;성별&#39;) . 키 브랜드평판지수 . 성별 남자 여자 남자 여자 . 혈액형 . A 175.140 | 162.1 | 7591755.20 | 5784794.5 | . AB 176.500 | NaN | 5687577.50 | NaN | . B 183.000 | NaN | 3506027.00 | 4668615.0 | . O 177.875 | NaN | 3939919.75 | NaN | . . &#51064;&#45937;&#49828; &#52488;&#44592;&#54868; (reset_index) . reset_index() 는 Multi-Index로 구성된 데이터 프레임의 인덱스를 초기화해 줍니다 . df2 . 키 브랜드평판지수 . 혈액형 성별 . A 남자 175.140 | 7591755.20 | . 여자 162.100 | 5784794.50 | . AB 남자 176.500 | 5687577.50 | . B 남자 183.000 | 3506027.00 | . 여자 NaN | 4668615.00 | . O 남자 177.875 | 3939919.75 | . . df2 = df2.reset_index() . df2 . 혈액형 성별 키 브랜드평판지수 . 0 A | 남자 | 175.140 | 7591755.20 | . 1 A | 여자 | 162.100 | 5784794.50 | . 2 AB | 남자 | 176.500 | 5687577.50 | . 3 B | 남자 | 183.000 | 3506027.00 | . 4 B | 여자 | NaN | 4668615.00 | . 5 O | 남자 | 177.875 | 3939919.75 | . . . &#51204;&#52376;&#47532; . &#44208;&#52769;&#44050; &#52292;&#50864;&#44592; fillna() . fillna(): na 값에 대하여 fill해주는 함수입니다. . df[&#39;키&#39;] . 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 NaN 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 . . df[&#39;키&#39;].fillna(-1) . 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 -1.0 8 179.2 9 167.1 10 -1.0 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 . . 키의 NaN 값을 채워준다음 유지시키려면 inplace=True 옵션을 주거나, fillna로 채워 준 값을 다시 대입해 주어야 합니다. . df2[&#39;키&#39;] = df2[&#39;키&#39;].fillna(-1) . &#48712; &#44050;(NaN)&#51060; &#51080;&#45716; &#54665;&#51012; &#51228;&#44144; . df . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . df.dropna() . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . axis (&#50676;/ &#54665;&#51012; &#46300;&#46989;) . axis=0은 행을 드랍합니다. . df.dropna(axis=0) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . axis=1은 열을 드랍합니다. . df.dropna(axis=1) . 이름 소속사 성별 생년월일 혈액형 브랜드평판지수 . 0 지민 | 빅히트 | 남자 | 1995-10-13 | A | 10523260 | . 1 지드래곤 | YG | 남자 | 1988-08-18 | A | 9916947 | . 2 강다니엘 | 커넥트 | 남자 | 1996-12-10 | A | 8273745 | . 3 뷔 | 빅히트 | 남자 | 1995-12-30 | AB | 8073501 | . 4 화사 | RBW | 여자 | 1995-07-23 | A | 7650928 | . 5 정국 | 빅히트 | 남자 | 1997-09-01 | A | 5208335 | . 6 민현 | 플레디스 | 남자 | 1995-08-09 | O | 4989792 | . 7 소연 | 큐브 | 여자 | 1998-08-26 | B | 4668615 | . 8 진 | 빅히트 | 남자 | 1992-12-04 | O | 4570308 | . 9 하성운 | 스타크루이엔티 | 남자 | 1994-03-22 | A | 4036489 | . 10 태연 | SM | 여자 | 1989-03-09 | A | 3918661 | . 11 차은우 | 판타지오 | 남자 | 1997-03-30 | B | 3506027 | . 12 백호 | 플레디스 | 남자 | 1995-07-21 | AB | 3301654 | . 13 JR | 플레디스 | 남자 | 1995-06-08 | O | 3274137 | . 14 슈가 | 빅히트 | 남자 | 1993-03-09 | O | 2925442 | . . how&#50741;&#49496; - &#39;any&#39;: &#54620;&#44060;&#46972;&#46020; &#51080;&#45716; &#44221;&#50864; &#46300;&#46989;, &#39;all&#39;&#51008; &#47784;&#46160; NaN&#51064; &#44221;&#50864; &#46300;&#46989; . df.dropna() . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . df.dropna(axis=0, how=&#39;any&#39;) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . df.dropna(axis=0, how=&#39;all&#39;) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . &#51473;&#48373;&#46108; &#44050; &#51228;&#44144; (drop_duplicates) . column&#51032; &#51473;&#48373;&#44050; &#51228;&#44144; . df[&#39;키&#39;] . 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 NaN 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 . . df[&#39;키&#39;].drop_duplicates() . 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 6 182.3 7 NaN 8 179.2 9 167.1 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 . . keep 옵션으로 유지하고 싶은 데이터를 선택할 수 있습니다. keep: &#39;first&#39; / &#39;last&#39; . df[&#39;키&#39;].drop_duplicates(keep=&#39;last&#39;) . 0 173.6 1 177.0 2 180.0 4 162.1 5 178.0 6 182.3 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 . . &#54665; &#51204;&#52404; &#51228;&#44144; . df.drop_duplicates(&#39;그룹&#39;) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . . df.drop_duplicates(keep=&#39;last&#39;) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . Drop - column/row &#51228;&#44144;&#54616;&#44592; . df.head() . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . . column &#51228;&#44144;&#54616;&#44592; . drop()을 활용하여 column을 제거할 수 있습니다. column을 제거할 때는 axis=1 옵션을 줍니다. . df.drop(&#39;그룹&#39;, axis=1) . 이름 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . df.drop([&#39;그룹&#39;,&#39;소속사&#39;], axis=1) . 이름 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . row &#51228;&#44144;&#54616;&#44592; . drop()을 활용하여 row를 제거할 수 있습니다. row를 제거할 때는 제거하고자하는 index와 axis=0 옵션을 줍니다. . df.drop(3, axis=0) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . 복수의 row를 제거하고자 할 때는 list로 지정합니다. . df.drop([3,5], axis=0) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . DataFrame &#54633;&#52824;&#44592; (concat) . df2 = pd.read_csv(&#39;https://bit.ly/ds-korean-idol-2&#39;) . row &#44592;&#51456; &#54633;&#52824;&#44592; . df_copy = df.copy() . row에 합칠 때는 pd.concat에 합칠 데이터프레임을 list로 합쳐줍니다. row 기준으로 합칠 때는 sort=False 옵션을 주어 순서가 유지되도록 합니다. . df_concat =pd.concat([df, df_copy], sort=False) df_concat . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . 꼬인 인덱스는 reset_index()를 이용하여 인덱스를 초기화 해줍니다. . 하지만, index라는 column이 추가 됩니다. 그럴때는 drop=True 옵션으로 새로 index column이 생성되지 않도록 만들어 줍니다 . df_concat.reset_index(drop=True) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . 15 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 16 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 17 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 18 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 19 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 20 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 21 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 22 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 23 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 24 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 25 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 26 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 27 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 28 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 29 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . column &#44592;&#51456;&#51004;&#47196; &#54633;&#52824;&#44592; . column을 기준으로 합치고자 할 때는 axis=1 옵션을 부여합니다 . pd.concat([df, df2], axis=1) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 이름 연봉 가족수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | 지민 | 3000 | 3 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | 지드래곤 | 3500 | 3 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | 강다니엘 | 3200 | 4 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | 뷔 | 3050 | 4 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | 화사 | 4300 | 3 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | 정국 | 2900 | 5 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | 민현 | 3400 | 6 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | 소연 | 4500 | 5 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | 진 | 4200 | 4 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | 하성운 | 4300 | 4 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | 태연 | 3700 | 3 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | 차은우 | 3850 | 5 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | 백호 | 3900 | 4 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | JR | 4100 | 3 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | 슈가 | 4150 | 3 | . . 행의 갯수가 맞지 않는 상태에서 column concat . df3 = df2.drop([3,5]) pd.concat([df, df3], axis=1) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 이름 연봉 가족수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | 지민 | 3000.0 | 3.0 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | 지드래곤 | 3500.0 | 3.0 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | 강다니엘 | 3200.0 | 4.0 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | NaN | NaN | NaN | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | 화사 | 4300.0 | 3.0 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | NaN | NaN | NaN | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | 민현 | 3400.0 | 6.0 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | 소연 | 4500.0 | 5.0 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | 진 | 4200.0 | 4.0 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | 하성운 | 4300.0 | 4.0 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | 태연 | 3700.0 | 3.0 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | 차은우 | 3850.0 | 5.0 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | 백호 | 3900.0 | 4.0 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | JR | 4100.0 | 3.0 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | 슈가 | 4150.0 | 3.0 | . . DataFrame &#48337;&#54633;&#54616;&#44592; (merge) . 이전에 봤던 concat과 merge는 단순 합치는 목적과 특정 기준(index)으로 합치느냐에 따라 용도가 다릅니다. . concat: row나 column 기준으로 단순하게 이어 붙히기 | merge: 특정 고유한 키(unique id) 값을 기준으로 병합하기 | . pd.merge(left, right, on=&#39;기준column&#39;, how=&#39;left&#39;) . left와 right는 병합할 두 DataFrame을 대입합니다. | on 에는 병합의 기준이 되는 column을 넣어 줍니다. | how 에는 &#39;left&#39;, &#39;right&#39;, &#39;inner&#39;, &#39;outer&#39; 라는 4가지의 병합 방식중 한가지를 택합니다. | . left, right &#48169;&#49885; . df2 에서 5개의 데이터를 고의적으로 drop한 데이터 . df_right = df2.drop([1, 3, 5, 7, 9], axis=0) df_right = df_right.reset_index(drop=True) df_right . 이름 연봉 가족수 . 0 지민 | 3000 | 3 | . 1 강다니엘 | 3200 | 4 | . 2 화사 | 4300 | 3 | . 3 민현 | 3400 | 6 | . 4 진 | 4200 | 4 | . 5 태연 | 3700 | 3 | . 6 차은우 | 3850 | 5 | . 7 백호 | 3900 | 4 | . 8 JR | 4100 | 3 | . 9 슈가 | 4150 | 3 | . . df . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . 병합할 2개의 DataFrame의 행의 갯수가 맞지 않습니다. 실 사례에서도 충분히 있을 법한 일입니다. . &#39;left&#39; 옵션을 부여하면, left DataFrame에 키 값이 존재하면 해당 데이터를 유지하고, 병합한 right DataFrame의 값의 NaN이 대입 됩니다. . pd.merge(df, df_right, on=&#39;이름&#39;, how = &#39;left&#39;) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 연봉 가족수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | 3000.0 | 3.0 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | NaN | NaN | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | 3200.0 | 4.0 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | NaN | NaN | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | 4300.0 | 3.0 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | NaN | NaN | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | 3400.0 | 6.0 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | NaN | NaN | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | 4200.0 | 4.0 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | NaN | NaN | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | 3700.0 | 3.0 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | 3850.0 | 5.0 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | 3900.0 | 4.0 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | 4100.0 | 3.0 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | 4150.0 | 3.0 | . . 반대로 &#39;right&#39; 옵션을 부여하면 right DataFrame을 기준으로 병합하게 됩니다. . pd.merge(df, df_right, on = &#39;이름&#39;, how=&#39;right&#39;) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 연봉 가족수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | 3000 | 3 | . 1 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | 3200 | 4 | . 2 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | 4300 | 3 | . 3 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | 3400 | 6 | . 4 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | 4200 | 4 | . 5 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | 3700 | 3 | . 6 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | 3850 | 5 | . 7 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | 3900 | 4 | . 8 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | 4100 | 3 | . 9 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | 4150 | 3 | . . inner, outer &#48169;&#49885; . inner 방식은 두 DataFrame에 모두 키 값이 존재하는 경우만 병합합니다. | outer 방식은 하나의 DataFrame에 키 값이 존재하는 경우 모두 병합합니다. | outer 방식에서는 없는 값은 NaN으로 대입됩니다. | . df . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . df_right . 이름 연봉 가족수 . 0 지민 | 3000 | 3 | . 1 강다니엘 | 3200 | 4 | . 2 화사 | 4300 | 3 | . 3 민현 | 3400 | 6 | . 4 진 | 4200 | 4 | . 5 태연 | 3700 | 3 | . 6 차은우 | 3850 | 5 | . 7 백호 | 3900 | 4 | . 8 JR | 4100 | 3 | . 9 슈가 | 4150 | 3 | . . pd.merge(df, df_right, on=&#39;이름&#39;, how=&#39;inner&#39;) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 연봉 가족수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | 3000 | 3 | . 1 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | 3200 | 4 | . 2 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | 4300 | 3 | . 3 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | 3400 | 6 | . 4 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | 4200 | 4 | . 5 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | 3700 | 3 | . 6 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | 3850 | 5 | . 7 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | 3900 | 4 | . 8 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | 4100 | 3 | . 9 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | 4150 | 3 | . . pd.merge(df, df_right, on=&#39;이름&#39;, how=&#39;outer&#39;) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 연봉 가족수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | 3000.0 | 3.0 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | NaN | NaN | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | 3200.0 | 4.0 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | NaN | NaN | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | 4300.0 | 3.0 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | NaN | NaN | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | 3400.0 | 6.0 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | NaN | NaN | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | 4200.0 | 4.0 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | NaN | NaN | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | 3700.0 | 3.0 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | 3850.0 | 5.0 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | 3900.0 | 4.0 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | 4100.0 | 3.0 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | 4150.0 | 3.0 | . . column&#47749;&#51008; &#45796;&#47476;&#51648;&#47564;, &#46041;&#51068;&#54620; &#49457;&#51656;&#51032; &#45936;&#51060;&#53552; &#51064; &#44221;&#50864; . df . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | . . df_right.columns = [&#39;성함&#39;, &#39;연봉&#39;, &#39;가족수&#39;] df_right . 성함 연봉 가족수 . 0 지민 | 3000 | 3 | . 1 강다니엘 | 3200 | 4 | . 2 화사 | 4300 | 3 | . 3 민현 | 3400 | 6 | . 4 진 | 4200 | 4 | . 5 태연 | 3700 | 3 | . 6 차은우 | 3850 | 5 | . 7 백호 | 3900 | 4 | . 8 JR | 4100 | 3 | . 9 슈가 | 4150 | 3 | . . df와 df_right를 병합하려고 했더니, df에서는 &#39;이름&#39;, df_right에서는 &#39;성함&#39;으로 표기되어 기준이 되는 column을 지정할 수 없습니다. . 이럴 때는 left_on, right_on 옵션을 사용합니다. . pd.merge(df, df_right, left_on=&#39;이름&#39;, right_on=&#39;성함&#39;, how=&#39;outer&#39;) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 성함 연봉 가족수 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | 지민 | 3000.0 | 3.0 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | NaN | NaN | NaN | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | 강다니엘 | 3200.0 | 4.0 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | NaN | NaN | NaN | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | 화사 | 4300.0 | 3.0 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | NaN | NaN | NaN | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | 민현 | 3400.0 | 6.0 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | NaN | NaN | NaN | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | 진 | 4200.0 | 4.0 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | NaN | NaN | NaN | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | 태연 | 3700.0 | 3.0 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | 차은우 | 3850.0 | 5.0 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | 백호 | 3900.0 | 4.0 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | JR | 4100.0 | 3.0 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | 슈가 | 4150.0 | 3.0 | . . Series&#51032; Type &#48320;&#54872;&#54616;&#44592; . type &#54869;&#51064;&#54616;&#44592; . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype -- -- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB . . 이전에 배운 info를 찍어보면, 우측에 type이 같이 찍히는 것을 확인하실 수 있습니다. . object: 일반 문자열 타입 | float: 실수 | int: 정수 | category: 카테고리 | datetime: 시간 | . type &#48320;&#54872;&#54616;&#44592; . type 변환을 위해서는 astype이라는 메소드를 사용합니다. | . df[&#39;키&#39;].dtypes . dtype(&#39;float64&#39;) . . df[&#39;키&#39;].astype(int) . ValueError Traceback (most recent call last) &lt;ipython-input-98-143bd2af1410&gt; in &lt;module&gt; 1 #collapse-output -&gt; 2 df[&#39;키&#39;].astype(int) ~ anaconda3 lib site-packages pandas core generic.py in astype(self, dtype, copy, errors) 5875 else: 5876 # else, only a single dtype is given -&gt; 5877 new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors) 5878 return self._constructor(new_data).__finalize__(self, method=&#34;astype&#34;) 5879 ~ anaconda3 lib site-packages pandas core internals managers.py in astype(self, dtype, copy, errors) 629 self, dtype, copy: bool = False, errors: str = &#34;raise&#34; 630 ) -&gt; &#34;BlockManager&#34;: --&gt; 631 return self.apply(&#34;astype&#34;, dtype=dtype, copy=copy, errors=errors) 632 633 def convert( ~ anaconda3 lib site-packages pandas core internals managers.py in apply(self, f, align_keys, ignore_failures, **kwargs) 425 applied = b.apply(f, **kwargs) 426 else: --&gt; 427 applied = getattr(b, f)(**kwargs) 428 except (TypeError, NotImplementedError): 429 if not ignore_failures: ~ anaconda3 lib site-packages pandas core internals blocks.py in astype(self, dtype, copy, errors) 671 vals1d = values.ravel() 672 try: --&gt; 673 values = astype_nansafe(vals1d, dtype, copy=True) 674 except (ValueError, TypeError): 675 # e.g. astype_nansafe can fail on object-dtype of strings ~ anaconda3 lib site-packages pandas core dtypes cast.py in astype_nansafe(arr, dtype, copy, skipna) 1066 1067 if not np.isfinite(arr).all(): -&gt; 1068 raise ValueError(&#34;Cannot convert non-finite values (NA or inf) to integer&#34;) 1069 1070 elif is_object_dtype(arr): ValueError: Cannot convert non-finite values (NA or inf) to integer . . 에러가 발생했습니다..NaN 값이 들어있기 때문에 변경이 안됩니다. . 이럴 때는 fillna로 빈값을 임의로 채워 주겠습니다. . df[&#39;키&#39;] = df[&#39;키&#39;].fillna(-1) . df[&#39;키&#39;].astype(int) . 0 173 1 177 2 180 3 178 4 162 5 178 6 182 7 -1 8 179 9 167 10 -1 11 183 12 175 13 176 14 174 Name: 키, dtype: int32 . . int형으로 타입을 바꾸니 float -&gt; int로 변경 된 것을 볼 수 있습니다. . &#45216;&#51676; &#48320;&#54872;&#54616;&#44592; (datetime &#53440;&#51077;) . 날짜를 변환하기 위해서는 판다스 메소드인 to_datetime이라는 메소드를 사용합니다. | . 현재 날짜 column은 dtype:이 object, 즉 문자열 타입으로 되어 있습니다. . df[&#39;생년월일&#39;] . 0 1995-10-13 1 1988-08-18 2 1996-12-10 3 1995-12-30 4 1995-07-23 5 1997-09-01 6 1995-08-09 7 1998-08-26 8 1992-12-04 9 1994-03-22 10 1989-03-09 11 1997-03-30 12 1995-07-21 13 1995-06-08 14 1993-03-09 Name: 생년월일, dtype: object . . df[&#39;생년월일&#39;] = pd.to_datetime(df[&#39;생년월일&#39;]) . datetime 타입으로 우리가 변환해준 중요한 이유가 있습니다! . 매우 손쉽게, 월, 일, 요일 등등의 날짜 정보를 세부적으로 추출해낼 수 있습니다. | datetime의 약어인 &#39;dt&#39;에는 다양한 정보들을 제공해 줍니다. | . df[&#39;생년월일&#39;].dt.year . 0 1995 1 1988 2 1996 3 1995 4 1995 5 1997 6 1995 7 1998 8 1992 9 1994 10 1989 11 1997 12 1995 13 1995 14 1993 Name: 생년월일, dtype: int64 . . df[&#39;생년월일&#39;].dt.month . 0 10 1 8 2 12 3 12 4 7 5 9 6 8 7 8 8 12 9 3 10 3 11 3 12 7 13 6 14 3 Name: 생년월일, dtype: int64 . . df[&#39;생년월일&#39;].dt.day . 0 13 1 18 2 10 3 30 4 23 5 1 6 9 7 26 8 4 9 22 10 9 11 30 12 21 13 8 14 9 Name: 생년월일, dtype: int64 . . df[&#39;생년월일&#39;].dt.hour . 0 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 10 0 11 0 12 0 13 0 14 0 Name: 생년월일, dtype: int64 . . df[&#39;생년월일&#39;].dt.minute . 0 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 10 0 11 0 12 0 13 0 14 0 Name: 생년월일, dtype: int64 . . df[&#39;생년월일&#39;].dt.second . 0 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 10 0 11 0 12 0 13 0 14 0 Name: 생년월일, dtype: int64 . . df[&#39;생년월일&#39;].dt.dayofweek . 0 4 1 3 2 1 3 5 4 6 5 0 6 2 7 2 8 4 9 1 10 3 11 6 12 4 13 3 14 1 Name: 생년월일, dtype: int64 . . 월요일: 0 화요일: 1, 수요일: 2, 목요일: 3, 금요일: 4, 토요일: 5, 일요일: 6 . df[&#39;생년월일&#39;].dt.weekofyear . &lt;ipython-input-110-2428c4b5ec27&gt;:2: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead. df[&#39;생년월일&#39;].dt.weekofyear . 0 41 1 33 2 50 3 52 4 29 5 36 6 32 7 35 8 49 9 12 10 10 11 13 12 29 13 23 14 10 Name: 생년월일, dtype: int64 . . apply . apply는 Series나 DataFrame에 좀 더 구체적인 로직을 적용하고 싶은 경우 활용합니다. . apply를 적용하기 위해서는 함수가 먼저 정의되어야합니다. | apply는 정의한 로직 함수를 인자로 넘겨줍니다. | . df.loc[df[&#39;성별&#39;] == &#39;남자&#39;, &#39;성별&#39;] = 1 df.loc[df[&#39;성별&#39;] == &#39;여자&#39;, &#39;성별&#39;] = 0 . df . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 . 0 지민 | 방탄소년단 | 빅히트 | 1 | 1995-10-13 | 173.6 | A | 10523260 | . 1 지드래곤 | 빅뱅 | YG | 1 | 1988-08-18 | 177.0 | A | 9916947 | . 2 강다니엘 | NaN | 커넥트 | 1 | 1996-12-10 | 180.0 | A | 8273745 | . 3 뷔 | 방탄소년단 | 빅히트 | 1 | 1995-12-30 | 178.0 | AB | 8073501 | . 4 화사 | 마마무 | RBW | 0 | 1995-07-23 | 162.1 | A | 7650928 | . 5 정국 | 방탄소년단 | 빅히트 | 1 | 1997-09-01 | 178.0 | A | 5208335 | . 6 민현 | 뉴이스트 | 플레디스 | 1 | 1995-08-09 | 182.3 | O | 4989792 | . 7 소연 | 아이들 | 큐브 | 0 | 1998-08-26 | -1.0 | B | 4668615 | . 8 진 | 방탄소년단 | 빅히트 | 1 | 1992-12-04 | 179.2 | O | 4570308 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 1 | 1994-03-22 | 167.1 | A | 4036489 | . 10 태연 | 소녀시대 | SM | 0 | 1989-03-09 | -1.0 | A | 3918661 | . 11 차은우 | 아스트로 | 판타지오 | 1 | 1997-03-30 | 183.0 | B | 3506027 | . 12 백호 | 뉴이스트 | 플레디스 | 1 | 1995-07-21 | 175.0 | AB | 3301654 | . 13 JR | 뉴이스트 | 플레디스 | 1 | 1995-06-08 | 176.0 | O | 3274137 | . 14 슈가 | 방탄소년단 | 빅히트 | 1 | 1993-03-09 | 174.0 | O | 2925442 | . . (목표) 남자/ 여자의 문자열 데이터로 구성된 &#39;성별&#39; column을 1 / 0 으로 바꿔보세요 | . df = pd.read_csv(&#39;http://bit.ly/ds-korean-idol&#39;) . [주의] 반드시 return 값이 존재하여야합니다. . 남자: 1 여자: 0 기타: -1 . def male_or_female(x): if x == &#39;남자&#39;: return 1 elif x == &#39;여자&#39;: return 0 . df[&#39;성별_NEW&#39;] = df[&#39;성별&#39;].apply(male_or_female) . df.head() . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 성별_NEW . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | 1 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | 1 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | 1 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | 1 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | 0 | . . (목표) cm당 브랜드 평판지수를 구해보세요 (브랜드평판지수/ 키) | . def cm_to_brand(df): value = df[&#39;브랜드평판지수&#39;] / df[&#39;키&#39;] return value . df.apply(cm_to_brand, axis=1) . 0 60617.857143 1 56027.949153 2 45965.250000 3 45356.747191 4 47198.815546 5 29260.308989 6 27371.321997 7 NaN 8 25503.950893 9 24156.128067 10 NaN 11 19158.617486 12 18866.594286 13 18603.051136 14 16812.885057 dtype: float64 . . lambda &#54632;&#49688;&#51032; &#51201;&#50857; . lambda는 1줄로 작성하는 간단 함수식입니다. | return을 별도로 명기하지 않습니다 | . f = lambda x: 1 if x == &#39;남자&#39; else 0 . df[&#39;성별&#39;].apply(f) . 0 1 1 1 2 1 3 1 4 0 5 1 6 1 7 0 8 1 9 1 10 0 11 1 12 1 13 1 14 1 Name: 성별, dtype: int64 . . 실제로는 간단한 계산식을 적용하려는 경우에 많이 사용합니다. . df[&#39;키/2&#39;] = df[&#39;키&#39;].apply(lambda x: x / 2) . df.head() . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 성별_NEW 키/2 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | 1 | 86.80 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | 1 | 88.50 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | 1 | 90.00 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | 1 | 89.00 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | 0 | 81.05 | . . df[&#39;키&#39;].apply(lambda x: x ** 2) . 0 30136.96 1 31329.00 2 32400.00 3 31684.00 4 26276.41 5 31684.00 6 33233.29 7 NaN 8 32112.64 9 27922.41 10 NaN 11 33489.00 12 30625.00 13 30976.00 14 30276.00 Name: 키, dtype: float64 . apply에 함수식을 만들어서 적용해주는 것과 동일하기 때문에, 복잡한 조건식은 함수로 간단한 계산식은 lambda로 적용할 수 있습니다. . map - &#44050;&#51012; &#47588;&#54609; . my_map = { &#39;남자&#39;: 1, &#39;여자&#39;: 0 } . df[&#39;성별&#39;].map(my_map) . 0 1 1 1 2 1 3 1 4 0 5 1 6 1 7 0 8 1 9 1 10 0 11 1 12 1 13 1 14 1 Name: 성별, dtype: int64 . . my_map = { &#39;남자&#39;: &#39;male&#39;, &#39;여자&#39;: &#39;female&#39; } . df[&#39;성별&#39;].map(my_map) . 0 male 1 male 2 male 3 male 4 female 5 male 6 male 7 female 8 male 9 male 10 female 11 male 12 male 13 male 14 male Name: 성별, dtype: object . . &#45936;&#51060;&#53552;&#54532;&#47112;&#51076;&#51032; &#49328;&#49696; &#50672;&#49328; . df = pd.DataFrame({&#39;통계&#39;: [60, 70, 80, 85, 75], &#39;미술&#39;: [50, 55, 80, 100, 95], &#39;체육&#39;: [70, 65, 50, 95, 100] }) . Column &#44284; Column &#44036; &#50672;&#49328; (+, -, *, /, %) . type(df[&#39;통계&#39;]) . pandas.core.series.Series . df[&#39;통계&#39;] + df[&#39;미술&#39;] + df[&#39;체육&#39;] . 0 180 1 190 2 210 3 280 4 270 dtype: int64 . . df[&#39;통계&#39;] - df[&#39;미술&#39;] . 0 10 1 15 2 0 3 -15 4 -20 dtype: int64 . . df[&#39;통계&#39;] * df[&#39;미술&#39;] . 0 3000 1 3850 2 6400 3 8500 4 7125 dtype: int64 . . df[&#39;통계&#39;] / df[&#39;미술&#39;] . 0 1.200000 1 1.272727 2 1.000000 3 0.850000 4 0.789474 dtype: float64 . . df[&#39;통계&#39;] % df[&#39;미술&#39;] . 0 10 1 15 2 0 3 85 4 75 dtype: int64 . . Column &#44284; &#49707;&#51088; &#44036; &#50672;&#49328; (+, -, *, /, %) . df[&#39;통계&#39;] + 10 . 0 70 1 80 2 90 3 95 4 85 Name: 통계, dtype: int64 . . &#48373;&#54633; &#50672;&#49328; . df = pd.DataFrame({&#39;통계&#39;: [60, 70, 80, 85, 75], &#39;미술&#39;: [50, 55, 80, 100, 95], &#39;체육&#39;: [70, 65, 50, 95, 100] }) . df[&#39;통계미술합계&#39;] = df[&#39;통계&#39;] + df[&#39;미술&#39;] + 10 . df . 통계 미술 체육 통계미술합계 . 0 60 | 50 | 70 | 120 | . 1 70 | 55 | 65 | 135 | . 2 80 | 80 | 50 | 170 | . 3 85 | 100 | 95 | 195 | . 4 75 | 95 | 100 | 180 | . . mean(), sum()&#51012; axis &#44592;&#51456;&#51004;&#47196; &#50672;&#49328; . df = pd.DataFrame({&#39;통계&#39;: [60, 70, 80, 85, 75], &#39;미술&#39;: [50, 55, 80, 100, 95], &#39;체육&#39;: [70, 65, 50, 95, 100] }) . df.sum(axis=0) # == df.sum() . 통계 370 미술 380 체육 380 dtype: int64 . . df.mean(axis=0) # == df.mean() . 통계 74.0 미술 76.0 체육 76.0 dtype: float64 . . df.sum(axis=1) . 0 180 1 190 2 210 3 280 4 270 dtype: int64 . . df.mean(axis=1) . 0 60.000000 1 63.333333 2 70.000000 3 93.333333 4 90.000000 dtype: float64 . . NaN &#44050;&#51060; &#51316;&#51116;&#54624; &#44221;&#50864; &#50672;&#49328; . df = pd.DataFrame({&#39;통계&#39;: [60, 70, np.nan , 85, 75], &#39;미술&#39;: [50, np.nan , 80, 100, 95], &#39;체육&#39;: [70, 65, 50, np.nan , 100] }) . df[&#39;통계&#39;] / 2 . 0 30.0 1 35.0 2 NaN 3 42.5 4 37.5 Name: 통계, dtype: float64 . . 1000 / df[&#39;통계&#39;] . 0 16.666667 1 14.285714 2 NaN 3 11.764706 4 13.333333 Name: 통계, dtype: float64 . . df[&#39;통계&#39;] / np.nan . 0 NaN 1 NaN 2 NaN 3 NaN 4 NaN Name: 통계, dtype: float64 . . np.nan / df[&#39;통계&#39;] . 0 NaN 1 NaN 2 NaN 3 NaN 4 NaN Name: 통계, dtype: float64 . . DataFrame &#44284; DataFrame &#44036; &#50672;&#49328; . df1 = pd.DataFrame({&#39;통계&#39;: [60, 70, 80, 85, 75], &#39;미술&#39;: [50, 55, 80, 100, 95], &#39;체육&#39;: [70, 65, 50, 95, 100] }) . df2 = pd.DataFrame({&#39;통계&#39;: [&#39;good&#39;, &#39;bad&#39;, &#39;ok&#39; , &#39;good&#39;, &#39;ok&#39;], &#39;미술&#39;: [50, 60 , 80, 100, 95], &#39;체육&#39;: [70, 65, 50, 70 , 100] }) . 문자열이 포함된 DataFrame의 경우 . df1 + df2 . TypeError Traceback (most recent call last) ~ anaconda3 lib site-packages pandas core ops array_ops.py in _na_arithmetic_op(left, right, op, is_cmp) 141 try: --&gt; 142 result = expressions.evaluate(op, left, right) 143 except TypeError: ~ anaconda3 lib site-packages pandas core computation expressions.py in evaluate(op, a, b, use_numexpr) 234 # error: &#34;None&#34; not callable --&gt; 235 return _evaluate(op, op_str, a, b) # type: ignore[misc] 236 return _evaluate_standard(op, op_str, a, b) ~ anaconda3 lib site-packages pandas core computation expressions.py in _evaluate_numexpr(op, op_str, a, b) 119 if result is None: --&gt; 120 result = _evaluate_standard(op, op_str, a, b) 121 ~ anaconda3 lib site-packages pandas core computation expressions.py in _evaluate_standard(op, op_str, a, b) 68 with np.errstate(all=&#34;ignore&#34;): &gt; 69 return op(a, b) 70 TypeError: unsupported operand type(s) for +: &#39;int&#39; and &#39;str&#39; During handling of the above exception, another exception occurred: TypeError Traceback (most recent call last) &lt;ipython-input-151-8f6622453dfa&gt; in &lt;module&gt; 1 #collapse-output -&gt; 2 df1 + df2 ~ anaconda3 lib site-packages pandas core ops common.py in new_method(self, other) 63 other = item_from_zerodim(other) 64 &gt; 65 return method(self, other) 66 67 return new_method ~ anaconda3 lib site-packages pandas core arraylike.py in __add__(self, other) 87 @unpack_zerodim_and_defer(&#34;__add__&#34;) 88 def __add__(self, other): &gt; 89 return self._arith_method(other, operator.add) 90 91 @unpack_zerodim_and_defer(&#34;__radd__&#34;) ~ anaconda3 lib site-packages pandas core frame.py in _arith_method(self, other, op) 5980 self, other = ops.align_method_FRAME(self, other, axis, flex=True, level=None) 5981 -&gt; 5982 new_data = self._dispatch_frame_op(other, op, axis=axis) 5983 return self._construct_result(new_data) 5984 ~ anaconda3 lib site-packages pandas core frame.py in _dispatch_frame_op(self, right, func, axis) 6016 # _frame_arith_method_with_reindex 6017 -&gt; 6018 bm = self._mgr.operate_blockwise(right._mgr, array_op) 6019 return type(self)(bm) 6020 ~ anaconda3 lib site-packages pandas core internals managers.py in operate_blockwise(self, other, array_op) 372 Apply array_op blockwise with another (aligned) BlockManager. 373 &#34;&#34;&#34; --&gt; 374 return operate_blockwise(self, other, array_op) 375 376 def apply( ~ anaconda3 lib site-packages pandas core internals ops.py in operate_blockwise(left, right, array_op) 52 res_blks: List[&#34;Block&#34;] = [] 53 for lvals, rvals, locs, left_ea, right_ea, rblk in _iter_block_pairs(left, right): &gt; 54 res_values = array_op(lvals, rvals) 55 if left_ea and not right_ea and hasattr(res_values, &#34;reshape&#34;): 56 res_values = res_values.reshape(1, -1) ~ anaconda3 lib site-packages pandas core ops array_ops.py in arithmetic_op(left, right, op) 187 else: 188 with np.errstate(all=&#34;ignore&#34;): --&gt; 189 res_values = _na_arithmetic_op(lvalues, rvalues, op) 190 191 return res_values ~ anaconda3 lib site-packages pandas core ops array_ops.py in _na_arithmetic_op(left, right, op, is_cmp) 147 # will handle complex numbers incorrectly, see GH#32047 148 raise --&gt; 149 result = _masked_arith_op(left, right, op) 150 151 if is_cmp and (is_scalar(result) or result is NotImplemented): ~ anaconda3 lib site-packages pandas core ops array_ops.py in _masked_arith_op(x, y, op) 89 if mask.any(): 90 with np.errstate(all=&#34;ignore&#34;): &gt; 91 result[mask] = op(xrav[mask], yrav[mask]) 92 93 else: TypeError: unsupported operand type(s) for +: &#39;int&#39; and &#39;str&#39; . . column의 순서가 바뀌어 있는 경우 . df1 = pd.DataFrame({&#39;미술&#39;: [10, 20, 30, 40, 50], &#39;통계&#39;:[60, 70, 80, 90, 100] }) df2 = pd.DataFrame({&#39;통계&#39;: [10, 20, 30, 40, 50], &#39;미술&#39;: [60, 70, 80, 90, 100] }) . df1 + df2 . 미술 통계 . 0 70 | 70 | . 1 90 | 90 | . 2 110 | 110 | . 3 130 | 130 | . 4 150 | 150 | . . 행의 갯수가 다른경우 . df1 = pd.DataFrame({&#39;미술&#39;: [10, 20, 30, 40, 50, 60], &#39;통계&#39;:[60, 70, 80, 90, 100, 110] }) df2 = pd.DataFrame({&#39;통계&#39;: [10, 20, 30, 40, 50], &#39;미술&#39;: [60, 70, 80, 90, 100] }) . df1 * df2 . 미술 통계 . 0 600.0 | 600.0 | . 1 1400.0 | 1400.0 | . 2 2400.0 | 2400.0 | . 3 3600.0 | 3600.0 | . 4 5000.0 | 5000.0 | . 5 NaN | NaN | . . df = pd.read_csv(&#39;https://bit.ly/ds-korean-idol&#39;) . &#45936;&#51060;&#53552; &#53440;&#51077;&#48324; column &#49440;&#53469; (select_dtypes) . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype -- -- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB . . &#47928;&#51088;&#50676;&#51060; &#51080;&#45716; column &#47564; &#49440;&#53469; . df.select_dtypes(include=&#39;object&#39;) . 이름 그룹 소속사 성별 생년월일 혈액형 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | A | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | A | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | A | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | AB | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | A | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | A | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | O | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | B | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | O | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | A | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | A | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | B | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | AB | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | O | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | O | . . df.select_dtypes(exclude=&#39;object&#39;) . 키 브랜드평판지수 . 0 173.6 | 10523260 | . 1 177.0 | 9916947 | . 2 180.0 | 8273745 | . 3 178.0 | 8073501 | . 4 162.1 | 7650928 | . 5 178.0 | 5208335 | . 6 182.3 | 4989792 | . 7 NaN | 4668615 | . 8 179.2 | 4570308 | . 9 167.1 | 4036489 | . 10 NaN | 3918661 | . 11 183.0 | 3506027 | . 12 175.0 | 3301654 | . 13 176.0 | 3274137 | . 14 174.0 | 2925442 | . . num_cols = df.select_dtypes(exclude=&#39;object&#39;).columns obj_cols = df.select_dtypes(include=&#39;object&#39;).columns . df[obj_cols] . 이름 그룹 소속사 성별 생년월일 혈액형 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | A | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | A | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | A | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | AB | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | A | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | A | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | O | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | B | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | O | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | A | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | A | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | B | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | AB | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | O | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | O | . . &#50896;&#54635;&#51064;&#53076;&#46377; (One-hot-encoding) . 원핫인코딩은 한개의 요소는 True 그리고 나머지 요소는 False로 만들어 주는 기법입니다. | 원핫인코딩은 왜 필요할까요? | . blood_map = { &#39;A&#39;: 0, &#39;B&#39;: 1, &#39;AB&#39;: 2, &#39;O&#39;: 3, } . df[&#39;혈액형_code&#39;] = df[&#39;혈액형&#39;].map(blood_map) . df.head() . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 혈액형_code . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | 0 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | 0 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | 0 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | 2 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | 0 | . . df[&#39;혈액형_code&#39;].value_counts() . 0 7 3 4 1 2 2 2 Name: 혈액형_code, dtype: int64 . . 우리가 만약 df[&#39;혈액형_code&#39;]를 머신러닝 알고리즘에 그대로 넣어 데이터를 예측하라고 지시한다면, 컴퓨터는 &#39;혈액형_code&#39;안에서 값들간의 관계를 스스로 형성하게 됩니다. | 이 상황에서 만약 B형은 1, AB형은 2라는 값을 가지고 있는데, 컴퓨터는 B형 + AB형 = O형이다라고 잘못 관계를 맺을 수 있게 됩니다. | 따라서, 우리는 4개의 별도의 column을 형성해주고 1개의 column에는 True 나머지는 모두 False를 넣어 줌으로써 A, B, AB, O형의 관계는 독립적이다를 표현해줍니다. | 이를 원핫인코딩이라고 합니다. | . df[&#39;혈액형_code&#39;] . 0 0 1 0 2 0 3 2 4 0 5 0 6 3 7 1 8 3 9 0 10 0 11 1 12 2 13 3 14 3 Name: 혈액형_code, dtype: int64 . . pd.get_dummies(df[&#39;혈액형_code&#39;]) . 0 1 2 3 . 0 1 | 0 | 0 | 0 | . 1 1 | 0 | 0 | 0 | . 2 1 | 0 | 0 | 0 | . 3 0 | 0 | 1 | 0 | . 4 1 | 0 | 0 | 0 | . 5 1 | 0 | 0 | 0 | . 6 0 | 0 | 0 | 1 | . 7 0 | 1 | 0 | 0 | . 8 0 | 0 | 0 | 1 | . 9 1 | 0 | 0 | 0 | . 10 1 | 0 | 0 | 0 | . 11 0 | 1 | 0 | 0 | . 12 0 | 0 | 1 | 0 | . 13 0 | 0 | 0 | 1 | . 14 0 | 0 | 0 | 1 | . . prefix를 설정하려면? . pd.get_dummies(df[&#39;혈액형_code&#39;], prefix=&#39;혈액형&#39;) . 혈액형_0 혈액형_1 혈액형_2 혈액형_3 . 0 1 | 0 | 0 | 0 | . 1 1 | 0 | 0 | 0 | . 2 1 | 0 | 0 | 0 | . 3 0 | 0 | 1 | 0 | . 4 1 | 0 | 0 | 0 | . 5 1 | 0 | 0 | 0 | . 6 0 | 0 | 0 | 1 | . 7 0 | 1 | 0 | 0 | . 8 0 | 0 | 0 | 1 | . 9 1 | 0 | 0 | 0 | . 10 1 | 0 | 0 | 0 | . 11 0 | 1 | 0 | 0 | . 12 0 | 0 | 1 | 0 | . 13 0 | 0 | 0 | 1 | . 14 0 | 0 | 0 | 1 | . . pd.get_dummies(df, columns = [&#39;혈액형_code&#39;]) . 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 혈액형_code_0 혈액형_code_1 혈액형_code_2 혈액형_code_3 . 0 지민 | 방탄소년단 | 빅히트 | 남자 | 1995-10-13 | 173.6 | A | 10523260 | 1 | 0 | 0 | 0 | . 1 지드래곤 | 빅뱅 | YG | 남자 | 1988-08-18 | 177.0 | A | 9916947 | 1 | 0 | 0 | 0 | . 2 강다니엘 | NaN | 커넥트 | 남자 | 1996-12-10 | 180.0 | A | 8273745 | 1 | 0 | 0 | 0 | . 3 뷔 | 방탄소년단 | 빅히트 | 남자 | 1995-12-30 | 178.0 | AB | 8073501 | 0 | 0 | 1 | 0 | . 4 화사 | 마마무 | RBW | 여자 | 1995-07-23 | 162.1 | A | 7650928 | 1 | 0 | 0 | 0 | . 5 정국 | 방탄소년단 | 빅히트 | 남자 | 1997-09-01 | 178.0 | A | 5208335 | 1 | 0 | 0 | 0 | . 6 민현 | 뉴이스트 | 플레디스 | 남자 | 1995-08-09 | 182.3 | O | 4989792 | 0 | 0 | 0 | 1 | . 7 소연 | 아이들 | 큐브 | 여자 | 1998-08-26 | NaN | B | 4668615 | 0 | 1 | 0 | 0 | . 8 진 | 방탄소년단 | 빅히트 | 남자 | 1992-12-04 | 179.2 | O | 4570308 | 0 | 0 | 0 | 1 | . 9 하성운 | 핫샷 | 스타크루이엔티 | 남자 | 1994-03-22 | 167.1 | A | 4036489 | 1 | 0 | 0 | 0 | . 10 태연 | 소녀시대 | SM | 여자 | 1989-03-09 | NaN | A | 3918661 | 1 | 0 | 0 | 0 | . 11 차은우 | 아스트로 | 판타지오 | 남자 | 1997-03-30 | 183.0 | B | 3506027 | 0 | 1 | 0 | 0 | . 12 백호 | 뉴이스트 | 플레디스 | 남자 | 1995-07-21 | 175.0 | AB | 3301654 | 0 | 0 | 1 | 0 | . 13 JR | 뉴이스트 | 플레디스 | 남자 | 1995-06-08 | 176.0 | O | 3274137 | 0 | 0 | 0 | 1 | . 14 슈가 | 방탄소년단 | 빅히트 | 남자 | 1993-03-09 | 174.0 | O | 2925442 | 0 | 0 | 0 | 1 | . . &#49884;&#44033;&#54868; . import matplotlib.pyplot as plt %matplotlib inline import platform if platform.system() == &#39;Darwin&#39;: # Mac 환경 폰트 설정 plt.rc(&#39;font&#39;, family=&#39;AppleGothic&#39;) elif platform.system() == &#39;Windows&#39;: # Windows 환경 폰트 설정 plt.rc(&#39;font&#39;, family=&#39;Malgun Gothic&#39;) plt.rc(&#39;axes&#39;, unicode_minus=False) # 마이너스 폰트 설정 %config InlineBackend.figure_format = &#39;retina&#39; . df = pd.read_csv(&#39;https://bit.ly/ds-house-price-clean&#39;) . df.plot() . &lt;AxesSubplot:&gt; . . Graph Size . plt.rcParams[&quot;figure.figsize&quot;] = (12, 9) . df.plot() . &lt;AxesSubplot:&gt; . . Plot &#44536;&#47000;&#54532; . plot은 일반 선그래프를 나타냅니다. . kind 옵션을 통해 원하는 그래프를 그릴 수 있습니다. . kind 옵션: . line: 선그래프 | bar: 바 그래프 | barh: 수평 바 그래프 | hist: 히스토그램 | kde: 커널 밀도 그래프 | hexbin: 고밀도 산점도 그래프 | box: 박스 플롯 | area: 면적 그래프 | pie: 파이 그래프 | scatter: 산점도 그래프 | . line &#44536;&#47000;&#54532; . line 그래프는 데이터가 연속적인 경우 사용하기 적절합니다. (예를 들면, 주가 데이터) | . df[&#39;분양가&#39;].plot(kind=&#39;line&#39;) . &lt;AxesSubplot:&gt; . . df_seoul = df.loc[df[&#39;지역&#39;] == &#39;서울&#39;] . df_seoul . 지역 규모 연도 월 분양가 . 0 서울 | 60㎡이하 | 2015 | 10 | 5652 | . 1 서울 | 60㎡초과 85㎡이하 | 2015 | 10 | 5882 | . 2 서울 | 85㎡초과 102㎡이하 | 2015 | 10 | 5721 | . 3 서울 | 102㎡초과 | 2015 | 10 | 5879 | . 64 서울 | 60㎡이하 | 2015 | 11 | 6320 | . ... ... | ... | ... | ... | ... | . 3178 서울 | 102㎡초과 | 2020 | 1 | 8779 | . 3234 서울 | 60㎡이하 | 2020 | 2 | 8193 | . 3235 서울 | 60㎡초과 85㎡이하 | 2020 | 2 | 8140 | . 3236 서울 | 85㎡초과 102㎡이하 | 2020 | 2 | 13835 | . 3237 서울 | 102㎡초과 | 2020 | 2 | 9039 | . 212 rows × 5 columns . . df_seoul_year = df_seoul.groupby(&#39;연도&#39;).mean() . df_seoul_year . 월 분양가 . 연도 . 2015 11.0 | 6201.000000 | . 2016 6.5 | 6674.520833 | . 2017 6.5 | 6658.729167 | . 2018 6.5 | 7054.687500 | . 2019 6.5 | 8735.083333 | . 2020 1.5 | 9647.375000 | . . df_seoul_year[&#39;분양가&#39;].plot(kind=&#39;line&#39;) . &lt;AxesSubplot:xlabel=&#39;연도&#39;&gt; . . bar &#44536;&#47000;&#54532; . bar 그래프는 그룹별로 비교할 때 유용합니다. . df.groupby(&#39;지역&#39;)[&#39;분양가&#39;].mean() . 지역 강원 2448.156863 경기 4133.952830 경남 2858.932367 경북 2570.465000 광주 3055.043750 대구 3679.620690 대전 3176.127389 부산 3691.981132 서울 7308.943396 세종 2983.543147 울산 2990.373913 인천 3684.302885 전남 2326.250000 전북 2381.416268 제주 3472.677966 충남 2534.950000 충북 2348.183962 Name: 분양가, dtype: float64 . . df.groupby(&#39;지역&#39;)[&#39;분양가&#39;].mean().plot(kind=&#39;bar&#39;) . &lt;AxesSubplot:xlabel=&#39;지역&#39;&gt; . . df.groupby(&#39;지역&#39;)[&#39;분양가&#39;].mean().plot(kind=&#39;barh&#39;) . &lt;AxesSubplot:ylabel=&#39;지역&#39;&gt; . . &#55176;&#49828;&#53664;&#44536;&#47016; (hist) . 히스토그램은 분포-빈도 를 시각화하여 보여줍니다 . 가로축에는 분포를, 세로축에는 빈도가 시각화되어 보여집니다. . df[&#39;분양가&#39;].plot(kind=&#39;hist&#39;) . &lt;AxesSubplot:ylabel=&#39;Frequency&#39;&gt; . . &#52964;&#45328; &#48128;&#46020; &#44536;&#47000;&#54532; . 히스토그램과 유사하게 밀도를 보여주는 그래프입니다. | 히스토그램과 유사한 모양새를 갖추고 있습니다. | 부드러운 라인을 가지고 있습니다. | . df[&#39;분양가&#39;].plot(kind=&#39;kde&#39;) . &lt;AxesSubplot:ylabel=&#39;Density&#39;&gt; . . Hexbin . hexbin은 고밀도 산점도 그래프입니다. | x와 y 키 값을 넣어 주어야 합니다. | x, y 값 모두 numeric 한 값을 넣어 주어야합니다. | 데이터의 밀도를 추정합니다. | . df.plot(kind=&#39;hexbin&#39;, x=&#39;분양가&#39;, y=&#39;연도&#39;, gridsize=20) . &lt;AxesSubplot:xlabel=&#39;분양가&#39;, ylabel=&#39;연도&#39;&gt; . . &#48149;&#49828; &#54540;&#47215;(box) . df_seoul = df.loc[df[&#39;지역&#39;] == &#39;서울&#39;] . df_seoul[&#39;분양가&#39;].plot(kind=&#39;box&#39;) . &lt;AxesSubplot:&gt; . . df_seoul.describe() . 연도 월 분양가 . count 212.00000 | 212.000000 | 212.000000 | . mean 2017.45283 | 6.566038 | 7308.943396 | . std 1.31439 | 3.603629 | 1402.869496 | . min 2015.00000 | 1.000000 | 5061.000000 | . 25% 2016.00000 | 3.000000 | 6519.750000 | . 50% 2017.00000 | 7.000000 | 6895.500000 | . 75% 2019.00000 | 10.000000 | 7732.000000 | . max 2020.00000 | 12.000000 | 13835.000000 | . . area plot . area plot은 line 그래프에서 아래 area를 모두 색칠해 주는 것이 특징입니다. . df.groupby(&#39;월&#39;)[&#39;분양가&#39;].count().plot(kind=&#39;line&#39;) . &lt;AxesSubplot:xlabel=&#39;월&#39;&gt; . . df.groupby(&#39;월&#39;)[&#39;분양가&#39;].count().plot(kind=&#39;area&#39;) . &lt;AxesSubplot:xlabel=&#39;월&#39;&gt; . . pie plot (&#54028;&#51060; &#44536;&#47000;&#54532;) . pie는 대표적으로 데이터의 점유율을 보여줄 때 유용합니다. . df.groupby(&#39;연도&#39;)[&#39;분양가&#39;].count().plot(kind=&#39;pie&#39;) . &lt;AxesSubplot:ylabel=&#39;분양가&#39;&gt; . . scatter plot (&#49328;&#51216;&#46020; &#44536;&#47000;&#54532;) . 점으로 데이터를 표기해 줍니다 | x, y 값을 넣어주어야합니다 (hexbin과 유사) | x축과 y축을 지정해주면 그에 맞는 데이터 분포도를 볼 수 있습니다. | 역시 numeric 한 column 만 지정할 수 있습니다 | . df.plot(x=&#39;월&#39;, y=&#39;분양가&#39;, kind=&#39;scatter&#39;) . &lt;AxesSubplot:xlabel=&#39;월&#39;, ylabel=&#39;분양가&#39;&gt; . .",
            "url": "https://star77sa.github.io/TIL-Blog/python/2021/08/09/Pandas.html",
            "relUrl": "/python/2021/08/09/Pandas.html",
            "date": " • Aug 9, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Deep Learning",
            "content": ". 1&#51109; &#49884;&#51089;&#54616;&#47728; . &#52572;&#44540;&#44620;&#51648;&#51032; &#49888;&#44221;&#47581; &#50672;&#44396; &#51200;&#51312;&#51032; &#51060;&#50976; . 역전파법에 의한 신경망 학습이 2층정도의 신경망에선 잘 이뤄졌지만 그보다 많은 층수에선 기대했던 결과를 얻지 못함. 과적합이 나타남. (예외 : CNN) | 신경망은 학습을 위한 여러 파라미터로 층수나 유닛의 수를 갖는데 이 파라미터가 최종적으로 어떻게 성능으로 이어지는지 알 수 없었음. 파라미터 결정에 노하우는 있지만 이론이 없었음. | 이런 이유로 머신러닝보다 뒤떨어진다는 평가를 받음. . CNN . 특정한 이미지 처리를 수행하는 층이 여러개 쌓인 구조를 갖는, 층간의 결합 밀도가 낮은 신경망 | . DBN . 일반적인 신경망과 유사하게 다층 구조를 갖는 그래프 모델(graph model). 이 모델의 동작은 확률적으로 기술되며, 주로 데이터의 생성 모델로 쓰였다. | . &#50669;&#51204;&#54028;&#48277; . 샘플에 대한 신경망의 오차(목표 출력과 실제 출력의 차이)를 다시 출력층에서부터 입력층으로 거꾸로 전파시켜 각 층의 가중치의 기울기를 계산하는 방법 | . &#49324;&#51204;&#54984;&#47144; . 사용하려는 신경망을 학습기키기 전 층단위의 학습을 거치는 것으로 더 나은 초기값을 얻는 방법. 딥 러닝 붐의 계기가 되었지만, 필수적인 것만은 아님. CNN같은 경우는 처음부터 사전훈련을 필요로 하지 않는다. | . &#51088;&#44592;&#48512;&#54840;&#54868;&#44592; . 입력으로부터 계산되는 출력이 입력 자체와 비슷해지도록 훈련되는 신경망. 다시말해 자기부호화기의 목표 출력은 입력 그 자체이며, 비지도 학습으로 학습이 이루어진다. | . 다층 신경망은 파라미터를 랜덤하게 초기화하면 학습이 잘 되지 않지만, 층마다 비지도 학습 형태의 사전훈련을 거친 뒤 얻은 파라미터를 초깃값으로 사용하면 학습이 잘된다고 한다. . . 2&#51109; &#50526;&#47673;&#51076; &#49888;&#44221;&#47581; . &#50526;&#47673;&#51076; &#49888;&#44221;&#47581; . . 층 모양으로 늘어선 유닛이 인접한 층(layer)들과만 결합하는 구조를 가지며 정보가 입력 측으로부터 출력 측으로 한 방향으로만 흐르는 신경망. 다층 퍼셉트론(multi-layer perceptron)이라 부르기도 한다. . 신경망을 구성하는 각 유닛은 복수의 입력을 받아 하나의 출력을 계산한다. 입력은 가중치 4개를 받지만, 이 유닛이 받는 총 입력은 다음과 같이 바이어스를 추가하여 5개이다. . | . $$ u = w_1x_1 + w_2x_2 + w_3x_3 + w_4x_4 + b $$ . 각 입력마다 다른 가중치(weight) w1, w2, w3, w4를 곱한 값을 모두 합하고, 이에 바이어스(bias)라 불리는 값을 더한 값이 된다. | . 이 유닛의 출력 z 는 총 입력 u에 대한 활성화 함수(activation function)라 불리는 함수 f의 함숫값이다. | . 유닛마다 각각 다른 가중치 w가 주어진다 . 세 개의 유닛이 받는 입력은 각각 다음과 같이 계산된다. . $$ u_1 = w_{11}x_1 + w_{12}x_2 + w_{13}x_3 + w_{14}x_4 + b_1 $$ . $$ u_1 = w_{21}x_1 + w_{22}x_2 + w_{23}x_3 + w_{24}x_4 + b_2 $$ . $$ u_1 = w_{31}x_1 + w_{32}x_2 + w_{33}x_3 + w_{34}x_4 + b_3 $$ . | . 여기에 다시 활성화 함수를 적용하여 아래 식과 같은 출력이 된다. . $$ z_{j} = f(u_{j}) , , , , , ,(j = 1, 2, 3) $$ . &#54876;&#49457;&#54868; &#54632;&#49688; . 유닛의 활성화 함수로는 통상적으로 단조증가하는 비선형함수가 사용된다. | . . 로지스틱 함수는 (0, 1)을 치역으로, 쌍곡선 정접함수는 (-1, 1)을 치역으로 갖는다. | 로지스틱함수와 쌍곡선 정접함수는 모두 시그모이드 함수이다. 출력이 서서히 그리고 매끄럽게 변화하는 특징을 갖는다. 이러한 특징은 생물의 신경세포가 갖는 성질을 모델링한 것이다. | . . 최근에 시그모이드 대신 램프 함수가 자주 사용된다. 간단하게 줄여 rectifier라고도 부른다. . 램프 함수는 z = u 인 선형 함수 중 u &lt; 0 인 부분을 f(u) = 0으로 바꾼 단순한 함수이다. . 위의 두 함수보다 학습이 빠르고 최종 결과가 더 좋은 경우가 많아 현재 가장 많이 사용된다. . 이 함수를 갖는 유닛을 ReLU (Rectified Linear Unit)라고 표기하기도 한다. . | . 램프 함수와 관계 깊은 맥스아웃은 K개의 유닛을 하나로 합친 것과 같은 구조를 갖는다. . 각각의 총 입력을 uj1, uj2 ... ujk 별로 따로 계산한 후, 그중 최댓값을 이 유닛의 출력으로 한다. . | . 신경망에서는 각 유닛의 활성화 함수가 비선형성을 갖는 것이 본질적으로 중요하지만, 부분적으로 선형사상을 사용하는 경우가 있다. . 회귀 문제에선 출력층에서 항등사상을, 클래스 분류에서는 소프트맥스 함수를 사용한다. . | . &#45796;&#52789; &#49888;&#44221;&#47581; . . 정보는 왼쪽에서 오른쪽 한 방향으로 전달, 순서대로 각 층을 l = 1, 2, 3으로 표기 . l = 1인 층을 입력층 . l = 2인 층을 중간층 또는 은닉층 . l = 3인 층을 출력층 이라고 한다. . | . 중간층에선 x를 입력으로 받는데, 그 다음 층에서는 중간층의 출력을 입력으로 받는다. | . 각 층에서 서로 다른 활성화 함수를 사용하여도 무방하다. 특히 출력층 유닛의 활성화 함수는 일반적으로 중간층과는 다른 활성화 함수를 사용한다. | . 하나의 입력 x에 대하여 바람직한 출력을 d라고 할 때, 이러한 입출력 쌍이 어러개 주어졌다고 하면 . 신경망의 출력 y이 최대한 d와 가까워지도록 w를 조정해야한다. 이것을 학습이라고 부른다. . 이 때 신경망이 나타내는 함수와 훈련 데이터와의 가까운 정도 즉 거리를 어떻게 측정할 것인지가 중요한데 . 이 거리의 척도를 오차함수라고 부른다. . | . 오차함수 = 손실함수 (나쁜 정도를 측정하는 함수라 보면 될듯 작을수록 좋다!) | . 문제의 유형 출력층에 쓰이는 활성화 함수 오차함수 . 회귀 | 항등사상 | 제곱오차 | . 이진 분류 | 로지스틱 함수 | 식 2-8 | . 다클래스 분류 | 소프트맥스 함수 | 교차 엔트로피 | . &#54924;&#44480; . 출력이 연속값을 갖는 함수를 대상으로 훈련 데이터를 잘 재현하는 함수를 찾는 것 . 목적으로 하는 함수와 같은 치역을 갖는 함수를 출력층의 활성화 함수로 골라야 함. . ex) 목표함수의 치역이 [-1 : 1]인 경우 쌍곡선 정접함수, 목표함수가 (-inf : inf)인 경우 항등사상이 적합하다. . &#52572;&#45824;&#50864;&#46020;&#48277;(Maximum Likelihood Estimation, &#51060;&#54616; MLE) . 모수적인 데이터 밀도 추정 방법으로써 파라미터 $ theta = ( theta_1, cdots, theta_m)$으로 구성된 어떤 확률밀도함수 $P(x| theta)$에서 관측된 표본 데이터 집합을 $x = (x_1, x_2, cdots, x_n)$이라 할 때, 이 표본들에서 파라미터 $ theta = ( theta_1, cdots, theta_m)$를 추정하는 방법이다. . 데이터가 먼저 주어지고, 이를 이용하여 함수의 파라미터를 추정하는 것 . &#51060;&#51652; &#48516;&#47448; . 활성화 함수로 로지스틱 함수를 가짐 | 최대우도법을 통해 추정한 파라미터 사용 | . &#45796;&#53364;&#47000;&#49828; &#48516;&#47448; . 클래스 분류란 입력 x를 내용에 따라 유한개의 클래스로 분류하는 문제. . 신경망의 출력층에 분류하려는 클래스 수 L과 같은 수의 유닛을 구성, 이 층의 활성화 함수를 소프트맥스로 선택. . . 소프트맥스 함수에서는 이 층 모든 유닛의 총 입력으로부터 결정되는 점이 다른 함수들과 다르다. . 출력 y1 y2 ... yn 총합이 항상 1이 되는 것에 주의 . . 3&#51109; &#54869;&#47456;&#51201; &#44221;&#49324; &#54616;&#44053;&#48277; . &#44221;&#49324;&#54616;&#44053;&#48277; . 학습의 목표는 선택한 오차함수에 대하여 최솟값을 주는 오차함수를 구하는 것이지만, . 오차함수는 일반적인 경우 볼록함수가 아니므로 전역극소점(global minimum)을 직접 구하는 것은 통상적으로 불가능하다. . 대신에 국소 극소점(local minimum)을 구하는 것을 생각해보면, 국소 극소점은 여러개 존재하므로 . 구한 극소점이 우연히 전역 극소점일 가능성은 낮다. 다만 국소 극소점이 충분히 작다면 목적으로 하는 클래스 분류나 . 회귀 문제를 나름대로 잘 풀 수도 있다. . | . . 현재의 w를 음의 기울기 방향으로 조금씩 움직이는 것을 여러번 반복하여 언젠가는 극소점에 도달하는 것이다. . 최소화 방법에 목적함수의 2차미분을 이용하는 뉴턴법 등이 있지만 문제의 크기가 큰 경우에 2차 미분에 대한 계산이 . 어렵기에 경사하강법은 사용할 수 있는 몇 안되는 유효한 방법 중 하나가 된다. . | . &#54869;&#47456;&#51201; &#44221;&#49324; &#54616;&#44053;&#48277; . 위에서는 각 샘플의 오차들의 합을 이용하여 한 방법인데, 이를 배치학습이라고 한다. = 에포크 학습 . 확률적 경사하강법은 이와 대조적으로 샘플의 일부, 극단적으론 샘플 하나만을 사용하여 파라미터를 업데이트 한다. . 1회 진행할때마다 다른 샘플을 선택하여 업데이트를 한다. . 배치학습과 비교하여 장점은 . 훈련 데이터에 잉여성이 있을 때 계산 효율이 향상되고 학습이 빨리 진행된다. . | 국소 극소점에 갇히는 위험을 줄일 수 있다. 목적함수가 w를 업데이트할 때마다 달라지므로. . | | . &#48120;&#45768;&#48176;&#52824; . 샘플 전체를 선택 : 경사하강법 / 배치학습 . 샘플 1개를 선택 : 확률적 경사하강법 . 샘플 여러개를 선택 : 미니배치 . | . 미니배치의 크기를 결정하는 통계적인 방법이 따로 있지는 않지만, 확률적 경사하강법의 장점과 병렬 계산 자원의 유효한 이용을 비교하여 . 대체로 10~100개 샘플 전후로 결정하는 경우가 많다. . | . 다클래스 분류 문제에서는 미니배치 간의 가중치 업데이트 값을 일정하게 하기 위해 미니배치마다 각 클래스의 샘플이 하나 이상 들어가도록 하는 것이 이상적 . 따라서 클래스 수가 10~100개 정도이면서 각 클래스의 출현 빈도가 서로 같을 때에는 분류하려는 클래스 수와 같은 크기의 미니배치를 생성하는 것이 좋다. . | . 미니 배치의 크기를 너무 작게 잡는 것은 별로 좋지 않다. (확률적 경사 하강법의 장점을 완전히 활용하지 못하게 하므로) | . 크기를 크게할수록 학습이 빨라지지만 계산속도(단위시간당 업데이트 횟수)는 오히려 느려진다. | . &#51068;&#48152;&#54868; &#49457;&#45733;&#44284; &#44284;&#51201;&#54633; . 학습의 진짜 목적은 이미 주어진 훈련 데이터가 아니라 앞으로 주어질 &#39;미지의&#39; 샘플 x에 대한 정확한 추정을 가능토록 하는 것 | . 훈련 데이터에 대한 오차 훈련오차(training error) . 샘플 모집단에 대한 오차에 대한 기댓값 일반화 오차(generalization error) . | . 일반화 오차가 작도록 하는 것이 목표이지만, 일반화 오차는 통계적인 기댓값이므로 훈련 오차처럼 계산할 수가 없다. . 그러므로 훈련 데이터와 다른 별도의 샘플 집합을 준비한 후, 이 샘플 집합에 대해서 훈련 오차와 같은 방법으로 계산한 오차를 기준으로 삼는다. . 이를 목적으로 준비하는 데이터를 테스트 데이터(test data), 테스트 데이터에 대한 오차를 테스트 오차(test error) . | . 학습곡선 : 학습에 의한 파라미터 변화에 따라 훈련 오차 및 테스트 오차가 어떻게 변화하는지에 대한 곡선 | . . 일반적으로 훈련 오차는 파라미터의 업데이트를 반복함에 따라 대개 단조적으로 감소한다. . 그에 비해 테스트 오차는 학습 초기에는 훈련 오차와 같이 감소하다가 학습도중에 자주 훈련오차와 많이 달라진 값을 갖게된다. . 과적합(overfitting) : 훈련 오차와 일반화 오차가 동떨어진 값을 갖는 상태가 되는 것 | . 조기종료(early stopping) : 파라미터 업데이트에 따라 테스트 오차가 증가한다면 더 이상의 학습은 오히려 방해가 되기에 그 시점에서 학습을 종료 | . &#44284;&#51201;&#54633;&#51012; &#50756;&#54868;&#49884;&#53412;&#45716; &#48169;&#48277; . 과적합이란 학습 시에 오차함수 값이 작은 국소 극소점에 갇힌 상황이라고 해석할 수 있다. . 신경망의 자유도(주로 가중치의 수)가 높을수록 그럴 가능성이 높다고 할 수 있다. . 다만 신경망의 자유도는 그 표현 능력과 직결된다. . | . 학습 시에 가중치의 자유도를 제약하는 규제화(regularization)에 의해 과적합 문제를 완화시키는 방법 : 가중치 감쇠, 가중치 상한, 드롭아웃 . &#44032;&#51473;&#52824; &#44048;&#49632; . 오차함수에 가중치의 제곱합(norm의 제곱)을 더한 뒤 이를 최소화 하는 방법. . 가중치는 자신의 크기에 비례하는 속도로 항상 감쇠하도록 업데이트된다. . | . 가중치 감쇠는 가중치 W에만 적용하며 바이어스b에는 적용하지 않는다. | . &#44032;&#51473;&#52824; &#49345;&#54620; . 각 유닛의 입력 측 결합의 가중치에 대해서 그 제곱합의 최댓값을 제약하는 방법 . $ sum_i w_{ji}^2 &lt; c $ . 이 부등식을 만족하지 않는 경우에는 가중치에 미리 정한 (1보다 작은) 상수를 곱하여 부등식을 만족하도록 한다. . | . 가중치 감쇠보다 뛰어난 효과, 드롭아웃과 함께 사용하면 특히 높은 효과. | . &#46300;&#47213;&#50500;&#50883; . 드롭아웃 : 다층 신경망의 유닛 중 일부를 확률적으로 선택하여 학습하는 방법 | . . 학습 시 . 중간층과 입력층 각 층의 유닛 중 미리 정해둔 비율 p만큼을 선택하고 선택되지 않은 유닛을 무효화. . 가상의 신경망을 구성하는 유닛은 가중치를 업데이트할 때 마다 다시 무작위로 선택 . | 추론 시 . 모든 유닛을 사용하여 앞먹임 계산을 한다. . 드롭아웃에서 무효화된 유닛은 일률적으로 출력을 p배로 한다. 추론시의 유닛 수가 학습 시에 비해 1/p배 된 것과 같기 때문에 이를 보상하기 위함 . (추론 시가 학습시보다 유닛 수가 많음.) . | . 드롭아웃이 목적하는 바 : 신경망의 자유도(가중치의 수)를 강제적으로 낮추고 과적합을 회피하는 것 | . 이 과정은 드롭아웃을 거친 신경망을 여러 개 훈련한 후 여러개의 신경망으로 부터 얻은 결괏값의 평균을 내는 것과 같은 효과가 있다고 볼 수 있다. . 다수의 신경망의 평균을 내면 추론의 정확도가 일반적으로 좋아진다고 알려져 있으며 드롭아웃은 같은 효과를 보다 적은 계산 비용으로 얻을 수 있는 방법이라 볼 수 있다. . | . &#54617;&#49845;&#51012; &#50948;&#54620; &#53944;&#47533; . 학습 시에 적용하는 것만으로도 일반화 성능을 향상시키거나 학습을 빨리 진행할 수 있게 하는 방법 . | 이론적 뒷받침이 부족한 노하우에 가까운 것들. 실제로 효과를 인정받는 것이 많아 오래전부터 사용됐다. . | . &#45936;&#51060;&#53552; &#51221;&#44508;&#54868; . 데이터에서 경향을 제거하기 위한 전처리 | 각 성분에서 해당 성분의 학습데이터 전체에서 평균을 빼서 평균이 0이되도록 변환한 뒤 각 성분을 표준편차로 나눈다. . 각 성분의 평균이 0, 분산이 1이됨 . | . &#45936;&#51060;&#53552; &#54869;&#51109; . 훈련 데이터의 부족은 과적합을 일으키는 가장 큰 원인. . | 데이터 확장 : 확보한 샘플 데이터를 일정하게 가공하여 양적으로 &#39;물타기&#39; 하는 방법 . | 데이터 확장은 샘플의 분포 양상을 예상할 수 있는 경우에 특히 유효하다. 이미지 데이터가 그 전형적인 예 . | . &#50668;&#47084; &#49888;&#44221;&#47581;&#51032; &#54217;&#44512; : &#47784;&#45944; &#54217;&#44512; . 여러개의 서로 다른 신경망을 조합하면 일반적으로 추정의 정확도를 향상시킬 수 있다. | 조합할 신경망은 같은 데이터로 훈련한 서로 구조가 다른 것들로 구성하거나 구조가 같아도 서로 다른 초깃값으로 초기화한 것으로 구성. . 입력에 서로 다른 변환을 가해 두고 각각 다른 신경망에 입력하여 결과를 평균 내는 방법도 있음. . 학습 시에 각 신경망은 서로 독립적으로 훈련 . | 단점 : 복수의 신경망을 학습시켜야 하므로 시간 및 연산량이 증가 . | 위에서의 드롭아웃은 신경망 하나를 사용해서 실질적으로는 여러개의 신경망에 모델 평균을 적용한 것과 같은 효과가 있다 . | . &#54617;&#49845;&#47456;&#51032; &#44208;&#51221; &#48169;&#48277; . 경사 하강법에서는 파라미터의 업데이트 정도를 학습률을 통해 조절 . | 학습률을 결정하기 위한 정석과 같은 방법 2가지 . 학습 초기에 값을 크게 설정했다가 학습의 진행과 함께 학습률을 점점 줄여가는 방법 . | 신경망의 모든 층에서 같은 학습률을 사용하는 것이 아닌 층마다 서로 다른 값을 사용하는 것 . 각 층의 가중치 업데이트 속도가 되도록 비슷하게 가중치를 설정하는 것이 좋다고 알려져 있다. | 로지스틱 함수처럼 치역이 제약된 활성화 함수를 사용할 때 특히 중요하다. | 램프 함수를 사용할 때는 적합하지 않다. | . | | . 학습률을 자동적으로 결정하는 방법 : AdaGrad 자주 나타나는 기울기의 성분보다 드물게 나타나는 기울기의 성분을 더 중시해서 파라미터를 업데이트 하는 것 | . | . &#47784;&#47704;&#53568; . 가중치의 업데이트 값에 이전 업데이트 값의 일정 비율을 더하는 방법 . | 오차 함수가 깊은 골짜기 같은 형상을 가지며, 그 골짜기 바닥이 비교적 평평한 경우에는 경사 하강법의 효율이 매우 떨어진다고 알려져있다. . 모멘텀은 이러한 문제를 해결하고 골짜기 방향을 따라 골짜기 바닥을 효율적으로 탐색할 수 있게 해준다. . | . &#44032;&#51473;&#52824;&#51032; &#52488;&#44592;&#54868; . 가장 일반적인 방법은 가우스 분포로부터 랜덤값을 생성하여 초깃값으로 삼는 방법. 가우스 분포의 표준편차의 선택은 학습에 결과에도 영향을 미친다. 표준편차를 그게 잡고 초깃값을 들쭉날쭉하게 하면 초기 학습은 빠르게 진행되지만 오차함수의 감소가 일찌감치 멈춰버리는 경향이 있음 | . | . 바이어스의 초깃값은 통상 0으로 결정 | 유닛의 활성화 함수로 로지스틱 함수 등 치역에 상하한이 있는 함수를 쓰는 경우 표준편차의 범위도 필연적으로 제약을 받는다. . 표준편차의 값이 적절하지 못하면 활성화 함수의 출력이 그 치역 내에서 적절한 범위로 들어오지 못하기 때문. . 표준편차가 너무 작으면 0으로 채운 초깃값을 사용하는 것과 차이가 없게됨. | 표준편차가 너무 크면 유닛의 입력에 대한 총합이 너무 들쭉날쭉해서 유닛의 출력이 치역의 최댓값 혹은 최솟값을 갖는 경우가 너무 많음 | | . 이 외에도 사전훈련을 통해 초깃값을 정하는 방법이 있으며 딥 뉴럴넷에서는 이쪽이 더 일반적 | . &#49368;&#54540;&#51032; &#49692;&#49436; . 확률적 경사 하강법을 쓸 때 훈련 샘플을 어떤 순서로 추출할 것인지에 대해 자유롭게 선택할 수 있다. . | 일반적으로는 신경망이 &#39;익숙하지 않은&#39; 샘플을 먼저 보이는 전략이 학습에 가장 유리하다고 할 수 있다. . 이 방법은 특히 유형별로 샘플 수에 편차가 있는 클래스 분류 문제에 좋은 결과를 보이곤 한다. . 하지만 훈련 데이터 중에 오답(잘못된 목표출력)이 포함된 경우에는 오히려 역효과가 나니 주의가 필요하다. . 그러나 딥 뉴럴넷을 대상으로 하는 최근의 케이스에서는 클래스 간의 샘플 수에 편차가 없도록 셔플링한 샘플을 기계적으로 조합하여 미니배치를 구성, . 미니배치를 구성한 순서대로 반복하여 신경망에 입력하는 경우가 많다. . 대규모 신경망과 대량의 훈련 샘플을 어떻게 효율적으로 다룰지에 중점을 더 두는 경우가 많다고 할 수 있다. . | . | .",
            "url": "https://star77sa.github.io/TIL-Blog/dl/2021/07/29/DeepLearning.html",
            "relUrl": "/dl/2021/07/29/DeepLearning.html",
            "date": " • Jul 29, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "마크다운",
            "content": "&#51060;&#48120;&#51648; &#50629;&#47196;&#46300; . # &lt;img src=&quot;my_icons/리스트.jpg&quot;&gt; . . 크기조정 | . # &lt;img src=&quot;my_icons/리스트.jpg&quot; width=&quot;300&quot; height=&quot;300&quot;&gt; . . &#51452;&#49437;&#52376;&#47532; . # &lt;--! 주석처리 할 문장 --&gt; . &#49688;&#49885; . # $$ 수식 $$ . $$ u_1 = w_{11}x_1 + w_{12}x_2 + w_{13}x_3 + w_{14}x_4 + b_1 $$ . 여기서, 내리는 숫자가 2개인경우 w_11이 아니라 w{11}로 써주어야함! . &#49688;&#49885; &#46916;&#50612;&#50416;&#44592; . # , 한칸 # ; 두칸 # quad 네칸 # qquad 여덟칸 . &#54364;&#47564;&#46308;&#44592; . # |제목|내용|설명| # |||| # |테스트1|테스트2|테스트3| # |테스트1|테스트2|테스트3| # |테스트1|테스트2|테스트3| . 제목 내용 설명 . 테스트1 | 테스트2 | 테스트3 | . 테스트1 | 테스트2 | 테스트3 | . 테스트1 | 테스트2 | 테스트3 | . italic , bold . # *내용* . 내용 . # **내용** . 내용 . # ***내용*** . 내용 .",
            "url": "https://star77sa.github.io/TIL-Blog/markdown/2021/07/27/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4.html",
            "relUrl": "/markdown/2021/07/27/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4.html",
            "date": " • Jul 27, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Numpy_Tutorial",
            "content": ". https://docs.scipy.org/doc/numpy-1.15.0/user/quickstart.html | https://github.com/ndb796/Python-Data-Analysis-and-Image-Processing-Tutorial | . https://www.machinelearningplus.com/python/numpy-tutorial-part1-array-python-examples/ | http://web.mit.edu/dvp/Public/numpybook.pdf | https://docs.scipy.org/doc/numpy-1.11.0/numpy-user-1.11.0.pdf | . . The Basic . import numpy as np . NumPy’s main object = the homogeneous multidimensional array. | In NumPy dimensions are called axes. | . 1차원 [1, 2, 1] 2차원 [[ 1., 0., 0.], [ 0., 1., 2.]] . . NumPy’s array class is called ndarray. | numpy.array is not the same as the Standard Python Library class array. 파이썬의 array는 1차원만을 다룬다. | . | . The more important attributes of an ndarray object are: ndarray.ndim : 넘파이의 차원 | ndarray.shape : 넘파이의 모양 (n, m) | ndarray.size : This is equal to the product of the elements of shape. (n*m) | ndarray.dtype : array안 요소의 타입 | ndarray.itemsize : array안 요소들의 사이즈(bytes) | ndarray.data : Normally, we won’t need to use this attribute because we will access the elements in an array using indexing facilities. | . | . An example . &gt;&gt;&gt; import numpy as np &gt;&gt;&gt; a = np.arange(15).reshape(3, 5) &gt;&gt;&gt; a array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]]) &gt;&gt;&gt; a.shape (3, 5) &gt;&gt;&gt; a.ndim 2 &gt;&gt;&gt; a.dtype.name &#39;int64&#39; &gt;&gt;&gt; a.itemsize 8 &gt;&gt;&gt; a.size 15 &gt;&gt;&gt; type(a) &lt;type &#39;numpy.ndarray&#39;&gt; &gt;&gt;&gt; b = np.array([6, 7, 8]) &gt;&gt;&gt; b array([6, 7, 8]) &gt;&gt;&gt; type(b) &lt;type &#39;numpy.ndarray&#39;&gt; . Array Creation . you can create an array from a regular Python list or tuple using the array function. . &gt;&gt;&gt; a = np.array([2,3,4]) &gt;&gt;&gt; a array([2, 3, 4]) . 2차원 array . &gt;&gt;&gt; b = np.array([(1.5,2,3), (4,5,6)]) &gt;&gt;&gt; b array([[ 1.5, 2. , 3. ], [ 4. , 5. , 6. ]]) . The function zeros creates an array full of zeros, . &gt;&gt;&gt; np.zeros( (3,4) ) array([[ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.]]) &gt;&gt;&gt; np.ones( (2,3,4), dtype=np.int16 ) # dtype can also be specified array([[[ 1, 1, 1, 1], [ 1, 1, 1, 1], [ 1, 1, 1, 1]], [[ 1, 1, 1, 1], [ 1, 1, 1, 1], [ 1, 1, 1, 1]]], dtype=int16) . To create sequences of numbers, NumPy provides a function analogous to range that returns arrays instead of lists. . &gt;&gt;&gt; np.arange( 10, 30, 5 ) array([10, 15, 20, 25]) &gt;&gt;&gt; np.arange( 0, 2, 0.3 ) # it accepts float arguments array([ 0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8]) &gt;&gt;&gt; np.linspace( 0, 2, 9 ) # 9 numbers from 0 to 2 array([ 0. , 0.25, 0.5 , 0.75, 1. , 1.25, 1.5 , 1.75, 2. ]) . other method . array, zeros, zeros_like, ones, ones_like, empty, empty_like, arange, linspace, numpy.random.rand, numpy.random.randn, fromfunction, fromfile . Printing Arrays . 1차원은 행으로, 2,3 차원은 행렬로 표현된다. . &gt;&gt;&gt; a = np.arange(6) # 1d array &gt;&gt;&gt; print(a) [0 1 2 3 4 5] &gt;&gt;&gt; b = np.arange(12).reshape(4,3) # 2d array &gt;&gt;&gt; print(b) [[ 0 1 2] [ 3 4 5] [ 6 7 8] [ 9 10 11]] &gt;&gt;&gt; c = np.arange(24).reshape(2,3,4) # 3d array &gt;&gt;&gt; print(c) [[[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] [[12 13 14 15] [16 17 18 19] [20 21 22 23]]] . Basic Operations . &gt;&gt;&gt; a = np.array( [20,30,40,50] ) &gt;&gt;&gt; b = np.arange( 4 ) &gt;&gt;&gt; b array([0, 1, 2, 3]) &gt;&gt;&gt; c = a-b &gt;&gt;&gt; c array([20, 29, 38, 47]) &gt;&gt;&gt; b**2 array([0, 1, 4, 9]) &gt;&gt;&gt; 10*np.sin(a) array([ 9.12945251, -9.88031624, 7.4511316 , -2.62374854]) &gt;&gt;&gt; a&lt;35 array([ True, True, False, False]) . *는 각각의 요소끼리 곱하고 @, dot은 행렬곱을 한다. . &gt;&gt;&gt; A = np.array( [[1,1], ... [0,1]] ) &gt;&gt;&gt; B = np.array( [[2,0], ... [3,4]] ) &gt;&gt;&gt; A * B # elementwise product array([[2, 0], [0, 4]]) &gt;&gt;&gt; A @ B # matrix product array([[5, 4], [3, 4]]) &gt;&gt;&gt; A.dot(B) # another matrix product array([[5, 4], [3, 4]]) . += , *= 연산 . &gt; &gt;&gt; a = np.ones((2,3), dtype=int) &gt;&gt;&gt; b = np.random.random((2,3)) &gt;&gt;&gt; a *= 3 &gt;&gt;&gt; a array([[3, 3, 3], [3, 3, 3]]) &gt;&gt;&gt; b += a &gt;&gt;&gt; b array([[ 3.417022 , 3.72032449, 3.00011437], [ 3.30233257, 3.14675589, 3.09233859]]) &gt;&gt;&gt; a += b # b is not automatically converted to integer type Traceback (most recent call last):...TypeError: Cannot cast ufunc add output from dtype(&#39;float64&#39;) to dtype(&#39;int64&#39;) with casting rule &#39;same_kind&#39; . . 전체합, 최솟값, 최댓값 등을 구할때는 ndarray 자체 메소드를 사용하여야한다. . &gt;&gt;&gt; a = np.random.random((2,3)) &gt;&gt;&gt; a array([[ 0.18626021, 0.34556073, 0.39676747], [ 0.53881673, 0.41919451, 0.6852195 ]]) &gt;&gt;&gt; a.sum() 2.5718191614547998 &gt;&gt;&gt; a.min() 0.1862602113776709 &gt;&gt;&gt; a.max() 0.6852195003967595 . 연산들은 전체를 기준으로 하지만, axis를 추가해주면 각 행이나 열마다 함수를 적용할 수 있다. . &gt;&gt;&gt; b array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) &gt;&gt;&gt; &gt;&gt;&gt; b.sum(axis=0) # sum of each column array([12, 15, 18, 21]) &gt;&gt;&gt; &gt;&gt;&gt; b.min(axis=1) # min of each row array([0, 4, 8]) &gt;&gt;&gt; &gt;&gt;&gt; b.cumsum(axis=1) # cumulative sum along each row 누적합 array([[ 0, 1, 3, 6], [ 4, 9, 15, 22], [ 8, 17, 27, 38]]) . 서로 다른 형태의 Numpy 연산 | . . array1 = np.arange(4).reshape(2,2) array2 = np.arange(2) array3 = array1 + array2 print(array3) . [[0 2] [2 4]] . 브로드캐스트 | . . 마스킹 연산 | . . Numpy 원소의 값을 조건에 따라 바꿀 때 다음과 같이한다. . 반복문을 이용할 때보다 매우 빠르게 동작한다. . 대체로 이미지 처리(Image Processing)에서 자주 활용된다. . array1 = np.arange(16).reshape(4,4) print(array1) array2 = array1 &lt; 10 print(array2) array1[array2] = 100 print(array1) . [[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11] [12 13 14 15]] [[ True True True True] [ True True True True] [ True True False False] [False False False False]] [[100 100 100 100] [100 100 100 100] [100 100 10 11] [ 12 13 14 15]] . Universal Functions . NumPy provides familiar mathematical functions such as sin, cos, and exp. In NumPy, these are called “universal functions”(ufunc). | . &gt;&gt;&gt; B = np.arange(3) &gt;&gt;&gt; B array([0, 1, 2]) &gt;&gt;&gt; np.exp(B) array([ 1. , 2.71828183, 7.3890561 ]) &gt;&gt;&gt; np.sqrt(B) array([ 0. , 1. , 1.41421356]) &gt;&gt;&gt; C = np.array([2., -1., 4.]) &gt;&gt;&gt; np.add(B, C) array([ 2., 0., 6.]) . other method . all, any, apply_along_axis, argmax, argmin, argsort, average, bincount, ceil, clip, conj, corrcoef, cov, cross, cumprod, cumsum, diff, dot, floor, inner, inv, lexsort, max, maximum, mean, median, min, minimum, nonzero, outer, prod, re, round, sort, std, sum, trace, transpose, var, vdot, vectorize, where . Indexing, Slicing and Iteration . 1차원 array는 파이썬의 리스트와 같이 인덱싱, 슬라이싱을 할 수 있다, | . Multidimensional arrays can have one index per axis. These indices are given in a tuple separated by commas . 반점을 사이에 둔 튜플 필요 . &gt; &gt;&gt; def f(x,y):... return 10*x+y... &gt; &gt;&gt; b = np.fromfunction(f,(5,4),dtype=int) &gt;&gt;&gt; b array([[ 0, 1, 2, 3], [10, 11, 12, 13], [20, 21, 22, 23], [30, 31, 32, 33], [40, 41, 42, 43]]) &gt;&gt;&gt; b[2,3] 23 &gt;&gt;&gt; b[0:5, 1] # each row in the second column of barray([ 1, 11, 21, 31, 41]) &gt; &gt;&gt; b[ :,1] # equivalent to the previous examplearray([ 1, 11, 21, 31, 41]) &gt; &gt;&gt; b[1:3, : ] # each column in the second and third row of barray([[10, 11, 12, 13],[20, 21, 22, 23]]) . | . Iterating over multidimensional arrays is done with respect to the first axis: . &gt; &gt;&gt; for row in b:print(row) [0 1 2 3] [10 11 12 13] [20 21 22 23] [30 31 32 33] [40 41 42 43] . However, if one wants to perform an operation on each element in the array, one can use the flat attribute which is an iterator over all the elements of the array: . &gt; &gt;&gt; for element in b.flat:print(element) 0 1 2 3 10 11 12 13 20 21 22 23 30 31 32 33 40 41 42 43 . other method . Indexing, Indexing (reference), newaxis, ndenumerate, indices . . Shape Manipulation . Changing the shape of an array . 모양을 바꾸는 3가지 방법 ravel(), reshape(), T. 하지만 원래의 array는 바뀌지않는다! | . &gt;&gt;&gt; a.shape (3, 4) &gt;&gt;&gt; a.ravel() # returns the array, flattened array([ 2., 8., 0., 6., 4., 5., 1., 1., 8., 9., 3., 6.]) &gt;&gt;&gt; a.reshape(6,2) # returns the array with a modified shape array([[ 2., 8.], [ 0., 6.], [ 4., 5.], [ 1., 1.], [ 8., 9.], [ 3., 6.]]) &gt;&gt;&gt; a.T # returns the array, transposed array([[ 2., 4., 8.], [ 8., 5., 9.], [ 0., 1., 3.], [ 6., 1., 6.]]) &gt;&gt;&gt; a.T.shape (4, 3) &gt;&gt;&gt; a.shape (3, 4) . 이번엔 원래의 array를 바꾸는 메소드 resize&gt;&gt;&gt; a array([[ 2., 8., 0., 6.], [ 4., 5., 1., 1.], [ 8., 9., 3., 6.]]) &gt;&gt;&gt; a.resize((2,6)) &gt;&gt;&gt; a array([[ 2., 8., 0., 6., 4., 5.], [ 1., 1., 8., 9., 3., 6.]]) . | . Stacking together different arrays . 행이나 열로 여러개의 array를 쌓을 수 있다.&gt;&gt;&gt; a = np.floor(10*np.random.random((2,2))) &gt;&gt;&gt; a array([[ 8., 8.], [ 0., 0.]]) &gt;&gt;&gt; b = np.floor(10*np.random.random((2,2))) &gt;&gt;&gt; b array([[ 1., 8.], [ 0., 4.]]) &gt;&gt;&gt; np.vstack((a,b)) array([[ 8., 8.], [ 0., 0.], [ 1., 8.], [ 0., 4.]]) &gt;&gt;&gt; np.hstack((a,b)) array([[ 8., 8., 1., 8.], [ 0., 0., 0., 4.]]) . | . 가로축으로 합치고 싶을 때 | . array1 = np.array([1,2,3]) array2 = np.array([4,5,6]) array3 = np.concatenate([array1, array2]) print(array3.shape) print(array3) . (6,) [1 2 3 4 5 6] . 세로축으로 합치고 싶을 때 | . array1 = np.arange(4).reshape(1,4) array2 = np.arange(8).reshape(2,4) print(array1) print(array2) array3 = np.concatenate([array1, array2], axis = 0) # axis = 0 이 추가됨! print(array3) . [[0 1 2 3]] [[0 1 2 3] [4 5 6 7]] [[0 1 2 3] [0 1 2 3] [4 5 6 7]] . other method . hstack, vstack, column_stack, concatenate, c_, r_ . Splitting one array into several smaller ones . 각 행을 원하는 갯수로 나누어준다. | . &gt;&gt;&gt; a = np.floor(10*np.random.random((2,12))) &gt;&gt;&gt; a array([[ 9., 5., 6., 3., 6., 8., 0., 7., 9., 7., 2., 7.], [ 1., 4., 9., 2., 2., 1., 0., 6., 2., 2., 4., 0.]]) &gt;&gt;&gt; np.hsplit(a,3) # Split a into 3 [array([[ 9., 5., 6., 3.], [ 1., 4., 9., 2.]]), array([[ 6., 8., 0., 7.], [ 2., 1., 0., 6.]]), array([[ 9., 7., 2., 7.], [ 2., 2., 4., 0.]])] . split 이용 | . import numpy as np array = np.arange(8).reshape(2, 4) left, right = np.split(array, [2], axis=1) # array에서 3번째열을 기준으로 나눈다. print(left.shape) print(right.shape) print(array) print(left) . (2, 2) (2, 2) [[0 1 2 3] [4 5 6 7]] [[0 1] [4 5]] . . Copies and VIews . 복사와 관련해서 초보자들이 실수하는 3가지 | . No copy at All . &gt;&gt;&gt; a = np.arange(12) &gt;&gt;&gt; b = a # no new object is created &gt;&gt;&gt; b is a # a and b are two names for the same ndarray object True &gt;&gt;&gt; b.shape = 3,4 # changes the shape of a &gt;&gt;&gt; a.shape (3, 4) . b라는 새로운 객체가 생긴게 아니라 b가 곧 a . View or Shallow Copy . View메서드는 동일한 데이터를 보는 새 배열 개체를 만든다.&gt;&gt;&gt; c = a.view() &gt;&gt;&gt; c is a False &gt;&gt;&gt; c.base ​is a # c is a view of the data owned by a True &gt;&gt;&gt; c.flags.owndata False &gt;&gt;&gt; &gt;&gt;&gt; c.shape ​= 2,6 # a&#39;s shape doesn&#39;t change &gt;&gt;&gt; a.shape (3, 4) &gt;&gt;&gt; c[0,4] ​= 1234 # a&#39;s data changes &gt;&gt;&gt; a array([[ 0, 1, 2, 3], [1234, 5, 6, 7], [ 8, 9, 10, 11] . | . 배열을 슬라이싱하면 배열의 뷰가 반환된다.&gt; &gt;&gt; s = a[ :, 1:3] # spaces added for clarity; could also be written &quot;s = a[:,1:3]&quot;&gt; &gt;&gt; s[:] = 10 # s[:] is a view of s. Note the difference between s=10 and s[:]=10&gt;&gt;&gt; a array([[ 0, 10, 10, 3], [1234, 10, 10, 7], [ 8, 10, 10, 11]]) . | . Deep Copy . copy 메서드는 배열과 그 데이터의 완전한 복사를 만들어준다. | . &gt;&gt;&gt; d = a.copy() # a new array object with new data is created &gt;&gt;&gt; d is a False &gt;&gt;&gt; d.base is a # d doesn&#39;t share anything with a False &gt;&gt;&gt; d[0,0] = 9999 &gt;&gt;&gt; a array([[ 0, 10, 10, 3], [1234, 10, 10, 7], [ 8, 10, 10, 11]]) . Functions and Methods Overview . . Fancy indexing and index tricks . &gt;&gt;&gt; a = np.arange(12)**2 # the first 12 square numbers &gt;&gt;&gt; i = np.array( [ 1,1,3,8,5 ] ) # an array of indices &gt;&gt;&gt; a[i] # the elements of a at the positions i array([ 1, 1, 9, 64, 25]) &gt;&gt;&gt; &gt;&gt;&gt; j = np.array( [ [ 3, 4], [ 9, 7 ] ] ) # a bidimensional array of indices &gt;&gt;&gt; a[j] # the same shape as j array([[ 9, 16], [81, 49]]) . + . .",
            "url": "https://star77sa.github.io/TIL-Blog/python/2021/07/27/Numpy.html",
            "relUrl": "/python/2021/07/27/Numpy.html",
            "date": " • Jul 27, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Python BOJ insight",
            "content": "&#47928;&#51088;&#50676; . 어떠한 단어에서 특정 문자가 있는지 위치를 찾을 때 . &#39;word&#39;.find(&#39;r&#39;) . &#39;word&#39;.index(&#39;r&#39;) . 을 사용한다. 차이점은 find는 찾고싶은 문자가 없으면 -1을 출력하고, index는 오류가 출력된다. . | . input() 합수는 str을 받는 함수이다. 숫자를 넣어도 str | . input() 대신 sys.stdin.readline() 사용하는 이유 반복문으로 여러 줄을 입력받는 상황에서는 반드시 sys.stdin.readline()을 사용해야 시간초과가 발생하지 않는다. . ※ readline()은 앞 뒤에 개행문자가 포함된다. 앞 뒤 공백을 제거하기 위해 뒤에 추가로 .strip()을 적어주자. . 띄어쓰기로 값을 구분해야 할때는 sys.stdin.readline().split()을 사용한다. . 주피터에서는 sys.stdin.readline() 작동하지않는다. input()으로 풀고 제출시에만 사용하자 . | . 특정 단어의 개수를 셀 때 . word = &#39;ljes=njak&#39;에서 &#39;nj&#39;의 개수를 찾으려면 . word.count(&#39;nj&#39;)를 치면된다. . | . 10의자리, 1의자리 문제 몫(//), 나머지(%)이용해서 풀기 . A // B 를 써야할 것 같은 문제 math.ceil(A/B) 고려할 것. . | . 40.0 같은 실수에서 소수점 아래까지 나타내고 싶으면 포맷팅을 사용하자. value = &quot;%.3f&quot; % 40.0 | . print()는 기본적으로 출력 이후에 줄 바꿈을 수행한다. 줄 바꿈을 원치 않는 경우 &#39;end&#39; 속성을 이용할 수 있다. | . &#47532;&#49828;&#53944; . 리스트에서 list.count( * ) 하면 *값의 개수를 찾아준다. . | 집합(set)는 중복된 원소를 가지지 않기에 list를 set로 바꿨다가 다시 list로 바꾸면 중복이 제거된다! . | . 정렬1 : sorted(list()) . 정렬2 : list().sort() . 1번은 새로운 리스트가 만들어지고, 2번은 기존의 리스트를 정렬시켜서 대체시킨다. . | 정렬에서 값이 리스트일 때, 정렬 중요도 설정 . A.sort(key = lambda x : x[1]) . 2번째 원소로 정렬 후 1번째 원소로 정렬? . A.sort(key = lambda x : (x[1], x[0])) . 2번째 원소로 내림차순 정렬 후 1번째 원소로 오름차순 정렬? . A.sort(key = lambda x : (-x[1], x[0])) . | . list 맨 마지막 수를 없앨 때 . list.remove(list[-1])하면 탐색 후 제거. . del list[-1]하면 맨 뒤를 바로 제거! . | . 리스트를 복사하고 싶을 때A = [1, 2, 3] temp = A . 라고 하면 참조가 된다. 복사만 하려면 슬라이싱을 이용하자. temp = A[:] . | . N x M 의 이중 배열을 만들고 싶을 때 리스트 컴프리헨션 이용. . 좋은 예시 : arr = [ [0]*m for _ in range(n)] . 잘못된 예시 : arr = [ [0]*m ] * n &lt;-- 전체 리스트 안에 포함된 각 리스트가 모두 같은 객체로 인식 된다. . | . 리스트에 홀수만 담고싶을 때, arr = [ i for i in range(20) if i%2 == 1] 이렇게 조건도 달아줄 수 있다. | . 리스트 관련 메서드 | . . &#46988;&#45796; &#54364;&#54788;&#49885; . 람다 표현식을 이용하면 함수를 간단하게 작성할 수 있다. 특정한 기능을 수행하는 함수를 한 줄에 작성할 수 있다는 점이 특징이다. | . | . def add(a, b): return a+b # 일반적인 add() 메서드 사용 print(add(3, 7)) # 람다 표현식으로 구현한 add() 메서드 print((lambda a, b : a + b)(3, 7)) . 10 10 . &#46357;&#49492;&#45320;&#47532; . 파이썬의 딕셔너리는 해시테이블을 이용하므로 데이터 조회, 수정에 있어서 O(1)의 시간에 처리가 가능하다. | . &#51312;&#44148;&#47928; . Python의 and . A and B 에서, A가 거짓일 경우, B는 보지않고 거짓인 A를 출력. False를 리턴해주지 않는다. . A and B 에서 A가 참이다? B는 확인하지 않고 그냥 B를 출력해준다. 참이면 참인대로, 거짓이면 거짓인대로 . | . Python의 or 둘 중에 하나만 참이어도 참이기에 A or B 에서 A가 참일경우 B는 확인하지않고 그냥 A를 출력한다. . 마찬가지로 A가 거짓인경우 B를 확인안하고 바로 리턴해준다. . 결국 파이썬에선 거짓일 때 False가 아니라 거짓인 값 자체를 반환해준다. . | . 1 == 1 and 2 이렇게하면 2가 나오고 . (1==1) and (1==2) 이렇게 하면 False가 나온다. . 논리연산자는 각각의 요소마다 써주어야 한다! . | . &#39;C&#39; == &#39;A&#39; or &#39;C&#39; == &#39;B&#39; or &#39;C&#39; == &#39;C&#39; . 0 or 0 or 1 =&gt; 1 =&gt; True . | &#39;C&#39; == (&#39;A&#39; or &#39;B&#39; or &#39;C&#39;) . &#39;C&#39; == (1 or 1 or 1) =&gt; &#39;C&#39; == 1 =&gt; False . | &#39;C&#39; == &#39;A&#39; or &#39;B&#39; or &#39;C&#39; . False or &#39;B&#39; or &#39;C&#39;에서 &#39;B&#39;는 바로 참으로 인식, &#39;B&#39;를 출력 . | . in 연산자와 not in 연산자 . 리스트, 튜플, 문자열, 딕셔너리 모두 사용 가능 . x in 리스트 : 리스트 안에 x가 들어가 있을 때 참(True) . x not in 문자열 : 문자열 안에 x가 들어가 있지 않을 때 참(True) . | . &#51204;&#50669;&#48320;&#49688;, &#51648;&#50669;&#48320;&#49688; . count = 0 def A(~): count += 1 A(~) . 이렇게 해도 count 는 증가하지않는다. 함수안의 count는 지역변수기 때문이다. . &#53364;&#47000;&#49828; . Class stack(): ~~~~~ ~~~~~ . 이런 클래스가 있다면 st = stack 이 아니라 st = stack() 이렇게 해줘야 인스턴스가 생성됨. . st = stack 을 하면 st가 stack 클래스의 기능을 한다.(별명) . &#49892;&#51204;&#50640;&#49436; &#50976;&#50857;&#54620; &#54364;&#51456; &#46972;&#51060;&#48652;&#47084;&#47532; . 내장 함수 : . 기본 입출력 함수부터 정렬 함수까지 기본적인 함수들을 제공한다. . 파이썬 프로그램을 작성할 때 없어서는 안되는 필수적인 기능을 포함하고 있다. . | itertools : . 파이썬에서 반복되는 형태의 데이터를 처리하기 위한 유용한 기능들을 제공한다. . 특히 순열과 조합 라이브러리는 코딩 테스트에서 자주 사용된다. . | heapq : . 힙(Heap) 자료구조를 제공한다. . 일반적으로 우선순위 큐 기능을 구현하기 위해 사용된다. . | bisect : . 이진 탐색(Binary Search) 기능을 제공한다. . | collections : . 덱(deque), 카운터(Counter) 등의 유용한 자료구조를 포함한다. . | math : . 필수적인 수학적 기능을 제공한다. . 팩토리얼, 제곱근, 최대공약수(GCD), 삼각함수 관련 함수부터 파이(pi)와 같은 상수를 포함한다. . | . ETC . 시간복잡도 생각하며 알고리즘 짤 것 | . 주피터 ctrl + / 누르면 그 줄 주석처리! | . 소수 / 에라토스테네스의 채 공부해볼 것. 구현 | . for i in range(n) 에서 맨 끝 1개를 덜 포함해서 종종 런타임에러가 일어났다. 주의 | . while stack and i&lt;N: 이거 하니까 인덱스 오류가 안났다. (백준 # 17298 오큰수) . 내가 했던건 while i&lt;N: . 차이점 ?? . | .",
            "url": "https://star77sa.github.io/TIL-Blog/python/2021/07/25/%EB%B0%B1%EC%A4%80.html",
            "relUrl": "/python/2021/07/25/%EB%B0%B1%EC%A4%80.html",
            "date": " • Jul 25, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "머신러닝 야학 - 머신러닝1",
            "content": "&#44592;&#44228;&#54617;&#49845;(machine learning) . . &#51648;&#46020;&#54617;&#49845; (supervised learning) . &#48516;&#47448; Classification . 범주형 변수를 예측하고 싶을 때 사용 | . &#54924;&#44480; Regression . 수치형 변수를 예측하고 싶을때 사용 | . &#48708;&#51648;&#46020;&#54617;&#49845; (unsupervised learning) . - 관측치(행)을 그룹핑 해주는 것 -&gt; 군집화 - 특성(열)을 그룹핑 해주는 것 -&gt; 연관규칙 . &#44400;&#51665;&#54868; Clustering . 비슷한 것들을 찾아서 그룹을 만드는 것 | . 지도학습의 분류와는 구분된다. 어떤 대상들을 구분해서 그룹을 만드는 것 - 군집화 | 어떤 대상이 어떤 그룹에 속하는지를 판단하는 것 - 분류 | . | . &#50672;&#44288; Association rule learing . 서로 연관된 특징(열)을 찾아내는 것 | 장바구니 분석 | . &#48320;&#54872; . &#44053;&#54868;&#54617;&#49845; (Reinforcement Learning) . 지도학습이 배움을 통해서 실력을 키우는 것이라면 강화학습은 일단 해보면서 경험을 통해서 실력을 키워가는 것 . 그 행동의 결과가 자신에게 유리한 것이었다면 상을 받고, 불리한 것이었다면 벌을 받는 것 | . 이 과정을 매우 많이 반복하면 더 좋은 답을 찾아낼 수 있다는 것이 강화학습의 기본 아이디어 | .",
            "url": "https://star77sa.github.io/TIL-Blog/ml/2021/07/15/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%95%BC%ED%95%99-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D1.html",
            "relUrl": "/ml/2021/07/15/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%95%BC%ED%95%99-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D1.html",
            "date": " • Jul 15, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "CatBoost",
            "content": "CatBoost &#53945;&#51669; . Great quality without parameter tuning . Reduce time spent on parameter tuning, because CatBoost provides great results with default parameters | . Categorical features support . Improve your training results with CatBoost that allows you to use non-numeric factors, instead of having to pre-process your data or spend time and effort turning it to numbers. | . Fast and scalable GPU version . Train your model on a fast implementation of gradient-boosting algorithm for GPU. Use a multi-card configuration for large datasets. | . Improved accuracy . Reduce overfitting when constructing your models with a novel gradient-boosting scheme. | . Fast prediction . Apply your trained model quickly and efficiently even to latency-critical tasks using CatBoost&#39;s model applier | . Default Parameter (CatBoost_Regressor) . class CatBoostRegressor(iterations=None, learning_rate=None, depth=None, l2_leaf_reg=None, model_size_reg=None, rsm=None, loss_function=&#39;RMSE&#39;, border_count=None, feature_border_type=None, per_float_feature_quantization=None, input_borders=None, output_borders=None, fold_permutation_block=None, od_pval=None, od_wait=None, od_type=None, nan_mode=None, counter_calc_method=None, leaf_estimation_iterations=None, leaf_estimation_method=None, thread_count=None, random_seed=None, use_best_model=None, best_model_min_trees=None, verbose=None, silent=None, logging_level=None, metric_period=None, ctr_leaf_count_limit=None, store_all_simple_ctr=None, max_ctr_complexity=None, has_time=None, allow_const_label=None, one_hot_max_size=None, random_strength=None, name=None, ignored_features=None, train_dir=None, custom_metric=None, eval_metric=None, bagging_temperature=None, save_snapshot=None, snapshot_file=None, snapshot_interval=None, fold_len_multiplier=None, used_ram_limit=None, gpu_ram_part=None, pinned_memory_size=None, allow_writing_files=None, final_ctr_computation_mode=None, approx_on_full_history=None, boosting_type=None, simple_ctr=None, combinations_ctr=None, per_feature_ctr=None, ctr_target_border_count=None, task_type=None, device_config=None, devices=None, bootstrap_type=None, subsample=None, sampling_unit=None, dev_score_calc_obj_block_size=None, max_depth=None, n_estimators=None, num_boost_round=None, num_trees=None, colsample_bylevel=None, random_state=None, reg_lambda=None, objective=None, eta=None, max_bin=None, gpu_cat_features_storage=None, data_partition=None, metadata=None, early_stopping_rounds=None, cat_features=None, grow_policy=None, min_data_in_leaf=None, min_child_samples=None, max_leaves=None, num_leaves=None, score_function=None, leaf_estimation_backtracking=None, ctr_history_unit=None, monotone_constraints=None, feature_weights=None, penalties_coefficient=None, first_feature_use_penalties=None, model_shrink_rate=None, model_shrink_mode=None, langevin=None, diffusion_temperature=None, posterior_sampling=None, boost_from_average=None) . &#47784;&#45944; Feature &#51473;&#50836;&#46020; &#53456;&#49353; . In short, you can do something like . pd.DataFrame({&#39;feature_importance&#39;: model.get_feature_importance(train_pool), &#39;feature_names&#39;: x_val.columns}).sort_values(by=[&#39;feature_importance&#39;], ascending=False) . you can also make a function like . def plot_feature_importance(importance,names,model_type): #Create arrays from feature importance and feature names feature_importance = np.array(importance) feature_names = np.array(names) #Create a DataFrame using a Dictionary data={&#39;feature_names&#39;:feature_names,&#39;feature_importance&#39;:feature_importance} fi_df = pd.DataFrame(data) #Sort the DataFrame in order decreasing feature importance fi_df.sort_values(by=[&#39;feature_importance&#39;], ascending=False,inplace=True)) #Define size of bar plot plt.figure(figsize=(10,8)) #Plot Searborn bar chart sns.barplot(x=fi_df[&#39;feature_importance&#39;], y=fi_df[&#39;feature_names&#39;]) #Add chart labels plt.title(model_type + &#39;FEATURE IMPORTANCE&#39;) plt.xlabel(&#39;FEATURE IMPORTANCE&#39;) plt.ylabel(&#39;FEATURE NAMES&#39;) . and plot the feature importance from different boosting algorithm . #plot the xgboost result plot_feature_importance(xgb_model.feature_importances_,train.columns,&#39;XG BOOST&#39;) #plot the catboost result plot_feature_importance(cb_model.get_feature_importance(),train.columns,&#39;CATBOOST&#39;) . &#48276;&#51452;&#54805; &#48320;&#49688; &#51648;&#51221;&#54616;&#44592; . x1_train = train[[&#39;Numerical variable&#39;, ... , &#39;Categorical variable&#39;]] y1_train = train[&#39;예측하고 싶은 값&#39;] x1_test = train[[&#39;Numerical variable&#39;, ... , &#39;Categorical variable&#39;]] categorical_features_indices1 = np.where(x1_train.dtypes == np.object)[0] # 이걸로 범주형 변수를 지정 from catboost import CatBoostRegressor cat = CatBoostRegressor(loss_function=&#39;MAE&#39;) model1 = cat model1.fit(x1_train, y1_train, cat_features=categorical_features_indices1) # categorical feature 지정. pred1 = model1.predict(x1_test) submission[&#39;예측하고 싶은 값&#39;] = pred1 submission.to_csv(&#39;catcategory2.csv&#39;, index=False) .",
            "url": "https://star77sa.github.io/TIL-Blog/python/analysis/model/2021/07/15/CatBoost.html",
            "relUrl": "/python/analysis/model/2021/07/15/CatBoost.html",
            "date": " • Jul 15, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "데이터 분석 Dacon",
            "content": "2021.06.29 . EDA . &#46972;&#51060;&#48652;&#47084;&#47532; &#48520;&#47084;&#50724;&#44592; . Pandas 와 Scikit-learn 라이브러리를 불러오세요 | . import pandas as pd from sklearn.tree import DecisionTreeRegressor . &#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592; . train.csv 와 test.csv 를 DataFrame 클래스로 불러오세요 | . pd.read_csv() . train = pd.read_csv(&#39;data/train.csv&#39;) test = pd.read_csv(&#39;data/test.csv&#39;) . &#45936;&#51060;&#53552; &#54665;&#50676; &#44079;&#49688; &#44288;&#52272; . shape 를 사용해 데이터 크기를 관찰하세요 | . df.shape . train.shape . (1459, 11) . test.shape . (715, 10) . &#44208;&#52769;&#52824; &#54869;&#51064; . info() 를 사용해 결측치가 있는지 확인하세요. | . df.info() . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1459 entries, 0 to 1458 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 id 1459 non-null int64 1 hour 1459 non-null int64 2 hour_bef_temperature 1457 non-null float64 3 hour_bef_precipitation 1457 non-null float64 4 hour_bef_windspeed 1450 non-null float64 5 hour_bef_humidity 1457 non-null float64 6 hour_bef_visibility 1457 non-null float64 7 hour_bef_ozone 1383 non-null float64 8 hour_bef_pm10 1369 non-null float64 9 hour_bef_pm2.5 1342 non-null float64 10 count 1459 non-null float64 dtypes: float64(9), int64(2) memory usage: 125.5 KB . test.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 715 entries, 0 to 714 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 id 715 non-null int64 1 hour 715 non-null int64 2 hour_bef_temperature 714 non-null float64 3 hour_bef_precipitation 714 non-null float64 4 hour_bef_windspeed 714 non-null float64 5 hour_bef_humidity 714 non-null float64 6 hour_bef_visibility 714 non-null float64 7 hour_bef_ozone 680 non-null float64 8 hour_bef_pm10 678 non-null float64 9 hour_bef_pm2.5 679 non-null float64 dtypes: float64(8), int64(2) memory usage: 56.0 KB . df[&#39;a&#39;].value_counts() . train[&#39;Embarked&#39;].value_counts() . S 644 C 168 Q 77 Name: Embarked, dtype: int64 . df[&#39;a&#39;].unique() . train[&#39;Embarked&#39;].unique() . array([&#39;S&#39;, &#39;C&#39;, &#39;Q&#39;, nan], dtype=object) . pd.Series.plot(kind = &quot;bar&quot;) . 막대 그래프 | index 값이 x축, value값이 y축으로 대응 됩니다. | value_counts()의 결과물을 보여줄 때 유용합니다. | groupby된 결과물을 보여줄 때 유용합니다. | . train.groupby(&#39;Pclass&#39;).mean()[&#39;Survived&#39;].plot(kind=&#39;bar&#39;, rot = 0) # 각도 0 . &lt;AxesSubplot:xlabel=&#39;Pclass&#39;&gt; . pd.Series.plot(kind = &#39;hist&#39;) . 히스토그램: 구간별로 속해있는 row의 개수를 시각화 합니다. | 수치형에서만 가능, 범주는 안됩니다! | . train[&#39;Age&#39;].plot(kind=&#39;hist&#39;, bins = 30) # bins 촘촘한 정도 . &lt;AxesSubplot:ylabel=&#39;Frequency&#39;&gt; . 보조선 =&gt; grid = True . train[&#39;Age&#39;].plot(kind=&#39;hist&#39;, bins = 30, grid=True) # bins 촘촘한 정도 . &lt;AxesSubplot:ylabel=&#39;Frequency&#39;&gt; . pd.DataFrame.plot(x, y, kind = &#39;scatter&#39;) . 산점도: 두 변수간의 관계를 시각화 | . train.plot(x = &#39;Age&#39;, y = &#39;Fare&#39;, kind = &#39;scatter&#39;) . &lt;AxesSubplot:xlabel=&#39;Age&#39;, ylabel=&#39;Fare&#39;&gt; . &#51204;&#52376;&#47532; . &#44208;&#52769;&#52824; &#51204;&#52376;&#47532; . dropna() 를 사용해 train 데이터는 결측치를 제거하고 | fillna() 를 사용해 test 데이터 결측치는 0 으로 대체하세요. | 그리고 결측치의 갯수를 출력하여 확인하세요. | . train = train.dropna() test = test.fillna(0) print(train.isnull().sum()) . id 0 hour 0 hour_bef_temperature 0 hour_bef_precipitation 0 hour_bef_windspeed 0 hour_bef_humidity 0 hour_bef_visibility 0 hour_bef_ozone 0 hour_bef_pm10 0 hour_bef_pm2.5 0 count 0 dtype: int64 . &#44208;&#52769;&#52824; &#45824;&#52404;&#54217;&#44512; . train.fillna({&#39;hour_bef_temperature&#39; : int(train[&#39;hour_bef_temperature&#39;].mean())},inplace=True) . &#44208;&#52769;&#52824; &#45824;&#52404;&#48372;&#44036; . 피쳐의 정보성을 강조하기 위한 보간법 사용 | 데이터의 순서가 시간 순서인 경우에 결측치들을 이전 행(직전시간)과 다음 행(직후시간)의 평균으로 보간하는 것은 상당히 합리적 | 이처럼 데이터에 따라서 결측치를 어떻게 대체할지 결정하는 것은 엔지니어의 결정. . | Python pandas의 interpolate() 를 이용해 결측치를 DataFrame 값에 선형으로 비례하여 보간하는 코드 . train.interpolate(inplace=True) . | . pd.Series.map() . 시리즈 내 값을 변환할 때 사용하는 함수 | 문자열의 경우 숫자형으로 대체해주어야함. 모델에 넣기위해서 | . train = train[&#39;Sex&#39;].map({&#39;male&#39; : 0, &#39;female&#39; : 1}) . &#47784;&#45944; &#54984;&#47144; . train 데이터의 count 피쳐를 뺀 것을 X_train 으로 할당하세요. | train 데이터의 count 피쳐만을 가진 것을 Y_train 으로 할당하세요. | 회귀의사결정나무를 선언하고 fit() 으로 훈련시키세요. | . X_train = train.drop([&#39;count&#39;], axis=1) Y_train = train[&#39;count&#39;] model = DecisionTreeRegressor() model.fit(X_train, Y_train) . DecisionTreeRegressor(ccp_alpha=0.0, criterion=&#39;mse&#39;, max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=&#39;deprecated&#39;, random_state=None, splitter=&#39;best&#39;) . &#53580;&#49828;&#53944; &#54028;&#51068; &#50696;&#52769; . predict() 을 이용해 test data 를 훈련한 모델로 예측한 data array 를 생성하세요. | . pred = model.predict(test) . submission &#54028;&#51068; &#49373;&#49457; . submission.csv 를 불러오세요. | submission df 의 count 피쳐에 예측한 결과를 덧입히세요. | submission df 를 to_csv() 를 이용해 csv 을 생성하세요. *index=False) | . submission = pd.read_csv(&#39;data/submission.csv&#39;) submission[&#39;count&#39;] = pred submission.to_csv(&#39;sub.csv&#39;,index=False) . . 2021.07.24 &#52628;&#44032; . &#45936;&#51060;&#53552; &#49688;&#51221; . 특정열의 특정행 값 바꾸기 | . train[&#39;석식계&#39;][973] = 479.8605851979346 . &#54596;&#53552;&#47553;&#54616;&#50668; &#45936;&#51060;&#53552; &#49688;&#51221; . df.iloc[ , ] . train.iloc[1,2] = 498 . &#45936;&#51060;&#53552; &#52628;&#52636;, &#51064;&#45937;&#49905; . df.groupby() . train.groupby(&#39;년&#39;).mean()[[&#39;중식계&#39;,&#39;석식계&#39;]] . 중식계 석식계 . 년 | | | . 2016 | 932.792952 | 519.418502 | . 2017 | 897.614754 | 459.015822 | . 2018 | 882.903766 | 465.547534 | . 2019 | 850.512195 | 447.336832 | . 2020 | 882.267241 | 432.736468 | . 2021 | 1009.705882 | 396.588235 | . df.query . df.sort_values() . train.query(&#39;월&lt;4 &amp; 월&gt;1 &amp; 년 == 2020&#39;).mean()[&#39;중식계&#39;] . 952.4285714285714 . train.query(&#39;년&gt;2016&#39;).groupby(&#39;월&#39;).mean()[&#39;중식계&#39;].sort_values() . 월 11 815.963415 12 834.473684 8 838.253012 7 839.523256 6 840.333333 5 849.460526 4 880.225000 10 894.666667 9 901.842857 1 934.278351 3 952.829268 2 998.042857 Name: 중식계, dtype: float64 . &#53945;&#51221; &#45936;&#51060;&#53552; &#46300;&#46989; . df.drop() . 특정 행 데이터 드랍 | . train = train.drop(train.index[[204, 224, 244, 262, 281, 306, 327, 346, 366, 392, 410, 828, 853, 872, 890, 912, 932, 955, 973, 993, 1166]]) . 특정 열 데이터 드랍 | . df.drop(&#39;열 이름&#39;, axis=1) .",
            "url": "https://star77sa.github.io/TIL-Blog/analysis/2021/06/29/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D.html",
            "relUrl": "/analysis/2021/06/29/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D.html",
            "date": " • Jun 29, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Python입문",
            "content": ". 0&#52264;&#50896; &#51088;&#47308;&#54805; . int&#54805; . float&#54805; . complex&#54805; . 파이썬 빌트인함수 . https://docs.python.org/3.8/library/functions.html | . 1&#52264;&#50896; &#51088;&#47308;&#54805; . str&#54805; . &#47928;&#51088;&#50676; &#50741;&#49496; . print(&#39;나는 n고경수&#39;) # 한줄띄우기 . 나는 고경수 . print(&#39;나는 t고경수&#39;) # 탭 . 나는 고경수 . print(&#39; &#39;) # 이스케이프 . . print(&#39;나는 n고경수&#39;) . 나는 n고경수 . print(&#39;나는 &#39;고경수 &#39;&#39;) . 나는&#39;고경수&#39; . print(&quot;나는&#39;고경수&#39;&quot;) . 나는&#39;고경수&#39; . &#47928;&#51088;&#50676; &#47700;&#49548;&#46300; . .replace() . S = &#39;xxxxSPAMxxxxSPAMxxxx&#39; S.replace(&#39;SPAM&#39;,&#39;EGGS&#39;) . &#39;xxxxEGGSxxxxEGGSxxxx&#39; . S.replace(&#39;SPAM&#39;,&#39;EGGS&#39;,1) . &#39;xxxxEGGSxxxxSPAMxxxx&#39; . .find() . S = &#39;xxxxSPAMxxxxSPAMxxxx&#39; . where=S.find(&#39;SPAM&#39;) . S[where] . &#39;S&#39; . .join() . &#39;-&#39;.join([&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]) . &#39;a-b-c&#39; . S=&#39;spammy&#39; S[3:5]=&#39;xx&#39; . TypeError Traceback (most recent call last) &lt;ipython-input-178-5854ec3fa955&gt; in &lt;module&gt; 1 S=&#39;spammy&#39; -&gt; 2 S[3:5]=&#39;xx&#39; TypeError: &#39;str&#39; object does not support item assignment . mm을 xx로 바꾸고 싶은데 문자열은 불변리스트라서 바꿀 수 없다. . 전략: 문자열을 잠시 가변객체인 리스트로 바꾼뒤 리스트에서 자유롭게 편집하고 그 다음에 다시 문자열로 만들자. . L=list(S) L . [&#39;s&#39;, &#39;p&#39;, &#39;a&#39;, &#39;x&#39;, &#39;x&#39;, &#39;y&#39;] . L[3:5] . [&#39;x&#39;, &#39;x&#39;] . L[3:5]=[&#39;x&#39;,&#39;x&#39;] L . [&#39;s&#39;, &#39;p&#39;, &#39;a&#39;, &#39;x&#39;, &#39;x&#39;, &#39;y&#39;] . S=&#39;&#39;.join(L) S . &#39;spaxxy&#39; . .split(&#39;,&#39;) . s=&#39;bob,hacker,40&#39; . s.split(&#39;,&#39;) . &#47928;&#51088;&#50676; &#54252;&#47607;&#54021; . &#54364;&#54788;&#49885; (&#47928;&#51088;&#50676;&#50640;&#49436; %&#50672;&#49328;&#51088; &#49324;&#50857;) . &#39;addr: %s to %s&#39; % (&#39;seoul&#39;,&#39;jeonju&#39;) . 잘못된 사용예시1 (리스트는 안됨) . &#39;addr: %s to %s&#39; % [&#39;seoul&#39;,&#39;jeonju&#39;] . TypeError Traceback (most recent call last) &lt;ipython-input-190-8a70b358fe3b&gt; in &lt;module&gt; -&gt; 1 &#39;addr: %s to %s&#39; % [&#39;seoul&#39;,&#39;jeonju&#39;] TypeError: not enough arguments for format string . 잘못된 사용예시2 (묶지않아도 안됨) . &#39;addr: %s to %s&#39; % &#39;seoul&#39;,&#39;jeonju&#39; . TypeError Traceback (most recent call last) &lt;ipython-input-192-0c8ecede52e2&gt; in &lt;module&gt; -&gt; 1 &#39;addr: %s to %s&#39; % &#39;seoul&#39;,&#39;jeonju&#39; TypeError: not enough arguments for format string . % 연산자는 왼쪽에 문자열 오브젝트, 그리고 오른쪽에는 명시적인 튜플이 있어야 연산이 진행된다. . 연산자라는 포인트를 이해하면 아래와 같은 문법도 가능함을 알 수 있다. . s = &#39;addr: %s to %s&#39; s % (&#39;seoul&#39;,&#39;jeonju&#39;) . &#39;addr: seoul to jeonju&#39; . .format &#47700;&#49436;&#46300; . &#39;이름:{},나이:{},성별:{}&#39;.format(&#39;고경수&#39;,&#39;24&#39;,&#39;남&#39;) . &#39;이름:고경수,나이:24,성별:남&#39; . list&#54805; . 메소드 . del a[0] a.append(&#39;a&#39;) a.index(&#39;a&#39;) a.remove(&#39;a&#39;) . &#47532;&#49828;&#53944;&#52980;&#54532;&#47532;&#54760;&#49496; . 리스트를 매우 효율적으로 만드는 테크닉 | for문에 비하여 가지고 있는 장점: (1) 코드가 간단하다. (2) 빠르다. | . x=[2**i for i in [0,1,2,3,4,5]] x . [1, 2, 4, 8, 16, 32] . [i+j for i in [&#39;stat&#39;,&#39;math&#39;] for j in &#39;12345&#39;] . [&#39;stat1&#39;, &#39;stat2&#39;, &#39;stat3&#39;, &#39;stat4&#39;, &#39;stat5&#39;, &#39;math1&#39;, &#39;math2&#39;, &#39;math3&#39;, &#39;math4&#39;, &#39;math5&#39;] . [i+j for i in &#39;XY&#39; for j in &#39;123&#39;] . [&#39;X1&#39;, &#39;X2&#39;, &#39;X3&#39;, &#39;Y1&#39;, &#39;Y2&#39;, &#39;Y3&#39;] . &#47532;&#49828;&#53944;&#51032; &#51473;&#52393; . a=[[11,12,13], [21,22,23], [31,32,33]] . a . [[11, 12, 13], [21, 22, 23], [31, 32, 33]] . a[0][0] . 11 . a[0][1] . 12 . 0 1 2 . 0 | 11 | 12 | 13 | . 1 | 21 | 22 | 23 | . 2 | 31 | 32 | 33 | . 2차원 배열의 느낌!!! . | 1차원 배열을 사실상 다차원배열로 확장할 수 있는 아이디어를 제공 . | . tuple&#54805; . 리스트와 비슷하다. | 차이점1: [ ] 대신에 ( )를 사용한다. | 차이점2: 불변형이다. (값을 바꿀 수 없음) | 차이점3: 하나의 원소로 이루어진 튜플을 만들때는 쉼표를 붙여야 함. | . a=(1,) a . (1,) . a + (2,) . (1, 2) . 차이점4: (의미가 명확할때) 튜플의 괄호는 생략가능하다. | . a=1,2 a . (1, 2) . 의미가 명확할때 생략해야함 . 1,2 + 3,4,5 . (1, 5, 4, 5) . &#53916;&#54540; &#50616;&#54056;&#53433; . name,age,sex,height,weight = &#39;Tom&#39;,20,&#39;M&#39;,180,70 . name . &#39;Tom&#39; . weight . 70 . [예제3]: 임시변수 사용없이 두 변수의 값을 교환 . a=10 b=20 . a,b=b,a . a . 20 . b . 10 . [예제4]: 함수의 입력으로 튜플을 넣을때 . def cal(a,b): print(str(a) + &#39;+&#39; + str(b) + &#39;=&#39; + str(a+b)) print(str(a) + &#39;-&#39; + str(b) + &#39;=&#39; + str(a-b)) print(str(a) + &#39;*&#39; + str(b) + &#39;=&#39; + str(a*b)) print(str(a) + &#39;/&#39; + str(b) + &#39;=&#39; + str(a/b)) . input=[3,4] cal(input) # 리스트로는 불가능하다. . TypeError Traceback (most recent call last) &lt;ipython-input-61-3191852bf0a7&gt; in &lt;module&gt; 1 ### 우리가 원하는 형태 2 input=[3,4] -&gt; 3 cal(input) # 리스트로는 불가능하다. TypeError: cal() missing 1 required positional argument: &#39;b&#39; . cal(input[0],input[1]) . 3+4=7 3-4=-1 3*4=12 3/4=0.75 . input=(3,4) input . (3, 4) . cal(*input) # 튜플 언패킹으로는 가능하다. . 3+4=7 3-4=-1 3*4=12 3/4=0.75 . 함수를 호출할때 인수앞에 *를 붙여 튜플을 언패킹할 수 있다. | . [예제6]: 플레이스홀더 . idlist=[(&#39;guebin&#39;, &#39;202112345&#39;,&#39;M&#39;,&#39;Korea&#39;), (&#39;iu&#39;, &#39;202154321&#39;,&#39;F&#39;,&#39;Korea&#39;), (&#39;hodong&#39;, &#39;201812321&#39;,&#39;M&#39;,&#39;Korea&#39;)] . for name,studentid,sex,nat in idlist: print(name) . guebin iu hodong . for name , _ , _ , _ in idlist: print(name) . guebin iu hodong . set&#54805; . A={&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;} B={&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;} . A.union(B) . {&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;} . A|B . {&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;} . A.intersection(B) . {&#39;c&#39;, &#39;d&#39;} . A &amp; B . {&#39;c&#39;, &#39;d&#39;} . A.difference(B) . {&#39;a&#39;, &#39;b&#39;} . A-B . {&#39;a&#39;, &#39;b&#39;} . a=set(&#39;hello&#39;) a . {&#39;e&#39;, &#39;h&#39;, &#39;l&#39;, &#39;o&#39;} . for i in a: print(i) . o l e h . 순서가 좀 이상하다 $ to$ 집합은 원래 순서가 없다. $ to$ 인덱싱이 불가능하다. $ to$ 슬라이싱도 불가능 . 집합 컴프리헨션 | . C={2**x for x in [1,2,3,4]} C . {2, 4, 8, 16} . dict&#54805; . mydict={&#39;a&#39;:[1,2,3],&#39;b&#39;:[3,4,5]} . mydict[&#39;a&#39;] . [1, 2, 3] . mydict[&#39;a&#39;]+mydict[&#39;b&#39;] . [1, 2, 3, 3, 4, 5] . mydict[0] # 인덱싱 불가능 . KeyError Traceback (most recent call last) &lt;ipython-input-88-857b2cc4f569&gt; in &lt;module&gt; -&gt; 1 mydict[0] # 인덱싱 불가능 KeyError: 0 . - 딕셔너리 컴프리핸션 . File &#34;&lt;ipython-input-89-235de1d2ec14&gt;&#34;, line 1 - 딕셔너리 컴프리핸션 ^ SyntaxError: invalid syntax . X={x:x**2 for x in [1,2,3,4]} X . {1: 1, 2: 4, 3: 9, 4: 16} . numpy . [$ ast$] &#45336;&#54028;&#51060;(numpy)&#47484; &#50780; &#50024;&#50556; &#54616;&#45716;&#44032;? (1) . 욕심: (1,2,3)+(2,3,4)=(3,5,7)를 계산하고 싶다. . import numpy as np a=np.array((1,2,3)) b=np.array([2,3,4]) a+b . array([3, 5, 7]) . [$ ast$] &#45336;&#54028;&#51060;&#51032; &#54840;&#54872;&#49457; . list - tuple - np.array사이에는 호환성이 좋음 . list(np.array(tuple(a))) . [1, 2, 3] . [$ ast$] &#45336;&#54028;&#51060;(numpy)&#47484; &#50780; &#50024;&#50556;&#54616;&#45716;&#44032;? (2) . 넘파이를 사용하면 벡터연산과 행렬연산을 쉽게 할 수 있다. . 예를들어 아래와 같은 문제가 있다고 하자. . $ begin{cases} w+2x+3y+4z=1 2w+2x+y=9 x-y=4 3w+x-y+3y=7 end{cases}$ . 매트릭스 형태로 위의 식을 표현하면 아래와 같다. . $ begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 4 2 &amp; 2 &amp; 1 &amp; 0 0 &amp; 1 &amp;-1 &amp; 0 3 &amp; 1 &amp;-1 &amp; 3 end{bmatrix} begin{bmatrix} w x y z end{bmatrix}= begin{bmatrix} 1 9 4 7 end{bmatrix}$ . 양변에 $ begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 4 2 &amp; 2 &amp; 1 &amp; 0 0 &amp; 1 &amp;-1 &amp; 0 3 &amp; 1 &amp;-1 &amp; 3 end{bmatrix}$의 역행렬을 취하면 . $ begin{bmatrix} w x y z end{bmatrix}= begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 4 2 &amp; 2 &amp; 1 &amp; 0 0 &amp; 1 &amp;-1 &amp; 0 3 &amp; 1 &amp;-1 &amp; 3 end{bmatrix}^{-1} begin{bmatrix} 1 9 4 7 end{bmatrix}$ . from numpy.linalg import inv A=[[1,2,3,4],[2,2,1,0],[0,1,-1,0],[3,1,-1,3]] b=[1,9,4,7] Aarr=np.array(A) barr=np.array(b) inv(Aarr) @ barr . array([ 2., 3., -1., -1.]) . 인덱싱 (슬라이싱 포함) | . A=np.array([[11,12,13,14,15],[21,22,23,24,25],[31,32,33,34,35]]) A . array([[11, 12, 13, 14, 15], [21, 22, 23, 24, 25], [31, 32, 33, 34, 35]]) . [예제1] (3,1)에 접근하여 보자! . A[2][0] . 31 . A[2,0] # list와의 차이점 . 31 . [예제4] 1행중에서 1,3,5열에 접근해보자. . A[0,[0,2,4]] #방법 1 . array([11, 13, 15]) . A[0][[0,2,4]] #방법 2 . array([11, 13, 15]) . b=(0,2,4) A[0,b] . array([11, 13, 15]) . [$ ast$] &#51064;&#45937;&#49905;&#51032; &#51333;&#47448; ($ star star star$) . 기본인덱싱: 인덱스, 슬라이싱을 활용 예1: A[1,1] | 예2: A[1,0:2] | . | 팬시인덱싱(응용인덱싱): 인덱스를 정수배열로 전달, np.ix_함수를 활용한 인덱싱, 부울값 인덱싱 예1: A[0,[0,2,4]] , 정수배열 인덱싱 | 예2: A[np.ix_(a,b)] , np.ix함수를 활용한 인덱싱 | 예3: c[c&gt;0] , 부울값인덱싱 | . | numpy를 배우는 방법 | . 인터넷+자동완성+contextual help . pandas . `dict`와 호환성이 좋은 새로운 자료형이 있는데, 그것이 바로 `pandas`이다. . 근본적인 차이: list는 번호로, dict는 keyword로 접근한다. . 인덱싱, 슬라이싱 vs 맵핑 note: 리스트는 키워드로 정보검색이 불가능하다. note: 딕셔너리는 인덱스로 정보검색이 불가능하다. | . d={&#39;새로이&#39;:[30,600,4.0], &quot;이서&quot;:[20,950,4.2], &quot;일권&quot;:[28,950,2.3], &quot;현이&quot;:[28,650,3.8]} . import pandas as pd pd.DataFrame(d) ## 판다스자료형 = 데이터프레임을 선언하는 방법 . 새로이 이서 일권 현이 . 0 30.0 | 20.0 | 28.0 | 28.0 | . 1 600.0 | 950.0 | 950.0 | 650.0 | . 2 4.0 | 4.2 | 2.3 | 3.8 | . df=pd.DataFrame(d).T df . 0 1 2 . 새로이 30.0 | 600.0 | 4.0 | . 이서 20.0 | 950.0 | 4.2 | . 일권 28.0 | 950.0 | 2.3 | . 현이 28.0 | 650.0 | 3.8 | . note: 이서의 정보를 알고 싶다면? (딕셔너리 느낌) . df.loc[&#39;이서&#39;] . 0 20.0 1 950.0 2 4.2 Name: 이서, dtype: float64 . note: 칼럼이름을 정하고 싶다면? . df.columns=[&#39;age&#39;,&#39;toeic&#39;,&#39;gpa&#39;] df . age toeic gpa . 새로이 30.0 | 600.0 | 4.0 | . 이서 20.0 | 950.0 | 4.2 | . 일권 28.0 | 950.0 | 2.3 | . 현이 28.0 | 650.0 | 3.8 | . df.loc[:,&#39;gpa&#39;] . 새로이 4.0 이서 4.2 일권 2.3 현이 3.8 Name: gpa, dtype: float64 . note: 2-3번째 칼럼을 불러오자! (넘파이느낌) . df.iloc[:,1:3] . toeic gpa . 새로이 600.0 | 4.0 | . 이서 950.0 | 4.2 | . 일권 950.0 | 2.3 | . 현이 650.0 | 3.8 | . note: 토익점수를 불러오고 싶다면? . df.loc[:,&#39;toeic&#39;] . 새로이 600.0 이서 950.0 일권 950.0 현이 650.0 Name: toeic, dtype: float64 . note: age~toeic까지의 정보를 얻고 싶다면? . df.loc[:,&#39;age&#39;:&#39;toeic&#39;] . age toeic . 새로이 30.0 | 600.0 | . 이서 20.0 | 950.0 | . 일권 28.0 | 950.0 | . 현이 28.0 | 650.0 | . note: 새로이~일권까지의 정보를 얻고 싶다면? . df.loc[&#39;새로이&#39;:&#39;일권&#39;,:] . age toeic gpa . 새로이 30.0 | 600.0 | 4.0 | . 이서 20.0 | 950.0 | 4.2 | . 일권 28.0 | 950.0 | 2.3 | . note: 토익점수가 800보다 높은사람을 부르고 싶다면? . df.query(&#39;toeic&gt;800&#39;) . age toeic gpa . 이서 20.0 | 950.0 | 4.2 | . 일권 28.0 | 950.0 | 2.3 | . note: 나이가 23보다 많고 토익점수가 800보다 높은 사람을 부르고 싶다면? . df.query(&#39;age&gt;23 &amp; toeic&gt;800&#39;) . age toeic gpa . 일권 28.0 | 950.0 | 2.3 | . Class . 많은 교재에서 정의를 회피함 | 비유적 설명 , 다른 대상을 가져와서 설명 클래스는 과자틀과 비슷하다. 클래스란 똑같은 무엇인가를 계속 만들어 낼 수도 있는 설계도면이고 객체란 클래스로 만든 피조물을 뜻한다. (점프투파이썬) | In object-oriented programming, a class is an extensible program-code-template for creating objects, providing initial values for state (member variables) and implementations of behavior (member functions or methods).` | . | . 직접적 설명 복제를 위한 확장가능한 프로그램 코드의 유닛 | . | . 좀더 정리하여 말하면, . (1) 개념의 인지 . (2) 복사하고 싶은 속성을 추림 . (3) 복사가능한 어떤 틀을 만듬 (=클래스를 정의) . (4) 틀에서 인스턴스를 만든다 (=클래스에서 인스턴스를 만든다) . class MooYaHo(): ### MooYaHo라는 이름을 가진 클래스 선언 title=&quot;농심 무파마&quot; ### 클래스안에서 정의된 변수1 img=Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) ### 클래스안에서 정의된 변수2 don=&quot;그만큼 맛있으시단거지&quot; ### 클래스안에서 정의된 변수3 def memeshow(self): ### 클래스안에서 정의된 함수* print(self.title) display(self.img) print(self.don) . 규칙1: 클래스내에서 함수를 선언하면 반드시 첫번째 인자는 self를 넣어야 한다. --&gt; self가 뭘까? . 규칙2: 클래스 내에서 정의한 변수 (예를들면 title, img, don)를 사용하려면 . self.title, self.img, self.don | MooYaHo.title, MooYaHo.img, MooYaHo.don | . 클래스에서 인스턴스를 찍어내는 방법 . 함수사용법과 비슷 | 클래스 이름을 쓰고 콘텐츠를 구체화시키는 과정에서 필요한 입력1, 입력2를 ()에 넣는다. | MooYaHo의 경우는 따로 입력이 없으므로, 그냥 MooYaHo하고 입력을 비워둔다. 즉 MooYaHo()로 생성 | . 성능1: 인스턴스에서 .을 찍고 접근할 수 있는 여러 자료들을 정의할 수 있다. . 성능2:인스턴스에서 .을 찍고 쓸 수 있는 자체적인 함수(=method라고 함)를 정의할 수 있다. . 출력만 살짝 바꾸어서 MooYaHo2를 만들고 싶다. | . --&gt; MooYaHo의 모든 내용은 그대로 가져오고, 그 살짝만 다시 조정하면 된다. . #### 이런식으로 할 필요 없다. class MooYaHo2(): ### MooYaHo라는 이름을 가진 클래스 선언 title=&quot;농심 무파마&quot; ### 클래스안에서 정의된 변수1 img=Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) ### 클래스안에서 정의된 변수2 don=&quot;그만큼 맛있으시단거지&quot; ### 클래스안에서 정의된 변수3 def memeshow(self): ### 클래스안에서 정의된 함수* print(&#39;☆☆☆☆☆☆[&#39;+self.title+&#39;]☆☆☆☆☆☆&#39;) display(self.img) print(&#39;형돈:&#39;+self.don) . class MooYaHo2(MooYaHo): choi=&#39;무야~~~~~호~~~!!!&#39; def memeshow(self): ### 클래스안에서 정의된 함수* print(&#39;☆☆☆☆☆☆[&#39;+self.title+&#39;]☆☆☆☆☆☆&#39;) display(self.img) print(self.choi) print(&#39;형돈:&#39;+self.don) . __str__ . __repr__ . __init__ . 상속 . | 객체임베딩(객체 내장) . | . Name Space . 전역 변수 &gt; 클래스 변수 &gt; 메소드 변수 &gt; 인스턴스 변수 | . &#50672;&#49328;&#51088; &#50724;&#48260;&#47196;&#46377; . - 연산자 오버로드 핵심아이디어 . 클래스가 일반 파이썬 연산을 재정의하는 것 | 여기에서 연산은 단순히 더하기 빼기를 의미하는게 아니라, print(), +, [0] 와 같은 파이썬 내장문법을 모두 포괄하는 개념이라 이해하는 것이 옳다. | . if&#47928; . a=11 if a&lt;5: print(&#39;a=....1,2,3,4&#39;) elif a&gt;10: print(&#39;a=11,12,13,....&#39;) else: print(&#39;a=5,6,7,...,10&#39;) . a=11,12,13,.... . a=2 if a==1: print(&#39;a=1&#39;) . if만 있어도 작동한다. . for&#47928; . for i in [1,2,3,4]: print(i) for i in (1,2,3,4): print(i) for i in &#39;1234&#39;: print(i) 1 2 3 4 . - 의문 . for i in ???: print(i) . 에서 물음표 자리에 올 수 있는 것이 무엇일까? . ??? 자리에 올 수 있는 것은 dir()하여 __iter__()라는 메서드가 있는 object이다. . a=1 . dir(a) [&#39;__abs__&#39;, &#39;__add__&#39; . . . . . . `to_bytes&#39;] . int클래스의 인스턴스는 __iter__()가 없다! . - list, pd.DataFrame, np.array 는 모두 __iter__() 함수가 있다. 따라서 iterable한 오브젝트이다. . iterable한 오브젝트는 iterator로 만들 수 있는 특징이 있다. . iterable한 오브젝트를 어떻게 iterator로 만드는가? . L=[[1,2,3],[3,4,5]] import pandas as pd df=pd.DataFrame(L) . dfiter1=df.__iter__() . dfiter2=iter(df) . dfiter1? . Type: generator String form: &lt;generator object RangeIndex.__iter__ at 0x000001A97812A350&gt; Docstring: &lt;no docstring&gt; . - dfiter1은 generator라는 클래스에서 만들어진 인스턴스 오브젝트이다. . dir(dfiter1) . [&#39;__class__&#39;, &#39;__del__&#39;, &#39;__delattr__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__iter__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__name__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__next__&#39;, &#39;__qualname__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;close&#39;, &#39;gi_code&#39;, &#39;gi_frame&#39;, &#39;gi_running&#39;, &#39;gi_yieldfrom&#39;, &#39;send&#39;, &#39;throw&#39;] . dfiter1.__next__() . 0 . – for 문의 작동원리 . for i in L: print(i) . (1) iter함수를 사용해서 L을 iterator로 만든다. . (2) iterator에서 .__next__()함수를 호출하고 결과를 i에 저장한뒤에 for문 블락안에 있는 내용(들여쓰기 된 내용)을 실행한다. . (3) StopIteration 에러가 발생하면 for 문을 멈춘다. . Liter=iter(L) . Liter.__next__() . [1, 2, 3] . Liter.__next__() . [3, 4, 5] . Liter.__next__() . StopIteration Traceback (most recent call last) &lt;ipython-input-228-6220b29182a4&gt; in &lt;module&gt; -&gt; 1 Liter.__next__() StopIteration: . range() . - for문의 정석은 아래와 같이 range()를 사용하는 것이다. . for i in range(5): print(i) . 0 1 2 3 4 . - range(5)의 정체는 그냥 iterable object이다. . - 그래서 언제든지 iterator로 바꿀 수 있다. . a = range(5) aiter=iter(a) . aiter.__next__() . 0 . aiter.__next__() . 1 . . . . . aiter.__next__() . StopIteration Traceback (most recent call last) &lt;ipython-input-238-b0a1ab28475b&gt; in &lt;module&gt; -&gt; 1 aiter.__next__() StopIteration: . - ???? 자리에 iterator 자체가와도 무방할것 같다. . - 확인 . L=iter([1,2,3,4]) for i in L: print(i) . 1 2 3 4 . with . f=open(&#39;test.txt&#39;) a=f.read() print(a) hello hello2 hello3 f.closed . false . f.close() f.closed . True . f가 닫힌 상태에서는 더 이상 읽을 수가 없다. . 파일을 닫지 않는다고 해서 큰 문제는 없어보이지만 그냥 닫는것이 좋다. . motivation | . - 생각해 보니까 파일을 열면 항상 닫아야 한다. . 이처럼 쌍(시작-끝)으로 수행되는 처리가 반복적으로 발생하는 경우가 있는데 그때마다 .close() 메소드 따위를 쓰는 것이 번거롭게 느껴진다. . 예를들면 파일을 열었으면 적당한 동작뒤에 알아서 닫아졌으면 좋겠다는 것이다. . 이러한 모티브에서 구현된 것이 with문 이다. . with open(&#39;test.txt&#39;) as g: print(g.read()) hello hello2 hello3 g.closed . True . 잘 닫아졌다. . - 기본사용법 . with의 사용법은 직관적으로 이해가 가능하지만 그래도 다시한번 살펴보자. . with blabla as variable: yadiyadi yadiyadi2 . (1) with blabla as variable에서 blabla가 실행된다. . (2) blabla의 실행결과로 어떠한 특별한 오브젝트가 만들어지는데 그 오브젝트를 우리가 variable로 부르기로 한다. . (3) 탭으로 들여쓰기된 부분, 즉 yadiyadi, yadiyadi2 가 순서대로 실행된다. . (4) 탭으로 들여쓰기된 부분이 실행되고 난 뒤에 g.closed() 따위의 미리 약속된 어떠한 코드가 실행되는것 같다. . - 동작원리 . 비밀은 __enter__ 와 __exit__ 메소드에 있다. . (for문 복습) for i in ...: 에서 ...에 올 수 있는 오브젝트는 __iter__ 메소드가 정의되어 있어야 한다. 이러한 오브젝트를 iterable한 오브젝트라고 한다. . (with문) with ... as variable: 에서 ...의 실행결과로 생성되는 오브젝트는 __enter__ 와 __exit__ 메소드가 정의되어 있어야 한다. . 이중 __enter__는 with문이 시작되면 자동으로 실행된다. | 이중 __exit__는 with문이 끝나면 자동으로 실행된다. | . - 예제 . class MooYaHo: def __init__(self): print(&#39;init&#39;) def __enter__(self): print(&#39;무야호&#39;) def __exit__(self,exc_type,exc_value,traceback): # self 이외의 3가지 변수는 예외처리에 관련된 변수인데 여기서는 다루지 않음. print(&#39;그만큼 신나시는거지&#39;) . with MooYaHo() as a: print(&#39;.&#39;) . init 무야호 . 그만큼 신나시는거지 . &#54632;&#49688; . 함수도 객체다 | . def myadd(a,b): return a+b . myadd(1,2) . 3 . ?myadd . Signature: myadd(a, b) Docstring: &lt;no docstring&gt; File: c: users owner 파이썬입문 &lt;ipython-input-250-e383cb6c2c80&gt; Type: function . - Type이 function이다? . - myadd 는 function class의 instance이다. . - 결국 myadd 역시 하나의 오브젝트에 불과하다. . higher-order function . myadd(1,2) . 3 . myadd의 입력 1,2는 int class의 인스턴스 오브젝트였음. . 즉 문법의 논리로 보면 함수의 입력에 들어갈 수 있는것은 오브젝트이면 된다. . 그런데 함수 자체도 오브젝트이다 $ to$ 함수도 함수의 입력으로 쓸 수 있다? . - 예제1 . def calc(fun,a,b): return fun(a,b) . calc(myadd,-3,3) . 0 . 이처럼 함수자체를 입력으로 받거나 출력으로 보내는 함수를 higher-order function이라고 한다. .",
            "url": "https://star77sa.github.io/TIL-Blog/python/2021/06/27/Python%EC%9E%85%EB%AC%B8-Summary.html",
            "relUrl": "/python/2021/06/27/Python%EC%9E%85%EB%AC%B8-Summary.html",
            "date": " • Jun 27, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "R입문",
            "content": ". R은 파이썬, C와 다르게 1부터 시작함 | . &#48289;&#53552; . era &lt;-c(5,4,3,4,5,6) . 벡터의 원소는 모두 같은 &#39;형식&#39;이나 &#39;데이터 형&#39;을 가진다. | . &#53945;&#49688;&#54620; &#54632;&#49688; . seq()는 등차수열을 생성한다. | . seq(from = 0, to = 10, by = 2.5) . &lt;ol class=list-inline&gt; 0 | 2.5 | 5 | 7.5 | 10 | &lt;/ol&gt; seq(0, 10, length = 10) . &lt;ol class=list-inline&gt; 0 | 1.11111111111111 | 2.22222222222222 | 3.33333333333333 | 4.44444444444444 | 5.55555555555556 | 6.66666666666667 | 7.77777777777778 | 8.88888888888889 | 10 | &lt;/ol&gt; rep()는 값이 반복되는 벡터를 생성한다. | . rep(0, times = 10) . &lt;ol class=list-inline&gt; 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | &lt;/ol&gt; rep(c(1,2,3), 2) . &lt;ol class=list-inline&gt; 1 | 2 | 3 | 1 | 2 | 3 | &lt;/ol&gt; rep(c(1,2,3), c(1,2,3)) . &lt;ol class=list-inline&gt; 1 | 2 | 2 | 3 | 3 | 3 | &lt;/ol&gt; rep(c(1,2,3), each = 3) . &lt;ol class=list-inline&gt; 1 | 1 | 1 | 2 | 2 | 2 | 3 | 3 | 3 | &lt;/ol&gt; &#53945;&#49688;&#54620; &#44050; . NA는 &quot;not available&quot; (결측)을 나타낸다. | . mean(x, na.rm = TRUE) . NULL는 &quot;존재하지 않음&quot;을 나타낸다. | . &#54596;&#53552;&#47553; . 특정한 조건에 부합하는 데이터 값만 남기는 기법 | . z &lt;- c(1,8,9,2,7,10,5,6,4,3) z[z %% 2 == 1] . &#50976;&#50857;&#54620; &#54632;&#49688;&#46308; . ifelse(test, yes, no)는 test가 TRUE이면 yes를 값으로 출력, False이면 no로 출력 | . x.1 &lt;- ifelse(x&gt;0, x, 2*x) . identical(x,y)는 x와 y가 동일한 벡터인가를 알려준다. | . all()와 any()는 일부 혹은 모든 인수가 TRUE인지 알려준다. | . names()는 벡터의 개별 요소에 이름을 부여한다. | . paste()는 2개의 문자열 벡터를 붙이는 기능을 한다. | . &#54632;&#49688; . sum.1 &lt;- function(x) { temp &lt;- 0 for(i in 1:length) temp &lt;- temp + x[i] return(temp) } . &#54665;&#47148; . cbind()는 같은 길이의 벡터를 열에 넣어 묶어주는 R함수 | . stat &lt;- cbind(year, game, era) . rbind()는 같은 길이의 벡터를 행에 넣어 묶어주는 R함수 | . M &lt;- rbind(e, f, g) . &#47532;&#49828;&#53944; . p개의 벡터로 구성되는 데이터 객체 | . L &lt;- list(game, era, e) L.1 &lt;- list(game = game, era = era, player = e) . &quot;name&quot; 또는 $name 으로 인덱싱 가능 | . L.1$game L.1[&quot;game&quot;] . &#45936;&#51060;&#53552;&#54532;&#47112;&#51076; . p개의 벡터로 구성되는 데이터 객체 | . 각 요소 벡터의 데이터 형태는 다를 수 있으나 길이는 같다. | . 형태는 행렬과 같으나 열별로만 데이터 형이 같다. | . WS &lt;- data.frame(year, winner, loser, wins, losses) . str() 함수는 데이터프레임의 구조를 파악하는 함수이다. | . str(WS) nrow(WS); ncol(WS); dim(WS), names(WS) #행 갯수, 열 갯수, 행 열 갯수, 헤더 이름 . 열(변수)인덱싱 | . WS$winner WS[,2] WS[[2]] . 행(객체)인덱싱 | . &quot;WS[3,] WS[&quot;3&quot;,] . &#46020;&#50880;&#47568; . R 함수에 대해 알고 싶은 경우 | . help(hist) ?hist . . 1,2 &#51109; &#44620;&#51648; &#51221;&#47532; .",
            "url": "https://star77sa.github.io/TIL-Blog/r/2021/06/21/R%EC%9E%85%EB%AC%B8-Summary.html",
            "relUrl": "/r/2021/06/21/R%EC%9E%85%EB%AC%B8-Summary.html",
            "date": " • Jun 21, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "Templete",
            "content": ".",
            "url": "https://star77sa.github.io/TIL-Blog/python/2020/02/20/templete.html",
            "relUrl": "/python/2020/02/20/templete.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://star77sa.github.io/TIL-Blog/jupyter/2020/01/01/test.html",
            "relUrl": "/jupyter/2020/01/01/test.html",
            "date": " • Jan 1, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "AI 대학원 진학을 목표로 공부하고 있습니다. . Name : 고경수 . | Email : star77sa@naver.com . | 학력 : 전북대학교 통계학, 컴퓨터공학 (3-1 재) . | . Project . 퓨쳐스리그 홍수ZERO 댐 유입량 예측(BigContest) . | 구내식당 식수인원 예측 AI 경진대회(Dacon) . | 네이버 영화 사이트 크롤링 및 분석 . | . Programming Skill . Python . | R . | C / C++ . | . Experience . 핀테크 앱 서비스 ‘티클리안’ 서포터즈 1기 (2020.02 ~ 2020.03) . | 취약계층을 위한 라면 나눔행사 지원 봉사활동 등 봉사활동 19건 44시간 (2020.05 ~ 2020.09) . | 2020 동계 어학연수 참여(University of San Jose) (2021.01 ~ 2021.02) . | 전북대학교 혁신교육개발원 BSM클리닉 수학 조교 (2021.04 ~ 2021.06) . | 2021 데이터 크리에이터 캠프 수료 및 본선진출 (2021.10.30 ~ 2021.10.30) . | .",
          "url": "https://star77sa.github.io/TIL-Blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://star77sa.github.io/TIL-Blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}