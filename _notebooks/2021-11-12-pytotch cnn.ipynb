{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63af8a47",
   "metadata": {},
   "source": [
    "# CNN\n",
    "> CNN 세팅, ResNet\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Python]\n",
    "- image: images/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19de0fc4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2e51d43-d7e0-496f-8012-195e70579698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:1.10.0+cpu\n",
      "cuda version: None\n",
      "cudnn version:None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # GPU 할당\n",
    "\n",
    "# Colab torch, gpu 확인\n",
    "print(\"Torch version:{}\".format(torch.__version__))\n",
    "print(\"cuda version: {}\".format(torch.version.cuda))\n",
    "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad04958-3648-4b26-a9a0-a7fb90eef705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data path : 약 1-2분 소요\n",
    "ROOT = \"/content/drive/MyDrive\"\n",
    "DIR = \"product_classification\"  # data 폴더와 ipynb 파일이 위치한 폴더명을 적으세요.\n",
    "PATH = os.path.join(ROOT, DIR)\n",
    "os.chdir(PATH)  # 현재 프로젝트 PATH로 이동\n",
    "\n",
    "# train, validation은 npy형태로 제공됩니다.\n",
    "X_train = np.load(\"Dataset/Train/X_train.npy\")\n",
    "Y_train = np.load(\"Dataset/Train/Y_train.npy\")\n",
    "X_val = np.load(\"Dataset/Valid/X_val.npy\")\n",
    "Y_val = np.load(\"Dataset/Valid/Y_val.npy\")\n",
    "X_test = np.load(\"Dataset/Test/X_test.npy\")  # 최종 제출할 prediction 결과에 사용할 데이터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cbc61a3-8c9e-495c-9e7a-12e4643c95c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - model이 한 번 학습할때 사용되는 data수 입니다\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7fa0b-9ff7-40b4-97ff-4c9a258380d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자료형 변환 numpy to torch\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "Y_train = torch.from_numpy(Y_train).long()\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "Y_val = torch.from_numpy(Y_val).long()\n",
    "X_test = torch.from_numpy(X_test).float()  \n",
    "\n",
    "# Print data info\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "\n",
    "train = TensorDataset(X_train, Y_train) \n",
    "val = TensorDataset(X_val, Y_val)\n",
    "\n",
    "# Train_Loader : mini batch 분할\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779cb475-a399-4374-9035-a786aca5687c",
   "metadata": {},
   "source": [
    "Accuracy 계산 커스텀 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2e6e6-47ef-4ab2-9a96-a39e0f5176e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy 계산\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97397e48-77da-47c6-9189-1723b4538ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 CNN 모델\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(7200, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = out.flatten(start_dim=1)\n",
    "        out = self.lin(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# pytorch에서 제공하는 CNN module 사용하기\n",
    "class Select_model(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=4, pretrained=False):\n",
    "        super(Select_model, self).__init__()\n",
    "\n",
    "        # Use a pretrained model\n",
    "        if model_name == \"vgg\":\n",
    "            self.network = models.vgg16(pretrained=pretrained)\n",
    "            # Replace last layer\n",
    "            num_ftrs = self.network.classifier[6].in_features\n",
    "            self.network.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        elif model_name == \"resnet\":  \n",
    "            self.network = models.resnet18(pretrained=pretrained)\n",
    "            # Replace last layer\n",
    "            num_ftrs = self.network.fc.in_features\n",
    "            self.network.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        elif model_name == \"googlenet\":\n",
    "            self.network = models.googlenet(pretrained=pretrained, aux_logits=False)\n",
    "            # Replace last layer\n",
    "            num_ftrs = self.network.fc.in_features\n",
    "            self.network.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        elif model_name == \"efficientnet_b0\":\n",
    "            self.network = models.efficientnet_b0(pretrained=pretrained, aux_logits=False)\n",
    "            # Replace last layer\n",
    "            num_ftrs = self.network.classifier[1].in_features\n",
    "            self.network.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b1d2851-175d-4eed-a2a6-53cef2d8d00d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=7200, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model 확인\n",
    "model = CNN(num_classes=4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c309ecb-df34-4d75-b6f1-14f6589415c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select_model(\n",
      "  (network): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model 확인\n",
    "model = Select_model('resnet')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e38eeb-13ba-4e70-a5c4-6577ae282168",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b42be6b-ae76-4730-a110-41a1ca884d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "\"\"\"\n",
    "2. hyperparameter를 바꿔봅시다!\n",
    "- 처음에 제공되는 값을 임의로 설정한 값입니다. 바꾸시고 돌리시면 됩니다!\n",
    "\"\"\"\n",
    "# learning rate : 모델의 학습 속도를 조절합니다. \n",
    "lr = 1e-10\n",
    "\n",
    "# weight_decay : L2 regularization으로 모델의 overfitting을 방지합니다\n",
    "weight_decay = 1e-10\n",
    "\n",
    "# epoch : 전체 dataset을 몇번 학습 시킬지 조절해보세요\n",
    "epochs = 2\n",
    "\n",
    "# model 선택\n",
    "\n",
    "## net = CNN(num_classes=4).to(device)\n",
    "net = Select_model('resnet').to(device)\n",
    "\n",
    "# optimizer 선택 (gradient descent : model update 방법): SGD, Adam, RMSProp\n",
    "# pytorch에서 제공하는 optimizer : https://pytorch.org/docs/stable/optim.html\n",
    "opt = \"Adam\"\n",
    "if opt == \"SGD\":\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay) \n",
    "elif opt == \"Adam\":\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "elif opt == \"RMSProb\":\n",
    "    optimizer = optim.RMSProb(net.parameters(), lr=lr, alpha = 0.9, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "# learning rate decay : 학습 도중 learning rate를 조절하는 technique \n",
    "# pytorch에서 제공하는 learning rate decay : https://pytorch.org/docs/stable/optim.html\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)  # epoch마다 x0.995 만큼 lr 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26151043-63ea-431f-bac5-06f12bba5a20",
   "metadata": {},
   "source": [
    "```python\n",
    "# training\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "train_correct_list = []\n",
    "val_correct_list = []\n",
    "result = {}\n",
    "\n",
    "# loss 함수\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    valLoss = 0\n",
    "    train_correct = 0\n",
    "    val_correct = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # training\n",
    "    for batch_idx, (input, label) in enumerate(train_loader):\n",
    "        input, label = input.to(device), label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = net(input)\n",
    "        loss = criterion(out, label)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc = accuracy(out, label)\n",
    "        train_correct += train_acc\n",
    "    \n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (val_input, val_label) in enumerate(val_loader):\n",
    "            net.eval()\n",
    "            val_input, val_label = val_input.to(device), val_label.to(device)\n",
    "            val_out = net(val_input)\n",
    "            val_loss = criterion(val_out, val_label)\n",
    "            val_acc = accuracy(val_out, val_label)\n",
    "            valLoss += val_loss.item()\n",
    "            val_correct += val_acc\n",
    "\n",
    "    print(\"[=] EPOCH [{:}/{:}] TIME [{:.3}s]\".format(epoch, epochs, time.time()-start_time) + \\\n",
    "          \" | TRAIN_LOSS [{:.3}] TRAIN_ACC [{:.3}] VAL_LOSS [{:.3}] VAL_ACC [{:.3}] \".format(\n",
    "              train_loss / len(train_loader), train_correct / len(train_loader), valLoss / len(val_loader), val_correct/len(val_loader)))\n",
    "    train_loss_list.append(train_loss / len(train_loader))\n",
    "    train_correct_list.append(train_correct.item() / len(train_loader))\n",
    "    val_loss_list.append(valLoss/len(val_loader))\n",
    "    val_correct_list.append(val_correct.item()/len(val_loader))\n",
    "    lr_scheduler.step()  # learning rate schedular step\n",
    "\n",
    "# 결과 저장\n",
    "result['train_loss'] = train_loss_list\n",
    "result['train_acc'] = train_correct_list\n",
    "result['val_loss'] = val_loss_list\n",
    "result['val_acc'] = val_correct_list\n",
    "total_result = []\n",
    "total_result.append(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb8a78-e0e0-40a4-b220-03f3ce66f944",
   "metadata": {},
   "source": [
    "## 학습결과 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3743e7ad-344f-4369-b86f-8ba65f221032",
   "metadata": {},
   "source": [
    "```python\n",
    "def plot_acc(total_result):\n",
    "    train_acc = [x['train_acc'] for x in total_result]\n",
    "    val_acc = [x['val_acc'] for x in total_result]\n",
    "    plt.plot(*train_acc)\n",
    "    plt.plot(*val_acc)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Accuracy per epochs');\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_loss(total_result):\n",
    "    train_loss = [x['train_loss'] for x in total_result]\n",
    "    val_loss = [x['val_loss'] for x in total_result]\n",
    "    plt.plot(*train_loss)\n",
    "    plt.plot(*val_loss)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss per epochs');\n",
    "    plt.show()\n",
    "\n",
    "plot_acc(total_result)\n",
    "plot_loss(total_result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85605f70-52cf-435c-8d0f-c7d615b92691",
   "metadata": {},
   "source": [
    "```python\n",
    "# test 결과 확인\n",
    "def predict_test(img, model):\n",
    "    x = img.to(device)\n",
    "    model.eval()\n",
    "    y = model(x)\n",
    "    _, pred  = torch.max(y, dim=1)\n",
    "\n",
    "    return pred\n",
    "\n",
    "# test data shape\n",
    "print(X_test.shape)\n",
    "\n",
    "# test data 예측결과 list로 저장\n",
    "preds = []\n",
    "for i in range(len(X_test)):\n",
    "    pred = predict_test(X_test[i:i+1], net)\n",
    "    preds.append(pred.item())\n",
    "\n",
    "print(len(preds))  # 개수가 1120개가 맞는지 확인하세요!\n",
    "\n",
    "# DataFrame \n",
    "# id 추가\n",
    "id = [i for i in range(len(X_test))]\n",
    "test_preds = {'id': id, 'label': preds}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae04c475-649e-4b20-8b68-756035a4ac2b",
   "metadata": {},
   "source": [
    "## 결과제출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19432f1-0e5a-42f0-8511-1d5045f31732",
   "metadata": {},
   "source": [
    "```python\n",
    "# Make output directory : test data 결과 파일 저장 경로\n",
    "SAVE_PATH = os.path.join(PATH, \"output\")\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.mkdir(SAVE_PATH)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Make submission file\n",
    "team = \"Big_Star\"\n",
    "\n",
    "# 이 밑은 수정하지 마세요.\n",
    "sub = pd.DataFrame(test_preds)\n",
    "sub.to_csv(os.path.join(SAVE_PATH, f\"./{team}_submission.csv\"), index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a29641-32ef-43a4-8c72-53c12e251986",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aaf507-871b-48b4-8e4f-37d443bbbc72",
   "metadata": {},
   "source": [
    "# Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb8ade8f-7316-4a86-910b-053b7fd836e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3d0daf-9fd4-4269-bb10-f6b034795f94",
   "metadata": {},
   "source": [
    "```python\n",
    "model_arch='vgg11'\n",
    "num_classes=5\n",
    "\n",
    "model = models.__dict__[model_arch](pretrained = True)\n",
    "\n",
    "in_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(in_features, num_classes)\n",
    "model = model.to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa19b0-8bff-4816-90e2-7771cf169e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
