<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Pytorch_Tutorial | kyeong-soo</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Pytorch_Tutorial" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="파이토치 튜토리얼" />
<meta property="og:description" content="파이토치 튜토리얼" />
<link rel="canonical" href="https://star77sa.github.io/TIL-Blog/pytorch/2021/12/25/Pytorch.html" />
<meta property="og:url" content="https://star77sa.github.io/TIL-Blog/pytorch/2021/12/25/Pytorch.html" />
<meta property="og:site_name" content="kyeong-soo" />
<meta property="og:image" content="https://star77sa.github.io/TIL-Blog/images/" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-25T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://star77sa.github.io/TIL-Blog/pytorch/2021/12/25/Pytorch.html","@type":"BlogPosting","headline":"Pytorch_Tutorial","dateModified":"2021-12-25T00:00:00-06:00","datePublished":"2021-12-25T00:00:00-06:00","image":"https://star77sa.github.io/TIL-Blog/images/","mainEntityOfPage":{"@type":"WebPage","@id":"https://star77sa.github.io/TIL-Blog/pytorch/2021/12/25/Pytorch.html"},"description":"파이토치 튜토리얼","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/TIL-Blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://star77sa.github.io/TIL-Blog/feed.xml" title="kyeong-soo" /><link rel="shortcut icon" type="image/x-icon" href="/TIL-Blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/TIL-Blog/">kyeong-soo</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/TIL-Blog/about/">About Me</a><a class="page-link" href="/TIL-Blog/search/">Search</a><a class="page-link" href="/TIL-Blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Pytorch_Tutorial</h1><p class="page-description">파이토치 튜토리얼</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-12-25T00:00:00-06:00" itemprop="datePublished">
        Dec 25, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      22 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/TIL-Blog/categories/#Pytorch">Pytorch</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/star77sa/TIL-Blog/tree/master/_notebooks/2021-12-25-Pytorch.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/TIL-Blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/star77sa/TIL-Blog/master?filepath=_notebooks%2F2021-12-25-Pytorch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/TIL-Blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/star77sa/TIL-Blog/blob/master/_notebooks/2021-12-25-Pytorch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/TIL-Blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#1.-TENSORS">1. TENSORS </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Initializing-a-Tensor">Initializing a Tensor </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Directly-from-data">Directly from data </a></li>
<li class="toc-entry toc-h3"><a href="#From-a-NumPy-array">From a NumPy array </a></li>
<li class="toc-entry toc-h3"><a href="#From-another-tensor:">From another tensor: </a></li>
<li class="toc-entry toc-h3"><a href="#With-random-or-constant-values:">With random or constant values: </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Attributes-of-a-Tensor">Attributes of a Tensor </a></li>
<li class="toc-entry toc-h2"><a href="#Operations-on-Tensors">Operations on Tensors </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Standard-numpy-like-indexing-and-slicing:">Standard numpy-like indexing and slicing: </a></li>
<li class="toc-entry toc-h3"><a href="#Joining-tensors">Joining tensors </a></li>
<li class="toc-entry toc-h3"><a href="#Arithmetic-operations">Arithmetic operations </a></li>
<li class="toc-entry toc-h3"><a href="#Single-element-tensors">Single-element tensors </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#2.-DATASETS-&-DATALOADERS">2. DATASETS &amp; DATALOADERS </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Loading-a-Dataset-데이터셋-불러오기">Loading a Dataset 데이터셋 불러오기 </a></li>
<li class="toc-entry toc-h2"><a href="#Iterating-and-Visualizing-the-Dataset-데이터셋을-순회하고-시각화하기">Iterating and Visualizing the Dataset 데이터셋을 순회하고 시각화하기 </a></li>
<li class="toc-entry toc-h2"><a href="#Creating-a-Custom-Dataset-for-your-files">Creating a Custom Dataset for your files </a>
<ul>
<li class="toc-entry toc-h3"><a href="#__init__">__init__ </a></li>
<li class="toc-entry toc-h3"><a href="#__len__">__len__ </a></li>
<li class="toc-entry toc-h3"><a href="#__getitem__">__getitem__ </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#DataLoader로-학습용-데이터-준비하기">DataLoader로 학습용 데이터 준비하기 </a></li>
<li class="toc-entry toc-h2"><a href="#DataLoader를-통해-순회하기(iterate)">DataLoader를 통해 순회하기(iterate) </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#3.-TRANSFORM">3. TRANSFORM </a>
<ul>
<li class="toc-entry toc-h2"><a href="#ToTensor()">ToTensor() </a></li>
<li class="toc-entry toc-h2"><a href="#Lambda-변형(Transform)">Lambda 변형(Transform) </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#4.-신경망-모델-구성하기">4. 신경망 모델 구성하기 </a>
<ul>
<li class="toc-entry toc-h2"><a href="#학습을-위한-장치-얻기">학습을 위한 장치 얻기 </a></li>
<li class="toc-entry toc-h2"><a href="#클래스-정의하기">클래스 정의하기 </a></li>
<li class="toc-entry toc-h2"><a href="#모델-계층(Layer)">모델 계층(Layer) </a>
<ul>
<li class="toc-entry toc-h3"><a href="#nn.Flatten">nn.Flatten </a></li>
<li class="toc-entry toc-h3"><a href="#nn.Linear">nn.Linear </a></li>
<li class="toc-entry toc-h3"><a href="#nn.ReLU">nn.ReLU </a></li>
<li class="toc-entry toc-h3"><a href="#nn.Sequential">nn.Sequential </a></li>
<li class="toc-entry toc-h3"><a href="#nn.Softmax">nn.Softmax </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#모델-매개변수">모델 매개변수 </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#5.-Autograd">5. Autograd </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Tensor,-Function과-연산그래프(Computational-graph)">Tensor, Function과 연산그래프(Computational graph) </a></li>
<li class="toc-entry toc-h2"><a href="#변화도(Gradient)-계산하기">변화도(Gradient) 계산하기 </a></li>
<li class="toc-entry toc-h2"><a href="#변화도-추적-멈추기">변화도 추적 멈추기 </a></li>
<li class="toc-entry toc-h2"><a href="#연산-그래프에-대한-추가-정보">연산 그래프에 대한 추가 정보 </a></li>
<li class="toc-entry toc-h2"><a href="#선택적으로-읽기(Optional-Reading):-텐서-변화도와-야코비안-곱-(Jacobian-Product)">선택적으로 읽기(Optional Reading): 텐서 변화도와 야코비안 곱 (Jacobian Product) </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#6.-Optimization">6. Optimization </a>
<ul>
<li class="toc-entry toc-h2"><a href="#기본(Pre-requisite)-코드">기본(Pre-requisite) 코드 </a></li>
<li class="toc-entry toc-h2"><a href="#하이퍼파라매터(Hyperparameter)">하이퍼파라매터(Hyperparameter) </a></li>
<li class="toc-entry toc-h2"><a href="#최적화-단계(Optimization-Loop)">최적화 단계(Optimization Loop) </a>
<ul>
<li class="toc-entry toc-h3"><a href="#손실-함수(loss-function)">손실 함수(loss function) </a></li>
<li class="toc-entry toc-h3"><a href="#옵티마이저(Optimizer)">옵티마이저(Optimizer) </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#전체-구현">전체 구현 </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#7.-모델-저장하고-불러오기">7. 모델 저장하고 불러오기 </a>
<ul>
<li class="toc-entry toc-h2"><a href="#모델-가중치-저장하고-불러오기">모델 가중치 저장하고 불러오기 </a></li>
<li class="toc-entry toc-h2"><a href="#모델의-형태를-포함하여-저장하고-불러오기">모델의 형태를 포함하여 저장하고 불러오기 </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-12-25-Pytorch.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a href="https://pytorch.org/tutorials/beginner/basics/intro.html">https://pytorch.org/tutorials/beginner/basics/intro.html</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="1.-TENSORS">
<a class="anchor" href="#1.-TENSORS" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. TENSORS<a class="anchor-link" href="#1.-TENSORS"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Initializing-a-Tensor">
<a class="anchor" href="#Initializing-a-Tensor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Initializing a Tensor<a class="anchor-link" href="#Initializing-a-Tensor"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Directly-from-data">
<a class="anchor" href="#Directly-from-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Directly from data<a class="anchor-link" href="#Directly-from-data"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[1, 2],
        [3, 4]])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="From-a-NumPy-array">
<a class="anchor" href="#From-a-NumPy-array" aria-hidden="true"><span class="octicon octicon-link"></span></a>From a NumPy array<a class="anchor-link" href="#From-a-NumPy-array"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">x_np</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np_array</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_np</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[1, 2],
        [3, 4]], dtype=torch.int32)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="From-another-tensor:">
<a class="anchor" href="#From-another-tensor:" aria-hidden="true"><span class="octicon octicon-link"></span></a>From another tensor:<a class="anchor-link" href="#From-another-tensor:"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span> <span class="c1"># retains the properties of x_data</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Ones Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">x_ones</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">x_rand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span> <span class="c1"># overrides the datatype of x_data</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Random Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">x_rand</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Ones Tensor: 
 tensor([[1, 1],
        [1, 1]]) 

Random Tensor: 
 tensor([[0.8391, 0.5009],
        [0.9606, 0.3604]]) 

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="With-random-or-constant-values:">
<a class="anchor" href="#With-random-or-constant-values:" aria-hidden="true"><span class="octicon octicon-link"></span></a>With random or constant values:<a class="anchor-link" href="#With-random-or-constant-values:"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,)</span>
<span class="n">rand_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="n">ones_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="n">zeros_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Random Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">rand_tensor</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Ones Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">ones_tensor</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Zeros Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">zeros_tensor</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Random Tensor: 
 tensor([[0.1136, 0.1366, 0.7857],
        [0.5840, 0.8021, 0.7719]]) 

Ones Tensor: 
 tensor([[1., 1., 1.],
        [1., 1., 1.]]) 

Zeros Tensor: 
 tensor([[0., 0., 0.],
        [0., 0., 0.]])
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Attributes-of-a-Tensor">
<a class="anchor" href="#Attributes-of-a-Tensor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Attributes of a Tensor<a class="anchor-link" href="#Attributes-of-a-Tensor"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Shape of tensor: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Datatype of tensor: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Device tensor is stored on: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Shape of tensor: torch.Size([3, 4])
Datatype of tensor: torch.float32
Device tensor is stored on: cpu
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Operations-on-Tensors">
<a class="anchor" href="#Operations-on-Tensors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Operations on Tensors<a class="anchor-link" href="#Operations-on-Tensors"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cuda'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Standard-numpy-like-indexing-and-slicing:">
<a class="anchor" href="#Standard-numpy-like-indexing-and-slicing:" aria-hidden="true"><span class="octicon octicon-link"></span></a>Standard numpy-like indexing and slicing:<a class="anchor-link" href="#Standard-numpy-like-indexing-and-slicing:"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'First row: '</span><span class="p">,</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'First column: '</span><span class="p">,</span> <span class="n">tensor</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Last column:'</span><span class="p">,</span> <span class="n">tensor</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">tensor</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>First row:  tensor([1., 1., 1., 1.])
First column:  tensor([1., 1., 1., 1.])
Last column: tensor([1., 1., 1., 1.])
tensor([[1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 1., 1.]])
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Joining-tensors">
<a class="anchor" href="#Joining-tensors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Joining tensors<a class="anchor-link" href="#Joining-tensors"> </a>
</h3>
<p>You can use <code>torch.cat</code> to concatenate a sequence of tensors along a given dimension.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">tensor</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">tensor</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],
        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],
        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],
        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Arithmetic-operations">
<a class="anchor" href="#Arithmetic-operations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Arithmetic operations<a class="anchor-link" href="#Arithmetic-operations"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y1</span> <span class="o">=</span> <span class="n">tensor</span> <span class="o">@</span> <span class="n">tensor</span><span class="o">.</span><span class="n">T</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">z1</span> <span class="o">=</span> <span class="n">tensor</span> <span class="o">*</span> <span class="n">tensor</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Single-element-tensors">
<a class="anchor" href="#Single-element-tensors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Single-element tensors<a class="anchor-link" href="#Single-element-tensors"> </a>
</h3>
<p>If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using <code>item()</code>:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">agg</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">agg_item</span> <span class="o">=</span> <span class="n">agg</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">agg_item</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">agg_item</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>12.0 &lt;class 'float'&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="2.-DATASETS-&amp;-DATALOADERS">
<a class="anchor" href="#2.-DATASETS-&amp;-DATALOADERS" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. DATASETS &amp; DATALOADERS<a class="anchor-link" href="#2.-DATASETS-&amp;-DATALOADERS"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<code>Dataset</code> stores the samples and their corresponding labels, and <code>DataLoader</code> wraps an iterable around the <code>Dataset</code> to enable easy access to the samples.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loading-a-Dataset-데이터셋-불러오기">
<a class="anchor" href="#Loading-a-Dataset-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loading a Dataset 데이터셋 불러오기<a class="anchor-link" href="#Loading-a-Dataset-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>TorchVision 에서 Fashion-MNIST 데이터셋을 불러오는 예제를 살펴보겠습니다. Fashion-MNIST는 Zalando의 기사 이미지 데이터셋으로 60,000개의 학습 예제와 10,000개의 테스트 예제로 이루어져 있습니다. 각 예제는 흑백(grayscale)의 28x28 이미지와 10개 분류(class) 중 하나인 정답(label)으로 구성됩니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We load the FashionMNIST Dataset with the following parameters:</p>
<ul>
<li>
<code>root</code> 는 학습/테스트 데이터가 저장되는 경로입니다.</li>
<li>
<code>train</code> 은 학습용 또는 테스트용 데이터셋 여부를 지정합니다.</li>
<li>
<code>download=True</code> 는 <code>root</code> 에 데이터가 없는 경우 인터넷에서 다운로드합니다.</li>
<li>
<code>transform</code> 과 <code>target_transform</code> 은 특징(feature)과 정답(label) 변형(transform)을 지정합니다.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="n">training_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">"data"</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">"data"</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\ksko\anaconda3\lib\site-packages\torchvision\io\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\Users\ksko\anaconda3\Lib\site-packages\torchvision\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
  warn(f"Failed to load image Python extension: {e}")
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Iterating-and-Visualizing-the-Dataset-데이터셋을-순회하고-시각화하기">
<a class="anchor" href="#Iterating-and-Visualizing-the-Dataset-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B%EC%9D%84-%EC%88%9C%ED%9A%8C%ED%95%98%EA%B3%A0-%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%98%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>Iterating and Visualizing the Dataset 데이터셋을 순회하고 시각화하기<a class="anchor-link" href="#Iterating-and-Visualizing-the-Dataset-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B%EC%9D%84-%EC%88%9C%ED%9A%8C%ED%95%98%EA%B3%A0-%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%98%EA%B8%B0"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>Dataset</code> 에 리스트(list)처럼 직접 접근(index)할 수 있습니다: <code>training_data[index]</code>. <code>matplotlib</code> 을 사용하여 학습 데이터의 일부를 시각화해보겠습니다..</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">labels_map</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s2">"T-Shirt"</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s2">"Trouser"</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s2">"Pullover"</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s2">"Dress"</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">:</span> <span class="s2">"Coat"</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">:</span> <span class="s2">"Sandal"</span><span class="p">,</span>
    <span class="mi">6</span><span class="p">:</span> <span class="s2">"Shirt"</span><span class="p">,</span>
    <span class="mi">7</span><span class="p">:</span> <span class="s2">"Sneaker"</span><span class="p">,</span>
    <span class="mi">8</span><span class="p">:</span> <span class="s2">"Bag"</span><span class="p">,</span>
    <span class="mi">9</span><span class="p">:</span> <span class="s2">"Ankle Boot"</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">cols</span><span class="p">,</span> <span class="n">rows</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">cols</span> <span class="o">*</span> <span class="n">rows</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">sample_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">img</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">training_data</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">]</span>
    <span class="n">figure</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">labels_map</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">"off"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Creating-a-Custom-Dataset-for-your-files">
<a class="anchor" href="#Creating-a-Custom-Dataset-for-your-files" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating a Custom Dataset for your files<a class="anchor-link" href="#Creating-a-Custom-Dataset-for-your-files"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>사용자 정의 Dataset 클래스는 반드시 3개 함수를 구현해야 합니다: __init<strong>, __len</strong>, and __getitem__. 아래 구현을 살펴보면 FashionMNIST 이미지들은 <code>img_dir</code> 디렉토리에 저장되고, 정답은 <code>annotations_file</code> csv 파일에 별도로 저장됩니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the next sections, we’ll break down what’s happening in each of these functions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">torchvision.io</span> <span class="kn">import</span> <span class="n">read_image</span>

<span class="k">class</span> <span class="nc">CustomImageDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">annotations_file</span><span class="p">,</span> <span class="n">img_dir</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">target_transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">annotations_file</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span> <span class="o">=</span> <span class="n">img_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_transform</span> <span class="o">=</span> <span class="n">target_transform</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_labels</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">img_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_labels</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">read_image</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_labels</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_transform</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_transform</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="__init__">
<a class="anchor" href="#__init__" aria-hidden="true"><span class="octicon octicon-link"></span></a>__init__<a class="anchor-link" href="#__init__"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>__init__  함수는 Dataset 객체가 생성(instantiate)될 때 한 번만 실행됩니다. 여기서는 이미지와 주석 파일(annotation_file)이 포함된 디렉토리와 (다음 장에서 자세히 살펴볼) 두가지 변형(transform)을 초기화합니다.</p>
<p>labels.csv 파일은 다음과 같습니다:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>tshirt1.jpg, 0
tshirt2.jpg, 0
......
ankleboot999.jpg, 9</code></pre>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">annotations_file</span><span class="p">,</span> <span class="n">img_dir</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">target_transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">img_labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">annotations_file</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">'file_name'</span><span class="p">,</span> <span class="s1">'label'</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span> <span class="o">=</span> <span class="n">img_dir</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target_transform</span> <span class="o">=</span> <span class="n">target_transform</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="__len__">
<a class="anchor" href="#__len__" aria-hidden="true"><span class="octicon octicon-link"></span></a>__len__<a class="anchor-link" href="#__len__"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>__len__ 함수는 데이터셋의 샘플 개수를 반환합니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Example:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="__getitem__">
<a class="anchor" href="#__getitem__" aria-hidden="true"><span class="octicon octicon-link"></span></a>__getitem__<a class="anchor-link" href="#__getitem__"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>__getitem__ 함수는 주어진 인덱스 <code>idx</code> 에 해당하는 샘플을 데이터셋에서 불러오고 반환합니다. 인덱스를 기반으로, 디스크에서 이미지의 위치를 식별하고, <code>read_image</code> 를 사용하여 이미지를 텐서로 변환하고, <code>self.img_labels</code> 의 csv 데이터로부터 해당하는 정답(label)을 가져오고, (해당하는 경우) 변형(transform) 함수들을 호출한 뒤, 텐서 이미지와 라벨을 Python 사전(dict)형으로 반환합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
    <span class="n">img_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_labels</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">read_image</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_labels</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_transform</span><span class="p">:</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_transform</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="DataLoader로-학습용-데이터-준비하기">
<a class="anchor" href="#DataLoader%EB%A1%9C-%ED%95%99%EC%8A%B5%EC%9A%A9-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A4%80%EB%B9%84%ED%95%98%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>DataLoader로 학습용 데이터 준비하기<a class="anchor-link" href="#DataLoader%EB%A1%9C-%ED%95%99%EC%8A%B5%EC%9A%A9-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A4%80%EB%B9%84%ED%95%98%EA%B8%B0"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>Dataset</code> 은 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한 번에 합니다. 모델을 학습할 때, 일반적으로 샘플들을 “미니배치(minibatch)”로 전달하고, 매 에폭(epoch)마다 데이터를 다시 섞어서 과적합(overfit)을 막고, Python의 <code>multiprocessing</code> 을 사용하여 데이터 검색 속도를 높이려고 합니다.</p>
<p>DataLoader 는 간단한 API로 이러한 복잡한 과정들을 추상화한 순회 가능한 객체(iterable)입니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="DataLoader를-통해-순회하기(iterate)">
<a class="anchor" href="#DataLoader%EB%A5%BC-%ED%86%B5%ED%95%B4-%EC%88%9C%ED%9A%8C%ED%95%98%EA%B8%B0(iterate)" aria-hidden="true"><span class="octicon octicon-link"></span></a>DataLoader를 통해 순회하기(iterate)<a class="anchor-link" href="#DataLoader%EB%A5%BC-%ED%86%B5%ED%95%B4-%EC%88%9C%ED%9A%8C%ED%95%98%EA%B8%B0(iterate)"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>DataLoader</code> 에 데이터셋을 불러온 뒤에는 필요에 따라 데이터셋을 순회(iterate)할 수 있습니다. 아래의 각 순회(iteration)는 (각각 <code>batch_size=64</code> 의 특징(feature)과 정답(label)을 포함하는) <code>train_features</code> 와 <code>train_labels</code> 의 묶음(batch)을 반환합니다. <code>shuffle=True</code> 로 지정했으므로, 모든 배치를 순회한 뒤 데이터가 섞입니다. (데이터 불러오기 순서를 보다 세밀하게(finer-grained) 제어하려면 Samplers 를 살펴보세요.)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 이미지와 정답(label)을 표시합니다.</span>
<span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Feature batch shape: </span><span class="si">{</span><span class="n">train_features</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Labels batch shape: </span><span class="si">{</span><span class="n">train_labels</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">train_features</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Label: </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="c1"># ```</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Feature batch shape: torch.Size([64, 1, 28, 28])
Labels batch shape: torch.Size([64])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Label: 6
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="3.-TRANSFORM">
<a class="anchor" href="#3.-TRANSFORM" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. TRANSFORM<a class="anchor-link" href="#3.-TRANSFORM"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>데이터가 항상 머신러닝 알고리즘 학습에 필요한 최종 처리가 된 형태로 제공되지는 않습니다. <strong>변형(transform)</strong> 을 해서 데이터를 조작하고 학습에 적합하게 만듭니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>모든 TorchVision 데이터셋들은 변형 로직을 갖는, 호출 가능한 객체(callable)를 받는 매개변수 두개 ( 특징(feature)을 변경하기 위한 <code>transform</code> 과 정답(label)을 변경하기 위한 <code>target_transform</code> )를 갖습니다 torchvision.transforms 모듈은 주로 사용하는 몇가지 변형(transform)을 제공합니다.</p>
<p>FashionMNIST 특징(feature)은 PIL Image 형식이며, 정답(label)은 정수(integer)입니다. 학습을 하려면 정규화(normalize)된 텐서 형태의 특징(feature)과 원-핫(one-hot)으로 부호화(encode)된 텐서 형태의 정답(label)이 필요합니다. 이러한 변형(transformation)을 하기 위해 <code>ToTensor</code> 와 <code>Lambda</code> 를 사용합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span><span class="p">,</span> <span class="n">Lambda</span>

<span class="n">ds</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">"data"</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">target_transform</span><span class="o">=</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="ToTensor()">
<a class="anchor" href="#ToTensor()" aria-hidden="true"><span class="octicon octicon-link"></span></a>ToTensor()<a class="anchor-link" href="#ToTensor()"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>ToTensor 는 PIL Image나 NumPy <code>ndarray</code> 를 <code>FloatTensor</code> 로 변환하고, 이미지의 픽셀의 크기(intensity) 값을 [0., 1.] 범위로 비례하여 조정(scale)합니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Lambda-변형(Transform)">
<a class="anchor" href="#Lambda-%EB%B3%80%ED%98%95(Transform)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Lambda 변형(Transform)<a class="anchor-link" href="#Lambda-%EB%B3%80%ED%98%95(Transform)"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lambda 변형은 사용자 정의 람다(lambda) 함수를 적용합니다. 여기에서는 정수를 원-핫으로 부호화된 텐서로 바꾸는 함수를 정의합니다. 이 함수는 먼저 (데이터셋 정답의 개수인) 크기 10짜리 영 텐서(zero tensor)를 만들고, scatter_ 를 호출하여 주어진 정답 <code>y</code> 에 해당하는 인덱스에 <code>value=1</code> 을 할당합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">target_transform</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
    <span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="4.-신경망-모델-구성하기">
<a class="anchor" href="#4.-%EC%8B%A0%EA%B2%BD%EB%A7%9D-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%EC%84%B1%ED%95%98%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. 신경망 모델 구성하기<a class="anchor-link" href="#4.-%EC%8B%A0%EA%B2%BD%EB%A7%9D-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%EC%84%B1%ED%95%98%EA%B8%B0"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>신경망은 데이터에 대한 연산을 수행하는 계층(layer)/모듈(module)로 구성되어 있습니다. torch.nn 네임스페이스는 신경망을 구성하는데 필요한 모든 구성 요소를 제공합니다. PyTorch의 모든 모듈은 nn.Module 의 하위 클래스(subclass) 입니다. 신경망은 다른 모듈(계층; layer)로 구성된 모듈입니다. 이러한 중첩된 구조는 복잡한 아키텍처를 쉽게 구축하고 관리할 수 있습니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이어지는 장에서는 FashionMNIST 데이터셋의 이미지들을 분류하는 신경망을 구성해보겠습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="학습을-위한-장치-얻기">
<a class="anchor" href="#%ED%95%99%EC%8A%B5%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%9E%A5%EC%B9%98-%EC%96%BB%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>학습을 위한 장치 얻기<a class="anchor-link" href="#%ED%95%99%EC%8A%B5%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%9E%A5%EC%B9%98-%EC%96%BB%EA%B8%B0"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>가능한 경우 GPU와 같은 하드웨어 가속기에서 모델을 학습하려고 합니다. torch.cuda 를 사용할 수 있는지 확인하고 그렇지 않으면 CPU를 계속 사용합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s1"> device'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Using cpu device
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="클래스-정의하기">
<a class="anchor" href="#%ED%81%B4%EB%9E%98%EC%8A%A4-%EC%A0%95%EC%9D%98%ED%95%98%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>클래스 정의하기<a class="anchor-link" href="#%ED%81%B4%EB%9E%98%EC%8A%A4-%EC%A0%95%EC%9D%98%ED%95%98%EA%B8%B0"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>신경망 모델을 <code>nn.Module</code> 의 하위클래스로 정의하고, __init__ 에서 신경망 계층들을 초기화합니다. <code>nn.Module</code> 을 상속받은 모든 클래스는 <code>forward</code> 메소드에 입력 데이터에 대한 연산들을 구현합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">NeuralNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NeuralNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>NeuralNetwork</code> 의 인스턴스(instance)를 생성하고 이를 <code>device</code> 로 이동한 뒤, 구조(structure)를 출력합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNetwork</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>모델을 사용하기 위해 입력 데이터를 전달합니다. 이는 일부 백그라운드 연산들 과 함께 모델의 <code>forward</code> 를 실행합니다. <code>model.forward()</code> 를 직접 호출하지 마세요!</p>
<p>모델에 입력을 호출하면 각 분류(class)에 대한 원시(raw) 예측값이 있는 10-차원 텐서가 반환됩니다. 원시 예측값을 <code>nn.Softmax</code> 모듈의 인스턴스에 통과시켜 예측 확률을 얻습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">pred_probab</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">logits</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">pred_probab</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Predicted class: </span><span class="si">{</span><span class="n">y_pred</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Predicted class: tensor([3])
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="모델-계층(Layer)">
<a class="anchor" href="#%EB%AA%A8%EB%8D%B8-%EA%B3%84%EC%B8%B5(Layer)" aria-hidden="true"><span class="octicon octicon-link"></span></a>모델 계층(Layer)<a class="anchor-link" href="#%EB%AA%A8%EB%8D%B8-%EA%B3%84%EC%B8%B5(Layer)"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>FashionMNIST 모델의 계층들을 살펴보겠습니다. 이를 설명하기 위해, 28x28 크기의 이미지 3개로 구성된 미니배치를 가져와, 신경망을 통과할 때 어떤 일이 발생하는지 알아보겠습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">input_image</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([3, 28, 28])
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="nn.Flatten">
<a class="anchor" href="#nn.Flatten" aria-hidden="true"><span class="octicon octicon-link"></span></a>nn.Flatten<a class="anchor-link" href="#nn.Flatten"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>nn.Flatten 계층을 초기화하여 각 28x28의 2D 이미지를 784 픽셀 값을 갖는 연속된 배열로 변환합니다. (dim=0의 미니배치 차원은 유지됩니다.)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<span class="n">flat_image</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">flat_image</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([3, 784])
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="nn.Linear">
<a class="anchor" href="#nn.Linear" aria-hidden="true"><span class="octicon octicon-link"></span></a>nn.Linear<a class="anchor-link" href="#nn.Linear"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>선형 계층 은 저장된 가중치(weight)와 편향(bias)을 사용하여 입력에 선형 변환(linear transformation)을 적용하는 모듈입니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">hidden1</span> <span class="o">=</span> <span class="n">layer1</span><span class="p">(</span><span class="n">flat_image</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">hidden1</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([3, 20])
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="nn.ReLU">
<a class="anchor" href="#nn.ReLU" aria-hidden="true"><span class="octicon octicon-link"></span></a>nn.ReLU<a class="anchor-link" href="#nn.ReLU"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>비선형 활성화(activation)는 모델의 입력과 출력 사이에 복잡한 관계(mapping)를 만듭니다. 비선형 활성화는 선형 변환 후에 적용되어 비선형성(nonlinearity) 을 도입하고, 신경망이 다양한 현상을 학습할 수 있도록 돕습니다.</p>
<p>이 모델에서는 nn.ReLU 를 선형 계층들 사이에 사용하지만, 모델을 만들 때는 비선형성을 가진 다른 활성화를 도입할 수도 있습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Before ReLU: </span><span class="si">{</span><span class="n">hidden1</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">"</span><span class="p">)</span>
<span class="n">hidden1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()(</span><span class="n">hidden1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"After ReLU: </span><span class="si">{</span><span class="n">hidden1</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Before ReLU: tensor([[ 0.1359, -0.3299, -0.1970,  0.5196, -0.0813, -0.2173, -0.1096, -0.0631,
         -0.0354,  0.2562, -0.1485, -0.5210,  0.2318, -0.2634,  0.7257, -0.1972,
         -0.3673, -0.4046, -0.0340, -0.5271],
        [ 0.1564, -0.3985,  0.1940,  0.4656,  0.3421, -0.4703, -0.2136, -0.1095,
         -0.2515,  0.0601, -0.3461, -0.7769,  0.2142, -0.0464,  0.9571, -0.1961,
          0.2188, -0.0828,  0.0039, -0.4262],
        [ 0.0486, -0.0440,  0.4727,  0.3145, -0.2762, -0.1264, -0.4441,  0.0866,
         -0.2323, -0.0479, -0.0198, -0.4986,  0.0509, -0.0111,  0.7532, -0.3162,
         -0.1697, -0.0800,  0.0344, -0.3996]], grad_fn=&lt;AddmmBackward0&gt;)


After ReLU: tensor([[0.1359, 0.0000, 0.0000, 0.5196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.2562, 0.0000, 0.0000, 0.2318, 0.0000, 0.7257, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000],
        [0.1564, 0.0000, 0.1940, 0.4656, 0.3421, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0601, 0.0000, 0.0000, 0.2142, 0.0000, 0.9571, 0.0000, 0.2188, 0.0000,
         0.0039, 0.0000],
        [0.0486, 0.0000, 0.4727, 0.3145, 0.0000, 0.0000, 0.0000, 0.0866, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0509, 0.0000, 0.7532, 0.0000, 0.0000, 0.0000,
         0.0344, 0.0000]], grad_fn=&lt;ReluBackward0&gt;)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="nn.Sequential">
<a class="anchor" href="#nn.Sequential" aria-hidden="true"><span class="octicon octicon-link"></span></a>nn.Sequential<a class="anchor-link" href="#nn.Sequential"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>nn.Sequential 은 순서를 갖는 모듈의 컨테이너입니다. 데이터는 정의된 것과 같은 순서로 모든 모듈들을 통해 전달됩니다. 순차 컨테이너(sequential container)를 사용하여 아래의 <code>seq_modules</code> 와 같은 신경망을 빠르게 만들 수 있습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seq_modules</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">flatten</span><span class="p">,</span>
    <span class="n">layer1</span><span class="p">,</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">input_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">seq_modules</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="nn.Softmax">
<a class="anchor" href="#nn.Softmax" aria-hidden="true"><span class="octicon octicon-link"></span></a>nn.Softmax<a class="anchor-link" href="#nn.Softmax"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>신경망의 마지막 선형 계층은 nn.Softmax 모듈에 전달될 ([-infty, infty] 범위의 원시 값(raw value)인) logits 를 반환합니다. logits는 모델의 각 분류(class)에 대한 예측 확률을 나타내도록 [0, 1] 범위로 비례하여 조정(scale)됩니다. <code>dim</code> 매개변수는 값의 합이 1이 되는 차원을 나타냅니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pred_probab</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="모델-매개변수">
<a class="anchor" href="#%EB%AA%A8%EB%8D%B8-%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98" aria-hidden="true"><span class="octicon octicon-link"></span></a>모델 매개변수<a class="anchor-link" href="#%EB%AA%A8%EB%8D%B8-%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>신경망 내부의 많은 계층들은 매개변수화(parameterize) 됩니다. 즉, 학습 중에 최적화되는 가중치와 편향과 연관지어집니다. <code>nn.Module</code> 을 상속하면 모델 객체 내부의 모든 필드들이 자동으로 추적(track)되며, 모델의 <code>parameters()</code> 및 <code>named_parameters()</code> 메소드로 모든 매개변수에 접근할 수 있게 됩니다.</p>
<p>이 예제에서는 각 매개변수들을 순회하며(iterate), 매개변수의 크기와 값을 출력합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"Model structure: "</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n\n</span><span class="s2">"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Layer: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> | Size: </span><span class="si">{</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2"> | Values : </span><span class="si">{</span><span class="n">param</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model structure:  NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
) 


Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0313, -0.0301, -0.0258,  ...,  0.0281,  0.0342,  0.0187],
        [ 0.0338,  0.0077,  0.0075,  ...,  0.0187,  0.0315,  0.0039]],
       grad_fn=&lt;SliceBackward0&gt;) 

Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0111, 0.0268], grad_fn=&lt;SliceBackward0&gt;) 

Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0409, -0.0326,  0.0223,  ...,  0.0191,  0.0215, -0.0205],
        [-0.0012,  0.0316, -0.0183,  ...,  0.0206, -0.0111, -0.0350]],
       grad_fn=&lt;SliceBackward0&gt;) 

Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0300,  0.0373], grad_fn=&lt;SliceBackward0&gt;) 

Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0060,  0.0204,  0.0370,  ..., -0.0408,  0.0104,  0.0433],
        [ 0.0021, -0.0366, -0.0415,  ...,  0.0363,  0.0430,  0.0140]],
       grad_fn=&lt;SliceBackward0&gt;) 

Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0413, -0.0108], grad_fn=&lt;SliceBackward0&gt;) 

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="5.-Autograd">
<a class="anchor" href="#5.-Autograd" aria-hidden="true"><span class="octicon octicon-link"></span></a>5. Autograd<a class="anchor-link" href="#5.-Autograd"> </a>
</h1>
<p><code>TORCH.AUTOGRAD</code>를 사용한 자동 미분</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>신경망을 학습할 때 가장 자주 사용되는 알고리즘은 <strong>역전파</strong>입니다. 이 알고리즘에서, 매개변수(모델 가중치)는 주어진 매개변수에 대한 손실 함수의 <strong>변화도(gradient)</strong> 에 따라 조정됩니다.</p>
<p>이러한 변화도를 계산하기 위해 PyTorch에는 <code>torch.autograd</code>라고 불리는 자동 미분 엔진이 내장되어 있습니다. 이는 모든 계산 그래프에 대한 변화도의 자동 계산을 지원합니다.</p>
<p>입력 <code>x</code>, 매개변수 <code>w</code>와 <code>b</code> , 그리고 일부 손실 함수가 있는 가장 간단한 단일 계층 신경망을 가정하겠습니다. PyTorch에서는 다음과 같이 정의할 수 있습니다:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># input tensor</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># expected output</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tensor,-Function과-연산그래프(Computational-graph)">
<a class="anchor" href="#Tensor,-Function%EA%B3%BC-%EC%97%B0%EC%82%B0%EA%B7%B8%EB%9E%98%ED%94%84(Computational-graph)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tensor, Function과 연산그래프(Computational graph)<a class="anchor-link" href="#Tensor,-Function%EA%B3%BC-%EC%97%B0%EC%82%B0%EA%B7%B8%EB%9E%98%ED%94%84(Computational-graph)"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이 신경망에서, <code>w</code>와 <code>b</code>는 최적화를 해야 하는 <strong>매개변수</strong> 입니다. 따라서 이러한 변수들에 대한 손실 함수의 변화도를 계산할 수 있어야 합니다. 이를 위해서 해당 텐서에 <code>requires_grad</code> 속성을 설정합니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>note</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>requires_grad</code>의 값은 텐서를 생성할 때 설정하거나, 나중에 <code>x.requires_grad_(True)</code> 메소드를 사용하여 나중에 설정할 수도 있습니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>연산 그래프를 구성하기 위해 텐서에 적용하는 함수는 사실 <code>Function</code> 클래스의 객체입니다. 이 객체는 순전파 방향으로 함수를 계산하는 방법과, 역방향 전파 단계에서 도함수(derivative)를 계산하는 방법을 알고 있습니다. 역방향 전파 함수에 대한 참조(reference)는 텐서의 <code>grad_fn</code> 속성에 저장됩니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Gradient function for z ='</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Gradient function for loss ='</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Gradient function for z = &lt;AddBackward0 object at 0x000001AFC94B79D0&gt;
Gradient function for loss = &lt;BinaryCrossEntropyWithLogitsBackward0 object at 0x000001AFC94B7160&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="변화도(Gradient)-계산하기">
<a class="anchor" href="#%EB%B3%80%ED%99%94%EB%8F%84(Gradient)-%EA%B3%84%EC%82%B0%ED%95%98%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>변화도(Gradient) 계산하기<a class="anchor-link" href="#%EB%B3%80%ED%99%94%EB%8F%84(Gradient)-%EA%B3%84%EC%82%B0%ED%95%98%EA%B8%B0"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>신경망에서 매개변수의 가중치를 최적화하려면 매개변수에 대한 손실함수의 도함수(derivative)를 계산해야 합니다. 즉, <code>x</code>와 <code>y</code>의 일부 고정값에서 $\frac{\partial loss}{\partial w} $ 와 $\frac{\partial loss}{\partial b} $ 가 필요합니다. 이러한 도함수를 계산하기 위해, loss.backward() 를 호출한 다음 w.grad와 b.grad에서 값을 가져옵니다:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[0.1565, 0.2825, 0.3122],
        [0.1565, 0.2825, 0.3122],
        [0.1565, 0.2825, 0.3122],
        [0.1565, 0.2825, 0.3122],
        [0.1565, 0.2825, 0.3122]])
tensor([0.1565, 0.2825, 0.3122])
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong><em>NOTE</em></strong></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>연산 그래프의 잎(leaf) 노드들 중 <code>requires_grad</code> 속성이 <code>True</code>로 설정된 노드들의 <code>grad</code> 속성만 구할 수 있습니다. 그래프의 다른 모든 노드에서는 변화도가 유효하지 않습니다.</p>
<p>성능 상의 이유로, 주어진 그래프에서의 <code>backward</code>를 사용한 변화도 계산은 한 번만 수행할 수 있습니다. 만약 동일한 그래프에서 여러번의 <code>backward</code> 호출이 필요하면, <code>backward</code> 호출 시에 <code>retrain_graph=True</code>를 전달해야 합니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="변화도-추적-멈추기">
<a class="anchor" href="#%EB%B3%80%ED%99%94%EB%8F%84-%EC%B6%94%EC%A0%81-%EB%A9%88%EC%B6%94%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>변화도 추적 멈추기<a class="anchor-link" href="#%EB%B3%80%ED%99%94%EB%8F%84-%EC%B6%94%EC%A0%81-%EB%A9%88%EC%B6%94%EA%B8%B0"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>기본적으로, <code>requires_grad=True</code>인 모든 텐서들은 연산 기록을 추적하고 변화도 계산을 지원합니다. 그러나 모델을 학습한 뒤 입력 데이터를 단순히 적용하기만 하는 경우와 같이 순전파 연산만 필요한 경우에는, 이러한 추적이나 지원이 필요없을 수 있습니다. 연산 코드를 <code>torch.no_grad()</code> 블록으로 둘러싸서 연산 추적을 멈출 수 있습니다:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>True
False
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>동일한 결과를 얻는 다른 방법은 텐서에 <code>detach()</code> 메소드를 사용하는 것입니다:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="n">z_det</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">z_det</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>False
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>변화도 추적을 멈춰야 하는 이유들은 다음과 같습니다:</p>
<ul>
<li>신경망의 일부 매개변수를 <strong>고정된 매개변수(frozen parameter)</strong> 로 표시합니다. 이는 사전 학습된 신경망을 미세조정 할 때 매우 일반적인 시나리오입니다.</li>
<li>변화도를 추적하지 않는 텐서의 연산이 더 효율적이기 때문에, 순전파 단계만 수행할 때 <strong>연산 속도가 향상됩니다.</strong>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="연산-그래프에-대한-추가-정보">
<a class="anchor" href="#%EC%97%B0%EC%82%B0-%EA%B7%B8%EB%9E%98%ED%94%84%EC%97%90-%EB%8C%80%ED%95%9C-%EC%B6%94%EA%B0%80-%EC%A0%95%EB%B3%B4" aria-hidden="true"><span class="octicon octicon-link"></span></a>연산 그래프에 대한 추가 정보<a class="anchor-link" href="#%EC%97%B0%EC%82%B0-%EA%B7%B8%EB%9E%98%ED%94%84%EC%97%90-%EB%8C%80%ED%95%9C-%EC%B6%94%EA%B0%80-%EC%A0%95%EB%B3%B4"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>개념적으로, autograd는 데이터(텐서)의 및 실행된 모든 연산들(및 연산 결과가 새로운 텐서인 경우도 포함하여)의 기록을 Function 객체로 구성된 방향성 비순환 그래프(DAG; Directed Acyclic Graph)에 저장(keep)합니다. 이 방향성 비순환 그래프(DAG)의 잎(leave)은 입력 텐서이고, 뿌리(root)는 결과 텐서입니다. 이 그래프를 뿌리에서부터 잎까지 추적하면 연쇄 법칙(chain rule)에 따라 변화도를 자동으로 계산할 수 있습니다.</p>
<p>순전파 단계에서, autograd는 다음 두 가지 작업을 동시에 수행합니다:</p>
<ul>
<li>요청된 연산을 수행하여 결과 텐서를 계산하고,</li>
<li>DAG에 연산의 변화도 기능(gradient function) 를 유지(maintain)합니다.</li>
</ul>
<p>역전파 단계는 DAG 뿌리(root)에서 .backward() 가 호출될 때 시작됩니다. autograd는 이 때:</p>
<ul>
<li>각 .grad_fn 으로부터 변화도를 계산하고,</li>
<li>각 텐서의 .grad 속성에 계산 결과를 쌓고(accumulate),</li>
<li>연쇄 법칙을 사용하여, 모든 잎(leaf) 텐서들까지 전파(propagate)합니다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong><em>NOTE</em></strong></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>PyTorch에서 DAG들은 동적(dynamic)입니다.</strong> 주목해야 할 중요한 점은 그래프가 처음부터(from scratch) 다시 생성된다는 것입니다; 매번 <code>.bachward()</code> 가 호출되고 나면, autograd는 새로운 그래프를 채우기(populate) 시작합니다. 이러한 점 덕분에 모델에서 흐름 제어(control flow) 구문들을 사용할 수 있게 되는 것입니다; 매번 반복(iteration)할 때마다 필요하면 모양(shape)이나 크기(size), 연산(operation)을 바꿀 수 있습니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="선택적으로-읽기(Optional-Reading):-텐서-변화도와-야코비안-곱-(Jacobian-Product)">
<a class="anchor" href="#%EC%84%A0%ED%83%9D%EC%A0%81%EC%9C%BC%EB%A1%9C-%EC%9D%BD%EA%B8%B0(Optional-Reading):-%ED%85%90%EC%84%9C-%EB%B3%80%ED%99%94%EB%8F%84%EC%99%80-%EC%95%BC%EC%BD%94%EB%B9%84%EC%95%88-%EA%B3%B1-(Jacobian-Product)" aria-hidden="true"><span class="octicon octicon-link"></span></a>선택적으로 읽기(Optional Reading): 텐서 변화도와 야코비안 곱 (Jacobian Product)<a class="anchor-link" href="#%EC%84%A0%ED%83%9D%EC%A0%81%EC%9C%BC%EB%A1%9C-%EC%9D%BD%EA%B8%B0(Optional-Reading):-%ED%85%90%EC%84%9C-%EB%B3%80%ED%99%94%EB%8F%84%EC%99%80-%EC%95%BC%EC%BD%94%EB%B9%84%EC%95%88-%EA%B3%B1-(Jacobian-Product)"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>대부분의 경우, 스칼라 손실 함수를 가지고 일부 매개변수와 관련한 변화도를 계산해야 합니다. 그러나 출력 함수가 임의의 텐서인 경우가 있습니다. 이럴 때, PyTorch는 실제 변화도가 아닌 <strong>야코비안 곱(Jacobian product)</strong> 을 계산합니다.</p>
<p>$\vec{x}=\langle x_1,\dots,x_n\rangle $이고, $\vec{y}=\langle y_1,\dots,y_m\rangle$ 일 때 벡터 함수 $\vec{y}=f(\vec{x})$에서 $\vec{x}$ 
 에 대한 $\vec{y}$의 변화도는 <strong>야코비안 행렬(Jacobian matrix)</strong> 로 주어집니다:</p>
<p>$J=\left(\begin{array}{ccc} \frac{\partial y_{1}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{1}}{\partial x_{n}}\\ \vdots &amp; \ddots &amp; \vdots\\ \frac{\partial y_{m}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{n}} \end{array}\right)
$</p>
<p>야코비안 행렬 자체를 계산하는 대신, PyTorch는 주어진 입력 벡터 $v=(v_1 \dots v_m)$에 대한 <strong>야코비안 곱(Jacobian Product)</strong> $v^T\cdot J$을 계산합니다. 이 과정은 vv를 인자로 backward를 호출하면 이뤄집니다. $v$의 크기는 곱(product)을 계산하려고 하는 원래 텐서의 크기와 같아야 합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="n">inp</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">out</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">inp</span><span class="p">),</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"First call</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">inp</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
<span class="n">out</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">inp</span><span class="p">),</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Second call</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">inp</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
<span class="n">inp</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">out</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">inp</span><span class="p">),</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Call after zeroing gradients</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">inp</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>First call
 tensor([[4., 2., 2., 2., 2.],
        [2., 4., 2., 2., 2.],
        [2., 2., 4., 2., 2.],
        [2., 2., 2., 4., 2.],
        [2., 2., 2., 2., 4.]])

Second call
 tensor([[8., 4., 4., 4., 4.],
        [4., 8., 4., 4., 4.],
        [4., 4., 8., 4., 4.],
        [4., 4., 4., 8., 4.],
        [4., 4., 4., 4., 8.]])

Call after zeroing gradients
 tensor([[4., 2., 2., 2., 2.],
        [2., 4., 2., 2., 2.],
        [2., 2., 4., 2., 2.],
        [2., 2., 2., 4., 2.],
        [2., 2., 2., 2., 4.]])
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>동일한 인자로<code>backward</code>를 두차례 호출하면 변화도 값이 달라집니다. 이는 <code>역방향</code> 전파를 수행할 때, PyTorch가 <strong>변화도를 누적(accumulate)해두기 때문</strong> 입니다. 즉, 계산된 변화도의 값이 연산 그래프의 모든 잎(leaf) 노드의 <code>grad</code> 속성에 추가됩니다. 따라서 제대로된 변화도를 계산하기 위해서는 <code>grad</code> 속성을 먼저 0으로 만들어야 합니다. 실제 학습 과정에서는 <em>옵티마이저(optimizer)</em> 가 이 과정을 도와줍니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong>NOTE</strong></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이전에는 매개변수 없이 <code>backward()</code> 함수를 호출했습니다. 이는 본질적으로 <code>backward(torch.tensor(1.0))</code> 을 호출하는 것과 동일하며, 신경망 훈련 중의 손실과 같은 스칼라-값 함수의 변화도를 계산하는 유용한 방법입니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="6.-Optimization">
<a class="anchor" href="#6.-Optimization" aria-hidden="true"><span class="octicon octicon-link"></span></a>6. Optimization<a class="anchor-link" href="#6.-Optimization"> </a>
</h1>
<p>모델 매개변수 최적화하기</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이제 모델과 데이터가 준비되었으니, 데이터에 매개변수를 최적화하여 모델을 학습하고, 검증하고, 테스트할 차례입니다. 모델을 학습하는 과정은 반복적인 과정을 거칩니다; (에폭(epoch)이라고 부르는) 각 반복 단계에서 모델은 출력을 추측하고, 추측과 정답 사이의 오류(손실(loss))를 계산하고, (이전 장에서 본 것처럼) 매개변수에 대한 오류의 도함수(derivative)를 수집한 뒤, 경사하강법을 사용하여 이 파라매터들을 <strong>최적화(optimize)</strong> 합니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="기본(Pre-requisite)-코드">
<a class="anchor" href="#%EA%B8%B0%EB%B3%B8(Pre-requisite)-%EC%BD%94%EB%93%9C" aria-hidden="true"><span class="octicon octicon-link"></span></a>기본(Pre-requisite) 코드<a class="anchor-link" href="#%EA%B8%B0%EB%B3%B8(Pre-requisite)-%EC%BD%94%EB%93%9C"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이전 장인 Dataset과 DataLoader와 신경망 모델 구성하기에서 코드를 기져왔습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span><span class="p">,</span> <span class="n">Lambda</span>

<span class="n">training_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">"data"</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">"data"</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">NeuralNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NeuralNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNetwork</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="하이퍼파라매터(Hyperparameter)">
<a class="anchor" href="#%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%A7%A4%ED%84%B0(Hyperparameter)" aria-hidden="true"><span class="octicon octicon-link"></span></a>하이퍼파라매터(Hyperparameter)<a class="anchor-link" href="#%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%A7%A4%ED%84%B0(Hyperparameter)"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>하이퍼파라매터(Hyperparameter)는 모델 최적화 과정을 제어할 수 있는 조절 가능한 매개변수입니다. 서로 다른 하이퍼파라매터 값은 모델 학습과 수렴율(convergence rate)에 영향을 미칠 수 있습니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>학습 시에는 다음과 같은 하이퍼파라매터를 정의합니다:</p>
<ul>
<li>
<strong>에폭(epoch) 수</strong> - 데이터셋을 반복하는 횟수</li>
<li>
<strong>배치 크기(batch size)</strong> - 매개변수가 갱신되기 전 신경망을 통해 전파된 데이터 샘플의 수</li>
<li>
<strong>학습률(learning rate)</strong> - 각 배치/에폭에서 모델의 매개변수를 조절하는 비율. 값이 작을수록 학습 속도가 느려지고, 값이 크면 학습 중 예측할 수 없는 동작이 발생할 수 있습니다.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="최적화-단계(Optimization-Loop)">
<a class="anchor" href="#%EC%B5%9C%EC%A0%81%ED%99%94-%EB%8B%A8%EA%B3%84(Optimization-Loop)" aria-hidden="true"><span class="octicon octicon-link"></span></a>최적화 단계(Optimization Loop)<a class="anchor-link" href="#%EC%B5%9C%EC%A0%81%ED%99%94-%EB%8B%A8%EA%B3%84(Optimization-Loop)"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>하이퍼파라매터를 설정한 뒤에는 최적화 단계를 통해 모델을 학습하고 최적화할 수 있습니다. 최적화 단계의 각 반복(iteration)을 <strong>에폭</strong> 이라고 부릅니다.</p>
<p>하나의 에폭은 다음 두 부분으로 구성됩니다:</p>
<ul>
<li>
<strong>학습 단계(train loop)</strong> - 학습용 데이터셋을 반복(iterate)하고 최적의 매개변수로 수렴합니다.</li>
<li>
<strong>검증/테스트 단계(validation/test loop)</strong> - 모델 성능이 개선되고 있는지를 확인하기 위해 테스트 데이터셋을 반복(iterate)합니다.</li>
</ul>
<p>학습 단계(training loop)에서 일어나는 몇 가지 개념들을 간략히 살펴보겠습니다. 최적화 단계(optimization loop)를 보려면 전체 구현 부분으로 건너뛰시면 됩니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="손실-함수(loss-function)">
<a class="anchor" href="#%EC%86%90%EC%8B%A4-%ED%95%A8%EC%88%98(loss-function)" aria-hidden="true"><span class="octicon octicon-link"></span></a>손실 함수(loss function)<a class="anchor-link" href="#%EC%86%90%EC%8B%A4-%ED%95%A8%EC%88%98(loss-function)"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>학습용 데이터를 제공하면, 학습되지 않은 신경망은 정답을 제공하지 않을 확률이 높습니다. <strong>손실 함수(loss function)</strong> 는 획득한 결과와 실제 값 사이의 틀린 정도(degree of dissimilarity)를 측정하며, 학습 중에 이 값을 최소화하려고 합니다. 주어진 데이터 샘플을 입력으로 계산한 예측과 정답(label)을 비교하여 손실(loss)을 계산합니다.</p>
<p>일반적인 손실함수에는 회귀 문제(regression task)에 사용하는 <code>nn.MSELoss</code>(평균 제곱 오차(MSE; Mean Square Error))나 분류(classification)에 사용하는 <code>nn.NLLLoss</code> (음의 로그 우도(Negative Log Likelihood)), 그리고 nn.LogSoftmax와 nn.NLLLoss를 합친 <code>nn.CrossEntropyLoss</code> 등이 있습니다.</p>
<p>모델의 출력 로짓(logit)을 <code>nn.CrossEntropyLoss</code>에 전달하여 로짓(logit)을 정규화하고 예측 오류를 계산합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="옵티마이저(Optimizer)">
<a class="anchor" href="#%EC%98%B5%ED%8B%B0%EB%A7%88%EC%9D%B4%EC%A0%80(Optimizer)" aria-hidden="true"><span class="octicon octicon-link"></span></a>옵티마이저(Optimizer)<a class="anchor-link" href="#%EC%98%B5%ED%8B%B0%EB%A7%88%EC%9D%B4%EC%A0%80(Optimizer)"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>최적화는 각 학습 단계에서 모델의 오류를 줄이기 위해 모델 매개변수를 조정하는 과정입니다. <strong>최적화 알고리즘</strong> 은 이 과정이 수행되는 방식(여기에서는 확률적 경사하강법(SGD; Stochastic Gradient Descent))을 정의합니다. 모든 최적화 절차(logic)는 <code>optimizer</code> 객체에 캡슐화(encapsulate)됩니다. 여기서는 SGD 옵티마이저를 사용하고 있으며, PyTorch에는 ADAM이나 RMSProp과 같은 다른 종류의 모델과 데이터에서 더 잘 동작하는 다양한 옵티마이저가 있습니다.</p>
<p>학습하려는 모델의 매개변수와 학습률(learning rate) 하이퍼파라매터를 등록하여 옵티마이저를 초기화합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>학습 단계(loop)에서 최적화는 세단계로 이뤄집니다:</p>
<ul>
<li>
<code>optimizer.zero_grad()</code>를 호출하여 모델 매개변수의 변화도를 재설정합니다. 기본적으로 변화도는 더해지기(add up) 때문에 중복 계산을 막기 위해 반복할 때마다 명시적으로 0으로 설정합니다.</li>
<li>
<code>loss.backward()</code>를 호출하여 예측 손실(prediction loss)을 역전파합니다. PyTorch는 각 매개변수에 대한 손실의 변화도를 저장합니다.</li>
<li>변화도를 계산한 뒤에는 <code>optimizer.step()</code>을 호출하여 역전파 단계에서 수집된 변화도로 매개변수를 조정합니다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="전체-구현">
<a class="anchor" href="#%EC%A0%84%EC%B2%B4-%EA%B5%AC%ED%98%84" aria-hidden="true"><span class="octicon octicon-link"></span></a>전체 구현<a class="anchor-link" href="#%EC%A0%84%EC%B2%B4-%EA%B5%AC%ED%98%84"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>최적화 코드를 반복하여 수행하는 <code>train_loop</code>와 테스트 데이터로 모델의 성능을 측정하는 <code>test_loop</code>를 정의하였습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="c1"># 예측(prediction)과 손실(loss) 계산</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># 역전파</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">batch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">current</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">batch</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">&gt;7f</span><span class="si">}</span><span class="s2">  [</span><span class="si">{</span><span class="n">current</span><span class="si">:</span><span class="s2">&gt;5d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">size</span><span class="si">:</span><span class="s2">&gt;5d</span><span class="si">}</span><span class="s2">]"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">):</span>
    <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
    <span class="n">test_loss</span><span class="p">,</span> <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">test_loss</span> <span class="o">/=</span> <span class="n">num_batches</span>
    <span class="n">correct</span> <span class="o">/=</span> <span class="n">size</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Test Error: </span><span class="se">\n</span><span class="s2"> Accuracy: </span><span class="si">{</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">correct</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;0.1f</span><span class="si">}</span><span class="s2">%, Avg loss: </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="s2">&gt;8f</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>손실 함수와 옵티마이저를 초기화하고<code>train_loop</code>와 <code>test_loop</code>에 전달합니다. 모델의 성능 향상을 알아보기 위해 자유롭게 에폭(epoch) 수를 증가시켜 볼 수 있습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="se">\n</span><span class="s2">-------------------------------"</span><span class="p">)</span>
    <span class="n">train_loop</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
    <span class="n">test_loop</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Done!"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1
-------------------------------
loss: 2.311592  [    0/60000]
loss: 2.297346  [ 6400/60000]
loss: 2.274133  [12800/60000]
loss: 2.267290  [19200/60000]
loss: 2.257109  [25600/60000]
loss: 2.225945  [32000/60000]
loss: 2.242777  [38400/60000]
loss: 2.204943  [44800/60000]
loss: 2.208444  [51200/60000]
loss: 2.179492  [57600/60000]
Test Error: 
 Accuracy: 35.3%, Avg loss: 2.168912 

Epoch 2
-------------------------------
loss: 2.182533  [    0/60000]
loss: 2.172041  [ 6400/60000]
loss: 2.113595  [12800/60000]
loss: 2.132339  [19200/60000]
loss: 2.082709  [25600/60000]
loss: 2.022780  [32000/60000]
loss: 2.064435  [38400/60000]
loss: 1.978238  [44800/60000]
loss: 2.001753  [51200/60000]
loss: 1.930731  [57600/60000]
Test Error: 
 Accuracy: 51.1%, Avg loss: 1.919847 

Done!
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="7.-모델-저장하고-불러오기">
<a class="anchor" href="#7.-%EB%AA%A8%EB%8D%B8-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B3%A0-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>7. 모델 저장하고 불러오기<a class="anchor-link" href="#7.-%EB%AA%A8%EB%8D%B8-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B3%A0-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이번 장에서는 저장하기나 불러오기를 통해 모델의 상태를 유지(persist)하고 모델의 예측을 실행하는 방법을 알아보겠습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="모델-가중치-저장하고-불러오기">
<a class="anchor" href="#%EB%AA%A8%EB%8D%B8-%EA%B0%80%EC%A4%91%EC%B9%98-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B3%A0-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>모델 가중치 저장하고 불러오기<a class="anchor-link" href="#%EB%AA%A8%EB%8D%B8-%EA%B0%80%EC%A4%91%EC%B9%98-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B3%A0-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>PyTorch 모델은 학습한 매개변수를 <code>state_dict</code>라고 불리는 내부 상태 사전(internal state dictionary)에 저장합니다. 이 상태 값들은 <code>torch.save</code> 메소드를 사용하여 저장(persist)할 수 있습니다:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'model_weights.pth'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Downloading: "https://download.pytorch.org/models/vgg16-397923af.pth" to C:\Users\ksko/.cache\torch\hub\checkpoints\vgg16-397923af.pth
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>모델 가중치를 불러오기 위해서는, 먼저 동일한 모델의 인스턴스(instance)를 생성한 다음에 <code>load_state_dict()</code> 메소드를 사용하여 매개변수들을 불러옵니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg16</span><span class="p">()</span> <span class="c1"># 기본 가중치를 불러오지 않으므로 pretrained=True를 지정하지 않습니다.</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'model_weights.pth'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong>NOTE</strong></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>추론(inference)을 하기 전에 <code>model.eval()</code> 메소드를 호출하여 드롭아웃(dropout)과 배치 정규화(batch normalization)를 평가 모드(evaluation mode)로 설정해야 합니다. 그렇지 않으면 일관성 없는 추론 결과가 생성됩니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="모델의-형태를-포함하여-저장하고-불러오기">
<a class="anchor" href="#%EB%AA%A8%EB%8D%B8%EC%9D%98-%ED%98%95%ED%83%9C%EB%A5%BC-%ED%8F%AC%ED%95%A8%ED%95%98%EC%97%AC-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B3%A0-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>모델의 형태를 포함하여 저장하고 불러오기<a class="anchor-link" href="#%EB%AA%A8%EB%8D%B8%EC%9D%98-%ED%98%95%ED%83%9C%EB%A5%BC-%ED%8F%AC%ED%95%A8%ED%95%98%EC%97%AC-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B3%A0-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>모델의 가중치를 불러올 때, 신경망의 구조를 정의하기 위해 모델 클래스를 먼저 생성(instantiate)해야 했습니다. 이 클래스의 구조를 모델과 함께 저장하고 싶으면, (<code>model.state_dict()</code>가 아닌) <code>model</code> 을 저장 함수에 전달합니다:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'model.pth'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>다음과 같이 모델을 불러올 수 있습니다:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'model.pth'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong>NOTE</strong></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이 접근 방식은 Python pickle 모듈을 사용하여 모델을 직렬화(serialize)하므로, 모델을 불러올 때 실제 클래스 정의(definition)를 적용(rely on)합니다.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="star77sa/TIL-Blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/TIL-Blog/pytorch/2021/12/25/Pytorch.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/TIL-Blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/TIL-Blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/TIL-Blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>TIL-Blog</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/star77sa" title="star77sa"><svg class="svg-icon grey"><use xlink:href="/TIL-Blog/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
