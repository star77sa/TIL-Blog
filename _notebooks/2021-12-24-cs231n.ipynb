{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ideal-dragon",
   "metadata": {},
   "source": [
    "# CS231n_CNN for Visual Recognition\n",
    "> Stanford University CS231n\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Pytorch]\n",
    "- image: images/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-participant",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-bidding",
   "metadata": {},
   "source": [
    "- http://cs231n.stanford.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-interference",
   "metadata": {},
   "source": [
    "---\n",
    "# Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5ee35f-0717-40dc-894b-fde58e6fed37",
   "metadata": {},
   "source": [
    "- **Image Classification:** We are given a **Training Set** of labeled images, asked to predict labels on **Test Set.** Common to report the **Accuracy** of predictions(fraction of correctly predicted images)\n",
    "\n",
    "- We introduced the **k-Nearest Neighbor Classifier**, which predicts the labels based on nearest images in the training set\n",
    "\n",
    "- We saw that the choice of distance and the value of k are **hyperparameters** that are tuned using a **validation set**, or through **cross-validation** if the size of the data is small.\n",
    "\n",
    "- Once the best set of hyperparameters is chosen, the classifier is evaluated once on the test set, and reported as the performance of kNN on that data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7addedb3-7b0c-4d2e-ae66-5f0651f19789",
   "metadata": {},
   "source": [
    "- Nearest Neighbor 분류기는 CIFAR-10 데이터셋에서 약 40% 정도의 정확도를 보이는 것을 확인하였다. 이 방법은 구현이 매우 간단하지만, 학습 데이터셋 전체를 메모리에 저장해야 하고, 새로운 테스트 이미지를 분류하고 평가할 때 계산량이 매우 많다.\n",
    "\n",
    "- 단순히 픽셀 값들의 L1이나 L2 거리는 이미지의 클래스보다 배경이나 이미지의 전체적인 색깔 분포 등에 더 큰 영향을 받기 때문에 이미지 분류 문제에 있어서 충분하지 못하다는 점을 보았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fda52a-1038-4b09-b774-0b2fa02fd758",
   "metadata": {},
   "source": [
    "---\n",
    "# Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f1345d-3cb9-46a5-a5d5-99772847f533",
   "metadata": {},
   "source": [
    "- We defined a **score function** from image pixels to class scores (in this section, a linear function that depends on weights W and biases b).\n",
    "\n",
    "- Unlike kNN classifier, the advantage of this parametric approach is that once we learn the parameters we can discard the training data. Additionally, the prediction for a new test image is fast since it requires a single matrix multiplication with W, not an exhaustive comparison to every single training example.\n",
    "\n",
    "- We introduced the bias trick, which allows us to fold the bias vector into the weight matrix for convenience of only having to keep track of one parameter matrix.\n",
    "\n",
    "- We defined a loss function (we introduced two commonly used losses for linear classifiers: the SVM and the Softmax) that measures how compatible a given set of parameters is with respect to the ground truth labels in the training dataset. We also saw that the loss function was defined in such way that making good predictions on the training data is equivalent to having a small loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38fd31c-e6a9-404b-82d0-d58e595e69e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
