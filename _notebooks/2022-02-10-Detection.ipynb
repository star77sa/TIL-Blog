{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ideal-dragon",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "> 객체 탐지 논문\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [python]\n",
    "- image: images/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db2688-eeeb-487d-8aae-2311b5054ad6",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88283f0-af0b-4655-960f-1808a0b9b344",
   "metadata": {},
   "source": [
    "참고 사이트 : https://ganghee-lee.tistory.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ac6067-e642-4c0a-bd2c-0a054521933d",
   "metadata": {},
   "source": [
    "<img src='img/Detection/공부순서.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7faad9-fee0-4f1f-bf7d-43f591d0d6e4",
   "metadata": {},
   "source": [
    "# 1. R-CNN (2013)\n",
    "***Rich feature hierarchies for accurate object detection and semantic segmentation***\n",
    "\n",
    "원문 : https://arxiv.org/abs/1311.2524"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac860587-bc3a-49e5-bc53-f81cfac4135c",
   "metadata": {},
   "source": [
    "<img src='img/Detection/rcnn/rcnn.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d1ca7-a7ea-444a-9530-e1c42e083187",
   "metadata": {},
   "source": [
    "**\" R-CNN 프로세스 \"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0583a3a-497a-453c-b5f8-9c40046618cf",
   "metadata": {},
   "source": [
    "1. Image를 입력받는다.\n",
    "\n",
    "2. Selective search 알고리즘에 의해 regional proposal output 약 2000개를 추출한다.\n",
    "\n",
    "    (추출한 regional proposal output을 모두 동일 input size로 만들어주기 위해 warp 해준다.\n",
    "    \n",
    "    `?` 왜 동일 input size로 만들어 줄까? : 사실 Convolution Layer에는 input size가 고정이지 않다. 그러나 마지막 FC layer에서의 input size는 고정이므로 Convolution Layer에 입력에서부터 동일한 input size로 넣어주어 output size를 동일하게 하는 것)\n",
    "\n",
    "    \n",
    "3. 2000개의 warped image를 각각 CNN 모델에 넣는다.\n",
    "\n",
    "4. 각각의 Convolution 결과에 대해 classification을 진행하여 결과를 얻는다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1e4a75-c65c-47c0-85f4-07306c995d55",
   "metadata": {},
   "source": [
    "위의 과정을 수행하기 위해 R-CNN은 세 가지 모듈로 나누어 놓았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96fc9e-be22-483d-a565-9e5fc3f78c6b",
   "metadata": {},
   "source": [
    "1. Region Proposal : \"Object가 있을법한 영역\"을 찾는 모듈 (기존의 Sliding window방식의 비효율성 극복)\n",
    "    \n",
    "2. CNN : 각각의 영역으로부터 고정된 크기의 Feature Vector를 뽑아낸다.\n",
    "\n",
    "3. SVM : Classification을 위한 선형 지도학습 모델\n",
    "\n",
    "    `?` 왜 Classifier로 Softmax를 쓰지 않고 SVM을 사용했을까? : CNN fine-tuning을 위한 학습 데이터가 시기상 많지 않아서 Softmax를 적용시키면 오히려 성능이 낮아져 SVM을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531d8f0a-f744-49a2-ae21-211eb6c3b375",
   "metadata": {},
   "source": [
    "## 1. Region Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65002c-e1f0-42c4-ba0a-f9589d8de17b",
   "metadata": {},
   "source": [
    "<img src='img/Detection/rcnn/region.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd634bf-f5a3-4b00-9e1c-961fd7888324",
   "metadata": {},
   "source": [
    "R-CNN에서는 가장 먼저 Region Proposal 단계에서 \"물체가 있을 법한 영역\"을 찾는다.\n",
    "\n",
    "이는 위에서 말했듯이 기존의 Sliding window방식의 비효율성을 극복하기 위한 것이다.\n",
    "\n",
    "먼저 기존의 Sliding window가 무엇인지 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91cc15-8501-4d75-9de7-35f8ba3e7171",
   "metadata": {},
   "source": [
    "### Sliding Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047e552d-f7a6-409a-9012-35b5076f9471",
   "metadata": {},
   "source": [
    "Sliding window방식은 이미지에서 물체를 찾기 위해 window의 (크기, 비율)을 임의로 마구 바꿔가면서\n",
    "모든 영역에 대해서 탐색하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d710bfa4-de14-4c0e-8494-b0ea64f9b37b",
   "metadata": {},
   "source": [
    "<img src='img/Detection/rcnn/sliding.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee201a6-2fdd-40ff-8c6b-351ae9224880",
   "metadata": {},
   "source": [
    "<center>좌 : 모든 영역에 대해 탐색 / 우 : 크기와 비율을 변형</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042e489-6850-4fc3-abb8-0523072410e1",
   "metadata": {},
   "source": [
    "이렇게 임의의 (크기, 비율)로 모든 영역을 탐색하는 것은 너무 느리다.\n",
    "\n",
    "따라서 R-CNN에서는 이 비효율성을 극복하기 위해 Selective search 알고리즘을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85477d14-40de-4ffb-af57-679dbc173240",
   "metadata": {},
   "source": [
    "### Selective search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af102228-e79c-4bf0-96f4-df4c80f2230b",
   "metadata": {},
   "source": [
    "<img src='img/Detection/rcnn/selective.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34060fef-7a92-404f-bfe5-8352da271242",
   "metadata": {},
   "source": [
    "1. 색상, 질감, 영역크기 등.. 을 이용해 non-object-based segmentation을 수행한다.\n",
    "\n",
    "    이 작업을 통해 좌측 제일 하단 그림과 같이 많은 small segmented areas들을 얻을 수 있다.\n",
    "\n",
    "2. Bottom-up 방식으로 small segmented areas들을 합쳐서 더 큰 segmented areas들을 만든다.\n",
    "\n",
    "3. (2)작업을 반복하여 최종적으로 2000개의 region proposal을 생성한다.\n",
    "\n",
    "Selective search알고리즘에 의해 2000개의 region proposal이 생성되면 이들을 모두 CNN에 넣기 전에\n",
    "같은 사이즈로 warp시켜야한다. (CNN output 사이즈를 동일하게 만들기 위해 - For FC layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99560007-6d83-469c-9cff-2a42d6fe9620",
   "metadata": {},
   "source": [
    "## 2. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb11508-42d8-489b-b58e-4fb280412c57",
   "metadata": {},
   "source": [
    "<img src='img/Detection/rcnn/cnn.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86249ada-5710-414f-8962-64af799b2506",
   "metadata": {},
   "source": [
    "Warp작업을 통해 region proposal 모두 224x224 크기로 되면 CNN 모델에 넣는다.\n",
    "\n",
    "여기서 CNN은 AlexNet의 거의 구조를 그대로 가져다 썼다.\n",
    "\n",
    "최종적으로 CNN을 거쳐 각각의 region proposal로부터 4096-dimentional feature vector를 뽑아내고,\n",
    "\n",
    "이를 통해 고정길이의 Feature Vector를 만들어낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120cdc40-576e-4e52-a84c-c3880e611756",
   "metadata": {},
   "source": [
    "## 3. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884e64f2-76c3-4ade-9bd3-63a1e4dab515",
   "metadata": {},
   "source": [
    "<img src='img/Detection/rcnn/svm.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d17c28-e590-4c69-9bf0-8318db002417",
   "metadata": {},
   "source": [
    "CNN모델로부터 feature가 추출되면 Linear SVM을 통해 classification을 진행한다.\n",
    "\n",
    "위에서 설명했듯이 Classifier로 softmax보다 SVM이 더 좋은 성능을 보였기 때문에 SVM을 채택했다.\n",
    "\n",
    "SVM은 CNN으로부터 추출된 각각의 feature vector들의 점수를 class별로 매기고, 객체인지 아닌지,\n",
    "객체라면 어떤 객체인지 등을 판별하는 역할을 하는 Classifier이다.\n",
    "\n",
    "`+` Selective search로 만든 bounding box는 정확하지 않기 때문에 물체를 정확히 감싸도록 조정해주는 bounding box regression(선형회귀 모델)이 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee75fe1-9882-48d7-906b-58142634b83a",
   "metadata": {},
   "source": [
    "## 단점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec58b1-547d-4ae5-be81-5adf91162f56",
   "metadata": {},
   "source": [
    "1. 여기서 selective search로 2000개의 region proposal을 뽑고 각 영역마다 CNN을 수행하기 때문에\n",
    "\n",
    "    CNN연산 * 2000 만큼의 시간이 걸려 수행시간이 매우 느리다. \n",
    "\n",
    " \n",
    "\n",
    "2. CNN, SVM, Bounding Box Regression 총 세가지의 모델이 multi-stage pipelines으로 한 번에 학습되지 않는다.\n",
    "\n",
    "    각 region proposal 에 대해 ConvNet forward pass를 실행할때 연산을 공유하지 않기에\n",
    "    end-to-end 로 학습할 수 없다.\n",
    "\n",
    "    따라서 SVM, bounding box regression에서 학습한 결과가 CNN을 업데이트 시키지 못한다.\n",
    "    \n",
    "    (* bounding box regression은 CNN을 거치기 전의 region proposal 데이터가 input으로 들어가고 SVM은 CNN을 거친 후의 feature map이 input으로 들어가기에 연산이 겹치지 않는다.)\n",
    "    \n",
    "\"그리고 이 두가지 문제를 RoI pooling으로 해결한 Fast R-CNN이 나오게 된다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adaaeec-7f14-4596-824e-68176c291647",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b084a8-cf47-45f1-8e8e-6d747280cdcb",
   "metadata": {},
   "source": [
    "# 2. Fast R-CNN (2014)\n",
    "***Fast R-CNN***\n",
    "\n",
    "원문 :  https://arxiv.org/abs/1504.08083"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd9ad4-02db-4bd5-b0a9-bd0063bac0e3",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac092e9-914a-4111-b3f3-6481d44b20ea",
   "metadata": {},
   "source": [
    "Fast R-CNN은 이전 R-CNN의 한계점을 극복하고자 나왔다. R-CNN는 이전 글에서 언급했듯이\n",
    "\n",
    "1) RoI (Region of Interest) 마다 CNN연산을 함으로써 속도저하\n",
    "\n",
    "2) multi-stage pipelines으로써 모델을 한번에 학습시키지 못함\n",
    "\n",
    "다음과 같은 한계점들이 있었다.\n",
    "\n",
    " \n",
    "\n",
    "그리고 Fast R-CNN에서는 다음 두 가지를 통해 위 한계점들을 극복했다.\n",
    "\n",
    "1) RoI pooling\n",
    "\n",
    "2) CNN 특징 추출부터 classification, bounding box regression까지 하나의 모델에서 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea17a78-2acc-4d4f-bad1-2ab3100ed5c5",
   "metadata": {},
   "source": [
    "## Fast R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d5e10-def8-422e-8c86-7e272965d085",
   "metadata": {},
   "source": [
    "<img src='img/Detection/fastrcnn/fastrcnn.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c1dca-9f74-4b7e-8c0c-e8c6a13b22ba",
   "metadata": {},
   "source": [
    "**\"Fast R-CNN 프로세스\"**\n",
    "\n",
    "1-1. R-CNN에서와 마찬가지로 Selective Search를 통해 RoI를 찾는다.\n",
    "\n",
    "1-2. 전체 이미지를 CNN에 통과시켜 feature map을 추출한다.\n",
    "\n",
    "2. Selective Search로 찾았었던 RoI를 feature map크기에 맞춰서 projection시킨다.\n",
    "\n",
    "3. projection시킨 RoI에 대해 RoI Pooling을 진행하여 고정된 크기의 feature vector를 얻는다.\n",
    "\n",
    "4. feature vector는 FC layer를 통과한 뒤, 두 브랜치로 나뉘게 된다.\n",
    "\n",
    "5-1. 하나는 softmax를 통과하여 RoI에 대해 object classification을 한다.\n",
    "\n",
    "5-2. bounding box regression을 통해 selective search로 찾은 box의 위치를 조정한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23306900-b60c-49fb-aa23-24f20ad2ff51",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3048c580-7e76-40ff-a355-97b3f7b1bed9",
   "metadata": {},
   "source": [
    "Fast R-CNN의 가장 핵심적인 아이디어는 RoI Pooling이다.\n",
    "\n",
    "R-CNN에서 CNN output이 FC layer의 input으로 들어가야했기 때문에 CNN input을 동일 size로 맞춰줘야 했다.\n",
    "\n",
    "따라서 원래 이미지에서 추출한 RoI를 crop, warp을 통해 동일 size로 조정했었다.\n",
    "\n",
    "그러나 실제로 \"FC layer의 input이 고정인거지 CNN input은 고정이 아니다\"\n",
    "\n",
    "따라서 CNN에는 입력 이미지 크기, 비율 관계없이 input으로 들어갈 수 있고\n",
    "\n",
    "FC layer의 input으로 들어갈때만 size를 맞춰주기만 하면된다.\n",
    "\n",
    "여기서 Spatial Pyramid Pooling(SPP)이 제안된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec5166a-501b-4b6f-958e-d6bab6d4f669",
   "metadata": {},
   "source": [
    "## Spatial Pyramid Pooling(SPP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973191b0-a25d-418e-a9a4-e9ed845486da",
   "metadata": {},
   "source": [
    "<img src='img/Detection/fastrcnn/spp.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b70951-73e9-476f-8cbf-20ce05ccded9",
   "metadata": {},
   "source": [
    "SPP에서는 먼저 이미지를 CNN에 통과시켜 feature map을 추출한다.\n",
    "\n",
    "그리고 미리 정해진 4x4, 2x2, 1x1 영역의 피라미드로 feature map을 나눠준다. 피라미드 한칸을 bin이라 한다.\n",
    "\n",
    "bin내에서 max pooling을 적용하여 각 bin마다 하나의 값을 추출하고,\n",
    "\n",
    "최종적으로 피라미드 크기만큼 max값을 추출하여 3개의 피라미드의 결과를 쭉 이어붙여 고정된 크기 vector를 만든다.\n",
    "\n",
    " \n",
    "\n",
    "정리하자면,\n",
    "\n",
    "4x4, 2x2, 1x1 세 가지 피라미드가 존재하고, max pooling을 적용하여 각 피라미드 크기에 맞게 max값을 뽑아낸다.\n",
    "\n",
    "각 피라미드 별로 뽑아낸 max값들을 쭉 이어붙여 고정된 크기 vector를 만들고 이게 FC layer의 input으로 들어간다.\n",
    "\n",
    " \n",
    "\n",
    "따라서 CNN을 통과한 feature map에서 2천개의 region proposal을 만들고 region proposal마다\n",
    "\n",
    "SPPNet에 집어넣어 고정된 크기의 feature vector를 얻어낸다. \n",
    "\n",
    "**이 작업을 통해 모든 2천개의 region proposal마다 해야했던 2천번의 CNN연산이 1번으로 줄었다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eeab1c-9f53-4a12-92a6-939d94222eca",
   "metadata": {},
   "source": [
    "## RoI Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18555bad-d539-4798-a62e-a95dda080f8f",
   "metadata": {},
   "source": [
    "다시 돌아와 Fast R-CNN에서 이 SPP가 적용되는 것을 보면 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659388ff-f363-4d6a-9f37-94f1cff8cfb5",
   "metadata": {},
   "source": [
    "<img src='img/Detection/fastrcnn/fastrcnn2.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8a560-aefb-44e0-83c1-aaa06afce2e0",
   "metadata": {},
   "source": [
    "실제로 Fast R-CNN에서는 1개의 피라미드를 적용시킨 SPP로 구성되어있다. 또한 피라미드의 사이즈는 7x7이다.\n",
    "\n",
    "Fast R-CNN에서 적용된 1개의 피라미드 SPP로 고정된 크기의 feature vector를 만드는과정을 **RoI Pooling**이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a99bd9-551e-418d-b182-635320cda02c",
   "metadata": {},
   "source": [
    "<img src='img/Detection/fastrcnn/roi.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf02c1-034b-4345-9fd7-e66174be483e",
   "metadata": {},
   "source": [
    "<center>RoI Pooling</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff37b4c7-f6b5-4d7e-a4bc-cb9d375213a7",
   "metadata": {},
   "source": [
    "Fast R-CNN에서 먼저 입력 이미지를 CNN에 통과시켜 feature map을 추출한다.\n",
    "\n",
    "그 후 이전에 미리 Selective search로 만들어놨던 RoI(=region proposal)을 feature map에 projection시킨다.\n",
    "\n",
    "위 그림의 가장 좌측 그림이 feature map이고 그 안에 hxw크기의 검은색 box가 투영된 RoI이다.\n",
    "\n",
    " \n",
    "\n",
    "(1) 미리 설정한 HxW크기로 만들어주기 위해서 (h/H) * (w/H) 크기만큼 grid를 RoI위에 만든다.\n",
    "\n",
    "(2) RoI를 grid크기로 split시킨 뒤 max pooling을 적용시켜 결국 각 grid 칸마다 하나의 값을 추출한다.\n",
    "\n",
    "위 작업을 통해 feature map에 투영했던 hxw크기의 RoI는 HxW크기의 고정된 feature vector로 변환된다.\n",
    "\n",
    " \n",
    "\n",
    "이렇게 RoI pooling을 이용함으로써\n",
    "\n",
    "\"원래 이미지를 CNN에 통과시킨 후 나온 feature map에 이전에 생성한 RoI를 projection시키고\n",
    "\n",
    "이 RoI를 FC layer input 크기에 맞게 고정된 크기로 변형할 수가 있다\"\n",
    "\n",
    "따라서 더이상 2000번의 CNN연산이 필요하지 않고 1번의 CNN연산으로 속도를 대폭 높일 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaebdc6-4a69-43c7-a6e7-91ec6b29acbc",
   "metadata": {},
   "source": [
    "## end-to-end : Trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cfdd59-f67a-49d6-a06e-1f4568daff20",
   "metadata": {},
   "source": [
    "다음은 R-CNN의 두번째 문제였던 multi-stage pipeline으로 인해 3가지 모델을 따로 학습해야했던 문제이다.\n",
    "\n",
    "R-CNN에서는 CNN을 통과한 후 각각 서로다른 모델인 SVM(classification), bounding box regression(localization)안으로 들어가 forward됐기 때문에 연산이 공유되지 않았다.\n",
    "\n",
    "(* bounding box regression은 CNN을 거치기 전의 region proposal 데이터가 input으로 들어가고 SVM은 CNN을 거친 후의 feature map이 input으로 들어가기에 연산이 겹치지 않는다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38cbe86-cd95-4b53-913e-aaba654996cd",
   "metadata": {},
   "source": [
    "<img src='img/Detection/fastrcnn/fastrcnn.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f35f6-4234-4f84-9e9d-0130f8c1ad76",
   "metadata": {},
   "source": [
    "<center>Fast R-CNN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee9c357-4bc7-4174-af57-4a3a9790d023",
   "metadata": {},
   "source": [
    "그러나 위 그림을 다시보면 RoI Pooling을 추가함으로써 이제 RoI영역을\n",
    "\n",
    "CNN을 거친후의 feature map에 투영시킬 수 있었다. \n",
    "\n",
    "따라서 동일 data가 각자 softmax(classification), bbox regressor(localization)으로 들어가기에 연산을 공유한다.\n",
    "\n",
    "이는 이제 모델이 end-to-end로 한 번에 학습시킬 수 있다는 뜻이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ef3789-2576-460c-84c1-8beb918c30ef",
   "metadata": {},
   "source": [
    "## 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e58dfa-b948-4cde-afdc-60e5289d8adf",
   "metadata": {},
   "source": [
    "RoI Pooling을 하나 추가함으로써 \n",
    "\n",
    "(1) CNN후에 region proposal 연산 - 2000xCNN연산 → 1번의 CNN연산\n",
    "\n",
    "(2) 변경된 feature vector가 결국 기존의 region proposal을 projection시킨 후 연산한 것이므로\n",
    "\n",
    "해당 output으로 classification과 bbox regression도 학습 가능의 성과를 이룰 수 있었다.\n",
    "\n",
    "**그러나 여전히 Fast R-CNN에서도 R-CNN에서와 마찬가지로 RoI를 생성하는 Selective search알고리즘은 CNN외부에서 진행되므로 이 부분이 속도의 bottleneck이다.** \n",
    "\n",
    "따라서 이 RoI 생성마저 CNN내부에서 함으로써 더욱 빠르면서 정확한 region proposal을 생성한 Faster R-CNN이 나오게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b828c18-c207-4076-95cd-5ff6f8a0aded",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Faster R-CNN (2015)\n",
    "***Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks***\n",
    "\n",
    "원문 :  https://arxiv.org/abs/1506.01497"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bbced3-d454-4724-86ff-50ed5e664d66",
   "metadata": {},
   "source": [
    "## introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906d301-f00f-427d-98a5-115c1bf73f79",
   "metadata": {},
   "source": [
    "**R-CNN**에서는 3가지 모듈 (region proposal, classification, bounding box regression)을 각각 따로따로 수행한다.\n",
    "\n",
    "(1)region proposal 추출 → 각 region proposal별로 CNN 연산 → (2)classification, (3)bounding box regression\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b340260b-0e07-4732-a0dc-200f0836f815",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e406fce1-c4fa-4e85-9eb3-fbdb386d8026",
   "metadata": {},
   "source": [
    "**Fast R-CNN**에서는 region proposal을 CNN level로 통과시켜 classification, bounding box regression을 하나로 묶었다.\n",
    "\n",
    "(1)region proposal 추출 → 전체 image CNN 연산 → RoI projection, RoI Pooling → (2)classification, bounding box regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834b8c81-e7e3-4ca3-aae6-2720432fb325",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b060386-0ecd-4ddd-9f30-b0062b436e2b",
   "metadata": {},
   "source": [
    "그러나 여전히 region proposal인 Selective search 알고리즘을 CNN외부에서 연산하므로 RoI 생성단계가 병목이다.\n",
    "\n",
    "따라서 Faster R-CNN에서는 detection에서 쓰인 conv feature을 RPN에서도 공유해서\n",
    "\n",
    "RoI생성역시 CNN level에서 수행하여 속도를 향상시킨다. \n",
    "\n",
    "\"Region Proposal도 Selective search 쓰지말고 CNN - (classification | bounding box regression) 이 네트워크 안에서 같이 해보자!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f8bdd6-46cf-402c-bb3a-d24412df1504",
   "metadata": {},
   "source": [
    "## Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d653f3-8912-4fcf-ae77-930f2309d74a",
   "metadata": {},
   "source": [
    "Selective search가 느린이유는 cpu에서 돌기 때문이다.\n",
    "\n",
    "따라서 Region proposal 생성하는 네트워크도 gpu에 넣기 위해서 Conv layer에서 생성하도록 하자는게 아이디어이다.\n",
    "\n",
    " \n",
    "\n",
    "Faster R-CNN은 한마디로 RPN + Fast R-CNN이라할 수 있다.\n",
    "\n",
    "Faster R-CNN은 Fast R-CNN구조에서 conv feature map과 RoI Pooling사이에 RoI를 생성하는\n",
    "\n",
    "Region Proposal Network가 추가된 구조이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80869c0-8a05-4137-81db-636eb0098ecc",
   "metadata": {},
   "source": [
    "<img src='img/Detection/fasterrcnn/faster.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f16194c-85fa-4762-adb2-4665f182ca5a",
   "metadata": {},
   "source": [
    "<center>RPN + Fast R-CNN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ef4e2b-dac6-463e-afc0-a980b2af5355",
   "metadata": {},
   "source": [
    "그리고 Faster R-CNN에서는 RPN 네트워크에서 사용할 CNN과\n",
    "\n",
    "Fast R-CNN에서 classification, bbox regression을 위해 사용한 CNN 네트워크를 공유하자는 개념에서 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c05f77-abe3-461a-8e46-2bbccf0bb1d8",
   "metadata": {},
   "source": [
    "<img src='img/Detection/fasterrcnn/share.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f97c2-22a2-412f-bd6a-23cb8806c7af",
   "metadata": {},
   "source": [
    "<center>CNN Sharing (RPN & Detector)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142bbc3-0c3e-4f36-acab-6490c1b5db38",
   "metadata": {},
   "source": [
    "결국 위 그림에서와 같이 CNN을 통과하여 생성된 conv feature map이 RPN에 의해 RoI를 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae24f93-2e20-4edf-9feb-54c5809b50d7",
   "metadata": {},
   "source": [
    "이렇게 feature map에 RoI가 투영되고 나면 FC layer에 의해 classification과 bbox regression이 수행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5807ef-487e-4b4b-90c8-d5c8a52db77d",
   "metadata": {},
   "source": [
    "<img src='img/Detection/fasterrcnn/process.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c9920-1cca-4ac9-b26f-2f11183c327a",
   "metadata": {},
   "source": [
    "위 그림에서 보다시피 마지막에 FC layer를 사용하기에 input size를 맞춰주기 위해 RoI pooling을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ce5bf-665d-498c-8325-f5c39e184e69",
   "metadata": {},
   "source": [
    "## RPN (Region Proposal Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ceec05-7a06-437e-a261-fa6fa884eddf",
   "metadata": {},
   "source": [
    "<img src='img/Detection/fasterrcnn/rpn.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dad8f39-0dbb-4fdb-ac9a-1cf7c84069a3",
   "metadata": {},
   "source": [
    "RPN의 input 값은 이전 CNN 모델에서 뽑아낸 feature map이다.\n",
    "\n",
    "Region proposal을 생성하기 위해 feature map위에 nxn window를 sliding window시킨다. \n",
    "\n",
    "이때, object의 크기와 비율이 어떻게 될지모르므로 k개의 anchor box를 미리 정의해놓는다.\n",
    "\n",
    "이 anchor box가 bounding box가 될 수 있는 것이고 미리 가능할만한 box모양 k개를 정의해놓는 것이다.\n",
    "\n",
    "여기서는 가로세로길이 3종류 x 비율 3종류 = 9개의 anchor box를 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c1c8b-71db-4ee9-95fd-e50dc35ff521",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f72772-2fb9-427d-a3ea-c2e71a8cc66f",
   "metadata": {},
   "source": [
    "이 단계에서 9개의 anchor box를 이용하여 classification과 bbox regression을 먼저 구한다. (For 학습)\n",
    "\n",
    "먼저, CNN에서 뽑아낸 feature map에 대해 3x3 conv filter 256개를 연산하여 depth를 256으로 만든다.\n",
    "\n",
    "그 후 1x1 conv 두개를 이용하여 각각 classification과 bbox regression을 계산한다.\n",
    "\n",
    "1x1 convolution은 fully connected layer와 같다고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d434be9-1242-4a00-aef1-30438eea50db",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e59bfa-1483-4381-ba70-7bdb172c26b5",
   "metadata": {},
   "source": [
    "RPN에서 이렇게 1x1 convolution을 이용하여 classification과 bbox regression을 계산하는데\n",
    "\n",
    "이때 네트워크를 가볍게 만들기 위해 binary classification으로 bbox에 물체가 있나 없나만 판단한다.\n",
    "\n",
    "무슨 물체인지 classification하는 것은 마지막 classification 단계에서 한다.\n",
    "\n",
    "RPN단계에서 classification과 bbox regression을 하는 이유는 결국 학습을 위함이다.\n",
    "\n",
    "IoU가 0.7보다 크거나, 한 지점에서 모든 anchor box중 가장 IoU가 큰 anchor box는 positive example로 만든다.\n",
    "\n",
    "IoU가 0.3보다 작으면 object가 아닌 background를 뜻하므로 negative example로 만들고\n",
    "\n",
    "이 사이에 있는 IoU에 대해서는 애매한 값이므로 학습 데이터로 이용하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e757e14d-f288-4271-999e-3ec42152b0be",
   "metadata": {},
   "source": [
    "## Non-Maximu Suppression  NMS알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597eeafe-4a12-46d2-bb4d-dfef666969d1",
   "metadata": {},
   "source": [
    "Faster R-CNN에 대한 학습이 완료된 후 RPN모델을 예측시키며 하마 한 객체당 여러 proposal값이 나올 것이다.\n",
    "\n",
    "이 문제를 해결하기 위해 NMS알고리즘을 사용하여 proposal의 개수를 줄인다.\n",
    "\n",
    "NMS알고리즘은 다음과 같다.\n",
    "\n",
    "1. box들의 score(confidence)를 기준으로 정렬한다.\n",
    "\n",
    "2. score가 가장 높은 box부터 시작해서 다른 모든 box들과 IoU를 계산해서 0.7이상이면 같은 객체를 detect한 box라고\n",
    "생각할 수 있기 때문에 해당 box는 지운다. \n",
    "\n",
    "3. 최종적으로 각 object별로 score가 가장 높은 box 하나씩만 남게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c89176f-a3b7-4208-9489-f3491e9457f0",
   "metadata": {},
   "source": [
    "<img src='img/Detection/fasterrcnn/before.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74aa12d-dd24-427c-a4fd-73ebad051b36",
   "metadata": {},
   "source": [
    "<center>NMS 전</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27dba7f-425d-438a-a59e-0d31f646926b",
   "metadata": {},
   "source": [
    "<img src='img/Detection/fasterrcnn/after.png' width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ebe6b0-409a-4117-8e26-980d0c9d7d55",
   "metadata": {},
   "source": [
    "<center>NMS 후</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
