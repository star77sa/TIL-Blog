<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Object Detection | kyeong-soo</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Object Detection" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="객체 탐지 논문" />
<meta property="og:description" content="객체 탐지 논문" />
<link rel="canonical" href="https://star77sa.github.io/TIL-Blog/python/2022/02/10/Detection.html" />
<meta property="og:url" content="https://star77sa.github.io/TIL-Blog/python/2022/02/10/Detection.html" />
<meta property="og:site_name" content="kyeong-soo" />
<meta property="og:image" content="https://star77sa.github.io/TIL-Blog/images/" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-02-10T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://star77sa.github.io/TIL-Blog/python/2022/02/10/Detection.html","@type":"BlogPosting","headline":"Object Detection","dateModified":"2022-02-10T00:00:00-06:00","datePublished":"2022-02-10T00:00:00-06:00","image":"https://star77sa.github.io/TIL-Blog/images/","mainEntityOfPage":{"@type":"WebPage","@id":"https://star77sa.github.io/TIL-Blog/python/2022/02/10/Detection.html"},"description":"객체 탐지 논문","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/TIL-Blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://star77sa.github.io/TIL-Blog/feed.xml" title="kyeong-soo" /><link rel="shortcut icon" type="image/x-icon" href="/TIL-Blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/TIL-Blog/">kyeong-soo</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/TIL-Blog/about/">About Me</a><a class="page-link" href="/TIL-Blog/search/">Search</a><a class="page-link" href="/TIL-Blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Object Detection</h1><p class="page-description">객체 탐지 논문</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-02-10T00:00:00-06:00" itemprop="datePublished">
        Feb 10, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/TIL-Blog/categories/#python">python</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/star77sa/TIL-Blog/tree/master/_notebooks/2022-02-10-Detection.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/TIL-Blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/star77sa/TIL-Blog/master?filepath=_notebooks%2F2022-02-10-Detection.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/TIL-Blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/star77sa/TIL-Blog/blob/master/_notebooks/2022-02-10-Detection.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/TIL-Blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#1.-R-CNN-(2013)">1. R-CNN (2013) </a>
<ul>
<li class="toc-entry toc-h2"><a href="#1.-Region-Proposal">1. Region Proposal </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Sliding-Window">Sliding Window </a></li>
<li class="toc-entry toc-h3"><a href="#Selective-search">Selective search </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#2.-CNN">2. CNN </a></li>
<li class="toc-entry toc-h2"><a href="#3.-SVM">3. SVM </a></li>
<li class="toc-entry toc-h2"><a href="#단점">단점 </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#2.-Fast-R-CNN-(2014)">2. Fast R-CNN (2014) </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Introdection">Introdection </a></li>
<li class="toc-entry toc-h2"><a href="#Fast-R-CNN">Fast R-CNN </a></li>
<li class="toc-entry toc-h2"><a href="#Spatial-Pyramid-Pooling(SPP)">Spatial Pyramid Pooling(SPP) </a></li>
<li class="toc-entry toc-h2"><a href="#RoI-Pooling">RoI Pooling </a></li>
<li class="toc-entry toc-h2"><a href="#end-to-end-:-Trainable">end-to-end : Trainable </a></li>
<li class="toc-entry toc-h2"><a href="#결론">결론 </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#3.-Faster-R-CNN-(2015)">3. Faster R-CNN (2015) </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-02-10-Detection.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>참고 사이트 : <a href="https://ganghee-lee.tistory.com/">https://ganghee-lee.tistory.com/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="1.-R-CNN-(2013)">
<a class="anchor" href="#1.-R-CNN-(2013)" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. R-CNN (2013)<a class="anchor-link" href="#1.-R-CNN-(2013)"> </a>
</h1>
<p><strong><em>Rich feature hierarchies for accurate object detection and semantic segmentation</em></strong></p>
<p>원문 : <a href="https://arxiv.org/abs/1311.2524">https://arxiv.org/abs/1311.2524</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/TIL-Blog/images/copied_from_nb/img/Detection/rcnn/rcnn.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>" R-CNN 프로세스 "</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li>
<p>Image를 입력받는다.</p>
</li>
<li>
<p>Selective search 알고리즘에 의해 regional proposal output 약 2000개를 추출한다.</p>
<p>(추출한 regional proposal output을 모두 동일 input size로 만들어주기 위해 warp 해준다.</p>
<p><code>?</code> 왜 동일 input size로 만들어 줄까? : 사실 Convolution Layer에는 input size가 고정이지 않다. 그러나 마지막 FC layer에서의 input size는 고정이므로 Convolution Layer에 입력에서부터 동일한 input size로 넣어주어 output size를 동일하게 하는 것)</p>
</li>
</ol>
<ol>
<li>
<p>2000개의 warped image를 각각 CNN 모델에 넣는다.</p>
</li>
<li>
<p>각각의 Convolution 결과에 대해 classification을 진행하여 결과를 얻는다.</p>
</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>위의 과정을 수행하기 위해 R-CNN은 세 가지 모듈로 나누어 놓았다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<ol>
<li>Region Proposal : "Object가 있을법한 영역"을 찾는 모듈 (기존의 Sliding window방식의 비효율성 극복)</li>
</ol>
</li>
<li>
<ol>
<li>CNN : 각각의 영역으로부터 고정된 크기의 Feature Vector를 뽑아낸다.</li>
</ol>
</li>
<li>
<ol>
<li>
<p>SVM : Classification을 위한 선형 지도학습 모델</p>
<p><code>?</code> 왜 Classifier로 Softmax를 쓰지 않고 SVM을 사용했을까? : CNN fine-tuning을 위한 학습 데이터가 시기상 많지 않아서 Softmax를 적용시키면 오히려 성능이 낮아져 SVM을 사용</p>
</li>
</ol>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Region-Proposal">
<a class="anchor" href="#1.-Region-Proposal" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Region Proposal<a class="anchor-link" href="#1.-Region-Proposal"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/TIL-Blog/images/copied_from_nb/img/Detection/rcnn/region.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>R-CNN에서는 가장 먼저 Region Proposal 단계에서 "물체가 있을 법한 영역"을 찾는다.</p>
<p>이는 위에서 말했듯이 기존의 Sliding window방식의 비효율성을 극복하기 위한 것이다.</p>
<p>먼저 기존의 Sliding window가 무엇인지 살펴보자.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Sliding-Window">
<a class="anchor" href="#Sliding-Window" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sliding Window<a class="anchor-link" href="#Sliding-Window"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sliding window방식은 이미지에서 물체를 찾기 위해 window의 (크기, 비율)을 임의로 마구 바꿔가면서
모든 영역에 대해서 탐색하는 것이다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/TIL-Blog/images/copied_from_nb/img/Detection/rcnn/sliding.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>좌 : 모든 영역에 대해 탐색 / 우 : 크기와 비율을 변형</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이렇게 임의의 (크기, 비율)로 모든 영역을 탐색하는 것은 너무 느리다.</p>
<p>따라서 R-CNN에서는 이 비효율성을 극복하기 위해 Selective search 알고리즘을 사용한다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Selective-search">
<a class="anchor" href="#Selective-search" aria-hidden="true"><span class="octicon octicon-link"></span></a>Selective search<a class="anchor-link" href="#Selective-search"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/TIL-Blog/images/copied_from_nb/img/Detection/rcnn/selective.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li>
<p>색상, 질감, 영역크기 등.. 을 이용해 non-object-based segmentation을 수행한다.</p>
<p>이 작업을 통해 좌측 제일 하단 그림과 같이 많은 small segmented areas들을 얻을 수 있다.</p>
</li>
<li>
<p>Bottom-up 방식으로 small segmented areas들을 합쳐서 더 큰 segmented areas들을 만든다.</p>
</li>
<li>
<p>(2)작업을 반복하여 최종적으로 2000개의 region proposal을 생성한다.</p>
</li>
</ol>
<p>Selective search알고리즘에 의해 2000개의 region proposal이 생성되면 이들을 모두 CNN에 넣기 전에
같은 사이즈로 warp시켜야한다. (CNN output 사이즈를 동일하게 만들기 위해 - For FC layer)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-CNN">
<a class="anchor" href="#2.-CNN" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. CNN<a class="anchor-link" href="#2.-CNN"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/TIL-Blog/images/copied_from_nb/img/Detection/rcnn/cnn.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Warp작업을 통해 region proposal 모두 224x224 크기로 되면 CNN 모델에 넣는다.</p>
<p>여기서 CNN은 AlexNet의 거의 구조를 그대로 가져다 썼다.</p>
<p>최종적으로 CNN을 거쳐 각각의 region proposal로부터 4096-dimentional feature vector를 뽑아내고,</p>
<p>이를 통해 고정길이의 Feature Vector를 만들어낸다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-SVM">
<a class="anchor" href="#3.-SVM" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. SVM<a class="anchor-link" href="#3.-SVM"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/TIL-Blog/images/copied_from_nb/img/Detection/rcnn/svm.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>CNN모델로부터 feature가 추출되면 Linear SVM을 통해 classification을 진행한다.</p>
<p>위에서 설명했듯이 Classifier로 softmax보다 SVM이 더 좋은 성능을 보였기 때문에 SVM을 채택했다.</p>
<p>SVM은 CNN으로부터 추출된 각각의 feature vector들의 점수를 class별로 매기고, 객체인지 아닌지,
객체라면 어떤 객체인지 등을 판별하는 역할을 하는 Classifier이다.</p>
<p><code>+</code> Selective search로 만든 bounding box는 정확하지 않기 때문에 물체를 정확히 감싸도록 조정해주는 bounding box regression(선형회귀 모델)이 존재한다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="단점">
<a class="anchor" href="#%EB%8B%A8%EC%A0%90" aria-hidden="true"><span class="octicon octicon-link"></span></a>단점<a class="anchor-link" href="#%EB%8B%A8%EC%A0%90"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li>
<p>여기서 selective search로 2000개의 region proposal을 뽑고 각 영역마다 CNN을 수행하기 때문에</p>
<p>CNN연산 * 2000 만큼의 시간이 걸려 수행시간이 매우 느리다.</p>
</li>
</ol>
<ol>
<li>
<p>CNN, SVM, Bounding Box Regression 총 세가지의 모델이 multi-stage pipelines으로 한 번에 학습되지 않는다.</p>
<p>각 region proposal 에 대해 ConvNet forward pass를 실행할때 연산을 공유하지 않기에
 end-to-end 로 학습할 수 없다.</p>
<p>따라서 SVM, bounding box regression에서 학습한 결과가 CNN을 업데이트 시키지 못한다.</p>
<p>(* bounding box regression은 CNN을 거치기 전의 region proposal 데이터가 input으로 들어가고 SVM은 CNN을 거친 후의 feature map이 input으로 들어가기에 연산이 겹치지 않는다.)</p>
</li>
</ol>
<p>"그리고 이 두가지 문제를 RoI pooling으로 해결한 Fast R-CNN이 나오게 된다."</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="2.-Fast-R-CNN-(2014)">
<a class="anchor" href="#2.-Fast-R-CNN-(2014)" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Fast R-CNN (2014)<a class="anchor-link" href="#2.-Fast-R-CNN-(2014)"> </a>
</h1>
<p><strong><em>Fast R-CNN</em></strong></p>
<p>원문 :  <a href="https://arxiv.org/abs/1504.08083">https://arxiv.org/abs/1504.08083</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introdection">
<a class="anchor" href="#Introdection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introdection<a class="anchor-link" href="#Introdection"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fast R-CNN은 이전 R-CNN의 한계점을 극복하고자 나왔다. R-CNN는 이전 글에서 언급했듯이</p>
<p>1) RoI (Region of Interest) 마다 CNN연산을 함으로써 속도저하</p>
<p>2) multi-stage pipelines으로써 모델을 한번에 학습시키지 못함</p>
<p>다음과 같은 한계점들이 있었다.</p>
<p>그리고 Fast R-CNN에서는 다음 두 가지를 통해 위 한계점들을 극복했다.</p>
<p>1) RoI pooling</p>
<p>2) CNN 특징 추출부터 classification, bounding box regression까지 하나의 모델에서 학습</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fast-R-CNN">
<a class="anchor" href="#Fast-R-CNN" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fast R-CNN<a class="anchor-link" href="#Fast-R-CNN"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/TIL-Blog/images/copied_from_nb/img/Detection/fastrcnn/fastrcnn.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>"Fast R-CNN 프로세스"</strong></p>
<p>1-1. R-CNN에서와 마찬가지로 Selective Search를 통해 RoI를 찾는다.</p>
<p>1-2. 전체 이미지를 CNN에 통과시켜 feature map을 추출한다.</p>
<ol>
<li>
<p>Selective Search로 찾았었던 RoI를 feature map크기에 맞춰서 projection시킨다.</p>
</li>
<li>
<p>projection시킨 RoI에 대해 RoI Pooling을 진행하여 고정된 크기의 feature vector를 얻는다.</p>
</li>
<li>
<p>feature vector는 FC layer를 통과한 뒤, 두 브랜치로 나뉘게 된다.</p>
</li>
</ol>
<p>5-1. 하나는 softmax를 통과하여 RoI에 대해 object classification을 한다.</p>
<p>5-2. bounding box regression을 통해 selective search로 찾은 box의 위치를 조정한다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fast R-CNN의 가장 핵심적인 아이디어는 RoI Pooling이다.</p>
<p>R-CNN에서 CNN output이 FC layer의 input으로 들어가야했기 때문에 CNN input을 동일 size로 맞춰줘야 했다.</p>
<p>따라서 원래 이미지에서 추출한 RoI를 crop, warp을 통해 동일 size로 조정했었다.</p>
<p>그러나 실제로 "FC layer의 input이 고정인거지 CNN input은 고정이 아니다"</p>
<p>따라서 CNN에는 입력 이미지 크기, 비율 관계없이 input으로 들어갈 수 있고</p>
<p>FC layer의 input으로 들어갈때만 size를 맞춰주기만 하면된다.</p>
<p>여기서 Spatial Pyramid Pooling(SPP)이 제안된다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Spatial-Pyramid-Pooling(SPP)">
<a class="anchor" href="#Spatial-Pyramid-Pooling(SPP)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Spatial Pyramid Pooling(SPP)<a class="anchor-link" href="#Spatial-Pyramid-Pooling(SPP)"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/TIL-Blog/images/copied_from_nb/img/Detection/fastrcnn/spp.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>SPP에서는 먼저 이미지를 CNN에 통과시켜 feature map을 추출한다.</p>
<p>그리고 미리 정해진 4x4, 2x2, 1x1 영역의 피라미드로 feature map을 나눠준다. 피라미드 한칸을 bin이라 한다.</p>
<p>bin내에서 max pooling을 적용하여 각 bin마다 하나의 값을 추출하고,</p>
<p>최종적으로 피라미드 크기만큼 max값을 추출하여 3개의 피라미드의 결과를 쭉 이어붙여 고정된 크기 vector를 만든다.</p>
<p>정리하자면,</p>
<p>4x4, 2x2, 1x1 세 가지 피라미드가 존재하고, max pooling을 적용하여 각 피라미드 크기에 맞게 max값을 뽑아낸다.</p>
<p>각 피라미드 별로 뽑아낸 max값들을 쭉 이어붙여 고정된 크기 vector를 만들고 이게 FC layer의 input으로 들어간다.</p>
<p>따라서 CNN을 통과한 feature map에서 2천개의 region proposal을 만들고 region proposal마다</p>
<p>SPPNet에 집어넣어 고정된 크기의 feature vector를 얻어낸다.</p>
<p><strong>이 작업을 통해 모든 2천개의 region proposal마다 해야했던 2천번의 CNN연산이 1번으로 줄었다.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="RoI-Pooling">
<a class="anchor" href="#RoI-Pooling" aria-hidden="true"><span class="octicon octicon-link"></span></a>RoI Pooling<a class="anchor-link" href="#RoI-Pooling"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>다시 돌아와 Fast R-CNN에서 이 SPP가 적용되는 것을 보면 다음과 같다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/TIL-Blog/images/copied_from_nb/img/Detection/fastrcnn/fastrcnn2.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>실제로 Fast R-CNN에서는 1개의 피라미드를 적용시킨 SPP로 구성되어있다. 또한 피라미드의 사이즈는 7x7이다.</p>
<p>Fast R-CNN에서 적용된 1개의 피라미드 SPP로 고정된 크기의 feature vector를 만드는과정을 <strong>RoI Pooling</strong>이라 한다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/TIL-Blog/images/copied_from_nb/img/Detection/fastrcnn/roi.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>RoI Pooling</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fast R-CNN에서 먼저 입력 이미지를 CNN에 통과시켜 feature map을 추출한다.</p>
<p>그 후 이전에 미리 Selective search로 만들어놨던 RoI(=region proposal)을 feature map에 projection시킨다.</p>
<p>위 그림의 가장 좌측 그림이 feature map이고 그 안에 hxw크기의 검은색 box가 투영된 RoI이다.</p>
<p>(1) 미리 설정한 HxW크기로 만들어주기 위해서 (h/H) * (w/H) 크기만큼 grid를 RoI위에 만든다.</p>
<p>(2) RoI를 grid크기로 split시킨 뒤 max pooling을 적용시켜 결국 각 grid 칸마다 하나의 값을 추출한다.</p>
<p>위 작업을 통해 feature map에 투영했던 hxw크기의 RoI는 HxW크기의 고정된 feature vector로 변환된다.</p>
<p>이렇게 RoI pooling을 이용함으로써</p>
<p>"원래 이미지를 CNN에 통과시킨 후 나온 feature map에 이전에 생성한 RoI를 projection시키고</p>
<p>이 RoI를 FC layer input 크기에 맞게 고정된 크기로 변형할 수가 있다"</p>
<p>따라서 더이상 2000번의 CNN연산이 필요하지 않고 1번의 CNN연산으로 속도를 대폭 높일 수 있었다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="end-to-end-:-Trainable">
<a class="anchor" href="#end-to-end-:-Trainable" aria-hidden="true"><span class="octicon octicon-link"></span></a>end-to-end : Trainable<a class="anchor-link" href="#end-to-end-:-Trainable"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>다음은 R-CNN의 두번째 문제였던 multi-stage pipeline으로 인해 3가지 모델을 따로 학습해야했던 문제이다.</p>
<p>R-CNN에서는 CNN을 통과한 후 각각 서로다른 모델인 SVM(classification), bounding box regression(localization)안으로 들어가 forward됐기 때문에 연산이 공유되지 않았다.</p>
<p>(* bounding box regression은 CNN을 거치기 전의 region proposal 데이터가 input으로 들어가고 SVM은 CNN을 거친 후의 feature map이 input으로 들어가기에 연산이 겹치지 않는다.)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/TIL-Blog/images/copied_from_nb/img/Detection/fastrcnn/fastrcnn.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>Fast R-CNN</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>그러나 위 그림을 다시보면 RoI Pooling을 추가함으로써 이제 RoI영역을</p>
<p>CNN을 거친후의 feature map에 투영시킬 수 있었다.</p>
<p>따라서 동일 data가 각자 softmax(classification), bbox regressor(localization)으로 들어가기에 연산을 공유한다.</p>
<p>이는 이제 모델이 end-to-end로 한 번에 학습시킬 수 있다는 뜻이다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="결론">
<a class="anchor" href="#%EA%B2%B0%EB%A1%A0" aria-hidden="true"><span class="octicon octicon-link"></span></a>결론<a class="anchor-link" href="#%EA%B2%B0%EB%A1%A0"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>RoI Pooling을 하나 추가함으로써</p>
<p>(1) CNN후에 region proposal 연산 - 2000xCNN연산 → 1번의 CNN연산</p>
<p>(2) 변경된 feature vector가 결국 기존의 region proposal을 projection시킨 후 연산한 것이므로</p>
<p>해당 output으로 classification과 bbox regression도 학습 가능의 성과를 이룰 수 있었다.</p>
<p><strong>그러나 여전히 Fast R-CNN에서도 R-CNN에서와 마찬가지로 RoI를 생성하는 Selective search알고리즘은 CNN외부에서 진행되므로 이 부분이 속도의 bottleneck이다.</strong></p>
<p>따라서 이 RoI 생성마저 CNN내부에서 함으로써 더욱 빠르면서 정확한 region proposal을 생성한 Faster R-CNN이 나오게 된다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="3.-Faster-R-CNN-(2015)">
<a class="anchor" href="#3.-Faster-R-CNN-(2015)" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Faster R-CNN (2015)<a class="anchor-link" href="#3.-Faster-R-CNN-(2015)"> </a>
</h1>
<p><strong><em>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</em></strong></p>
<p>원문 :  <a href="https://arxiv.org/abs/1506.01497">https://arxiv.org/abs/1506.01497</a></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="star77sa/TIL-Blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/TIL-Blog/python/2022/02/10/Detection.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/TIL-Blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/TIL-Blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/TIL-Blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>TIL-Blog</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/star77sa" target="_blank" title="star77sa"><svg class="svg-icon grey"><use xlink:href="/TIL-Blog/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
