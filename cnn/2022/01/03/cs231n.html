<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>CS231n_CNN for Visual Recognition | kyeong-soo</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="CS231n_CNN for Visual Recognition" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Stanford University CS231n" />
<meta property="og:description" content="Stanford University CS231n" />
<link rel="canonical" href="https://star77sa.github.io/TIL-Blog/cnn/2022/01/03/cs231n.html" />
<meta property="og:url" content="https://star77sa.github.io/TIL-Blog/cnn/2022/01/03/cs231n.html" />
<meta property="og:site_name" content="kyeong-soo" />
<meta property="og:image" content="https://star77sa.github.io/TIL-Blog/images/" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-03T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://star77sa.github.io/TIL-Blog/cnn/2022/01/03/cs231n.html","@type":"BlogPosting","headline":"CS231n_CNN for Visual Recognition","dateModified":"2022-01-03T00:00:00-06:00","datePublished":"2022-01-03T00:00:00-06:00","image":"https://star77sa.github.io/TIL-Blog/images/","mainEntityOfPage":{"@type":"WebPage","@id":"https://star77sa.github.io/TIL-Blog/cnn/2022/01/03/cs231n.html"},"description":"Stanford University CS231n","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/TIL-Blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://star77sa.github.io/TIL-Blog/feed.xml" title="kyeong-soo" /><link rel="shortcut icon" type="image/x-icon" href="/TIL-Blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/TIL-Blog/">kyeong-soo</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/TIL-Blog/about/">About Me</a><a class="page-link" href="/TIL-Blog/search/">Search</a><a class="page-link" href="/TIL-Blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">CS231n_CNN for Visual Recognition</h1><p class="page-description">Stanford University CS231n</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-01-03T00:00:00-06:00" itemprop="datePublished">
        Jan 3, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      8 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/TIL-Blog/categories/#CNN">CNN</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/star77sa/TIL-Blog/tree/master/_notebooks/2022-01-03-cs231n.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/TIL-Blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/star77sa/TIL-Blog/master?filepath=_notebooks%2F2022-01-03-cs231n.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/TIL-Blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/star77sa/TIL-Blog/blob/master/_notebooks/2022-01-03-cs231n.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/TIL-Blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Image-Classification">Image Classification </a></li>
<li class="toc-entry toc-h1"><a href="#Linear-Classification">Linear Classification </a></li>
<li class="toc-entry toc-h1"><a href="#Optimization">Optimization </a></li>
<li class="toc-entry toc-h1"><a href="#Backprop">Backprop </a></li>
<li class="toc-entry toc-h1"><a href="#Neural-Network---1">Neural Network - 1 </a></li>
<li class="toc-entry toc-h1"><a href="#Neural-Network---2">Neural Network - 2 </a></li>
<li class="toc-entry toc-h1"><a href="#Neural-Network---3">Neural Network - 3 </a></li>
<li class="toc-entry toc-h1"><a href="#CNN">CNN </a></li>
<li class="toc-entry toc-h1"><a href="#Spatial-Localization-and-Detection">Spatial Localization and Detection </a></li>
<li class="toc-entry toc-h1"><a href="#CNNs-in-practice">CNNs in practice </a></li>
<li class="toc-entry toc-h1"><a href="#Segmentaion">Segmentaion </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-01-03-cs231n.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><a href="http://cs231n.stanford.edu/">http://cs231n.stanford.edu/</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="Image-Classification">
<a class="anchor" href="#Image-Classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Image Classification<a class="anchor-link" href="#Image-Classification"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p><strong>Image Classification:</strong> We are given a <strong>Training Set</strong> of labeled images, asked to predict labels on <strong>Test Set.</strong> Common to report the <strong>Accuracy</strong> of predictions(fraction of correctly predicted images)</p>
</li>
<li>
<p>We introduced the <strong>k-Nearest Neighbor Classifier</strong>, 이는 트레이닝 셋에서 가장 가까운 이미지에 기반하여 예측을 한다.</p>
</li>
<li>
<p>We saw that the choice of distance and the value of k are <strong>hyperparameters</strong> that are tuned using a <strong>validation set</strong>, or through <strong>cross-validation</strong> if the size of the data is small.</p>
</li>
<li>
<p>Once the best set of hyperparameters is chosen, the classifier is evaluated once on the test set, and reported as the performance of kNN on that data.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>Nearest Neighbor 분류기는 CIFAR-10 데이터셋에서 약 40% 정도의 정확도를 보이는 것을 확인하였다. 이 방법은 구현이 매우 간단하지만, 학습 데이터셋 전체를 메모리에 저장해야 하고, 새로운 테스트 이미지를 분류하고 평가할 때 계산량이 매우 많다.</p>
</li>
<li>
<p>단순히 픽셀 값들의 L1이나 L2 거리는 이미지의 클래스보다 배경이나 이미지의 전체적인 색깔 분포 등에 더 큰 영향을 받기 때문에 이미지 분류 문제에 있어서 충분하지 못하다는 점을 보았다.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="Linear-Classification">
<a class="anchor" href="#Linear-Classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Linear Classification<a class="anchor-link" href="#Linear-Classification"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>We defined a <strong>score function</strong> from image pixels to class scores (in this section, a linear function that depends on weights <strong>W</strong> and biases <strong>b</strong>).</p>
</li>
<li>
<p>Unlike kNN classifier, the advantage of this <strong>parametric approach</strong> is that once we learn the parameters we can discard the training data. Additionally, the prediction for a new test image is fast since it requires a single matrix multiplication with <strong>W</strong>, not an exhaustive comparison to every single training example.</p>
</li>
<li>
<p>We introduced the <strong>bias trick</strong>, which allows us to fold the bias vector into the weight matrix for convenience of only having to keep track of one parameter matrix.
하나의 매개변수 행렬만 추적해야 하는 편의를 위해 편향 벡터를 가중치 행렬로 접을 수 있는 편향 트릭을 도입했습니다 .</p>
</li>
<li>
<p>We defined a <strong>loss function</strong> (we introduced two commonly used losses for linear classifiers: the <strong>SVM</strong> and the <strong>Softmax</strong>) that measures how compatible a given set of parameters is with respect to the ground truth labels in the training dataset. We also saw that the loss function was defined in such way that making good predictions on the training data is equivalent to having a small loss.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Optimization">
<a class="anchor" href="#Optimization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Optimization<a class="anchor-link" href="#Optimization"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>We developed the intuition of the loss function as a <strong>high-dimensional optimization landscape</strong> in which we are trying to reach the bottom. The working analogy we developed was that of a blindfolded hiker who wishes to reach the bottom. In particular, we saw that the SVM cost function is piece-wise linear and bowl-shaped.</p>
</li>
<li>
<p>We motivated the idea of optimizing the loss function with <strong>iterative refinement</strong>, where we start with a random set of weights and refine them step by step until the loss is minimized.</p>
</li>
<li>
<p>We saw that the <strong>gradient</strong> of a function gives the steepest ascent direction and we discussed a simple but inefficient way of computing it numerically using the finite difference approximation (the finite difference being the value of h used in computing the numerical gradient).</p>
</li>
<li>
<p>We saw that the parameter update requires a tricky setting of the <strong>step size</strong> (or the <strong>learning rate</strong>) that must be set just right: if it is too low the progress is steady but slow. If it is too high the progress can be faster, but more risky. We will explore this tradeoff in much more detail in future sections.</p>
</li>
<li>
<p>We discussed the tradeoffs between computing the <strong>numerical</strong> and <strong>analytic</strong> gradient. The numerical gradient is simple but it is approximate and expensive to compute. The analytic gradient is exact, fast to compute but more error-prone since it requires the derivation of the gradient with math. Hence, in practice we always use the analytic gradient and then perform a <strong>gradient check</strong>, in which its implementation is compared to the numerical gradient.</p>
</li>
<li>
<p>We introduced the <strong>Gradient Descent</strong> algorithm which iteratively computes the gradient and performs a parameter update in loop.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Backprop">
<a class="anchor" href="#Backprop" aria-hidden="true"><span class="octicon octicon-link"></span></a>Backprop<a class="anchor-link" href="#Backprop"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>We developed intuition for what the gradients mean, how they flow backwards in the circuit, and how they communicate which part of the circuit should increase or decrease and with what force to make the final output higher.</p>
</li>
<li>
<p>We discussed the importance of <strong>staged computation</strong> for practical implementations of backpropagation. You always want to break up your function into modules for which you can easily derive local gradients, and then chain them with chain rule. Crucially, you almost never want to write out these expressions on paper and differentiate them symbolically in full, because you never need an explicit mathematical equation for the gradient of the input variables. Hence, decompose your expressions into stages such that you can differentiate every stage independently (the stages will be matrix vector multiplies, or max operations, or sum operations, etc.) and then backprop through the variables one step at a time.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="Neural-Network---1">
<a class="anchor" href="#Neural-Network---1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Neural Network - 1<a class="anchor-link" href="#Neural-Network---1"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>We introduced a very coarse model of a biological <strong>neuron</strong></p>
</li>
<li>
<p>실제 사용되는 몇몇 <strong>활성화 함수</strong> 에 대해 논의하였고, ReLU가 가장 일반적인 선택이다.</p>
<ul>
<li>활성화 함수 쓰는 이유 : 데이터를 비선형으로 바꾸기 위해서. 선형이면 은닉층이 1개밖에 안나옴</li>
</ul>
</li>
</ul>
<ul>
<li>
<p>We introduced <strong>Neural Networks</strong> where neurons are connected with <strong>Fully-Connected layers</strong> where neurons in adjacent layers have full pair-wise connections, but neurons within a layer are not connected.</p>
</li>
<li>
<p>우리는 layered architecture를 통해 활성화 함수의 기능 적용과 결합된 행렬 곱을 기반으로 신경망을 매우 효율적으로 평가할 수 있음을 보았다.</p>
</li>
<li>
<p>우리는 Neural Networks가 <strong>universal function approximators</strong>(NN으로 어떠한 함수든 근사시킬 수 있다)임을 보았지만, 우리는 또한 이 특성이 그들의 편재적인 사용과 거의 관련이 없다는 사실에 대해 논의하였다. They are used because they make certain “right” assumptions about the functional forms of functions that come up in practice.</p>
</li>
<li>
<p>우리는 큰 network가 작은 network보다 항상 더 잘 작동하지만, 더 높은 model capacity는 더 강력한 정규화(높은 가중치 감소같은)로 적절히 해결되어야 하며, 그렇지 않으면 오버핏될 수 있다는 사실에 대해 논의하였다. 이후 섹션에서 더 많은 형태의 정규화(특히 dropout)를 볼 수 있을 것이다.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="Neural-Network---2">
<a class="anchor" href="#Neural-Network---2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Neural Network - 2<a class="anchor-link" href="#Neural-Network---2"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>권장되는 전처리는 데이터의 중앙에 평균이 0이 되도록 하고 (zero centered), 스케일을 [-1, 1]로 정규화 하는 것 입니다.</p>
<ul>
<li>올바른 전처리 방법 : 예를들어 평균차감 기법을 쓸 때 학습, 검증, 테스트를 위한 데이터를 먼저 나눈 후 학습 데이터를 대상으로 평균값을 구한 후에 평균차감 전처리를 모든 데이터군(학습, 검증, 테스트)에 적용하는 것이다.</li>
</ul>
</li>
<li>
<p>ReLU를 사용하고 초기화는 $\sqrt{2/n}$ 의 표준 편차를 갖는 정규 분포에서 가중치를 가져와 초기화합니다. 여기서 $n$은 뉴런에 대한 입력 수입니다. E.g. in numpy: <code>w = np.random.randn(n) * sqrt(2.0/n)</code>.</p>
</li>
<li>
<p>L2 regularization과 드랍아웃을 사용 (the inverted version)</p>
</li>
<li>
<p>Batch normalization 사용 (이걸쓰면 드랍아웃은 잘 안씀)</p>
</li>
<li>
<p>실제로 수행할 수 있는 다양한 작업과 각 작업에 대한 가장 일반적인 손실 함수에 대해 논의했다.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="Neural-Network---3">
<a class="anchor" href="#Neural-Network---3" aria-hidden="true"><span class="octicon octicon-link"></span></a>Neural Network - 3<a class="anchor-link" href="#Neural-Network---3"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>신경망(neural network)를 훈련하기 위하여:</p>
<ul>
<li>
<p>코드를 짜는 중간중간에 작은 배치로 그라디언트를 체크하고, 뜻하지 않게 튀어나올 위험을 인지하고 있어야 한다.</p>
</li>
<li>
<p>코드가 제대로 돌아가는지 확인하는 방법으로, 손실함수값의 초기값이 합리적인지 그리고 데이터의 일부분으로 100%의 훈련 정확도를 달성할 수 있는지 확인해야한다.</p>
</li>
<li>
<p>훈련 동안, 손실함수와 train/validation 정확도를 계속 살펴보고, (이게 좀 더 멋져 보이면) 현재 파라미터 값 대비 업데이트 값 또한 살펴보라 (대충 ~ 1e-3 정도 되어야 한다). 만약 ConvNet을 다루고 있다면, 첫 층의 웨이트값도 살펴보라.</p>
</li>
<li>
<p>업데이트 방법으로 추천하는 건 SGD+Nesterov Momentum 혹은 Adam이다.</p>
</li>
<li>
<p>학습 속도를 훈련 동안 계속 하강시켜라. 예를 들면, 정해진 에폭 수 뒤에 (혹은 검증 정확도가 상승하다가 하강세로 꺾이면) 학습 속도를 반으로 깎아라.</p>
</li>
<li>
<p>Hyper parameter 검색은 grid search가 아닌 random search으로 수행하라. 처음에는 성긴 규모에서 탐색하다가 (넓은 hyper parameter 범위, 1-5 epoch 정도만 학습), 점점 촘촘하게 검색하라. (좁은 범위, 더 많은 에폭에서 학습)</p>
</li>
<li>추가적인 개선을 위하여 모형 앙상블을 구축하라.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="CNN">
<a class="anchor" href="#CNN" aria-hidden="true"><span class="octicon octicon-link"></span></a>CNN<a class="anchor-link" href="#CNN"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>ConvNet 아키텍쳐는 여러 레이어를 통해 입력 이미지 볼륨을 출력 볼륨 (클래스 점수)으로 변환시켜 준다.</p>
</li>
<li>
<p>ConvNet은 몇 가지 종류의 레이어로 구성되어 있다. CONV/FC/RELU/POOL 레이어가 현재 가장 많이 쓰인다.</p>
</li>
<li>
<p>각 레이어는 3차원의 입력 볼륨을 미분 가능한 함수를 통해 3차원 출력 볼륨으로 변환시킨다.</p>
</li>
<li>
<p>parameter가 있는 레이어도 있고 그렇지 않은 레이어도 있다 (FC/CONV는 parameter를 갖고 있고, RELU/POOL 등은 parameter가 없음).</p>
</li>
<li>
<p>hyperparameter가 있는 레이어도 있고 그렇지 않은 레이어도 있다 (CONV/FC/POOL 레이어는 hyperparameter를 가지며 ReLU는 가지지 않음).</p>
</li>
<li>
<p>stride, zero-padding ...</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="Spatial-Localization-and-Detection">
<a class="anchor" href="#Spatial-Localization-and-Detection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Spatial Localization and Detection<a class="anchor-link" href="#Spatial-Localization-and-Detection"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/TIL-Blog/images/copied_from_nb/img/cs231/detect.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Classification : 사진에 대한 라벨이 아웃풋</li>
<li>Localization : 사진에 대한 상자가 아웃풋 (x, y, w, h)</li>
<li>Detection : 사진에 대한 여러개의 상자가 아웃풋 DOG(x, y, w, h), CAT(x, y, w, h), ...</li>
<li>Segmentation : 상자가 아니라 객체의 이미지 형상을 그대로.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>Localization method : localization as Regression, Sliding Window : Overfeat</p>
</li>
<li>
<p>Region Proposals : 비슷한 색깔, 텍스쳐를 기준으로 박스를 생성</p>
</li>
<li>
<p>Detection :</p>
<ul>
<li>R-CNN : Region-based CNN. Region -&gt; CNN<ul>
<li>문제점 : Region proposal 마다 CNN을 돌려서 시간이 매우 많이든다.</li>
</ul>
</li>
<li>Fast R-CNN : CNN -&gt; Region<ul>
<li>문제점 : Region Proposal 과정에서 시간이 든다.</li>
</ul>
</li>
<li>
<p>Faster R-CNN : Region Proposals도 CNN을 이용해서 해보자.</p>
</li>
<li>
<p>YOLO(You Only Look Once) : Detection as Regression</p>
<ul>
<li>성능은 Faster R-CNN보다 떨어지지만, 속도가 매우 빠르다.</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="CNNs-in-practice">
<a class="anchor" href="#CNNs-in-practice" aria-hidden="true"><span class="octicon octicon-link"></span></a>CNNs in practice<a class="anchor-link" href="#CNNs-in-practice"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>Data Augmentation</p>
<ul>
<li>Change the pixels without changing the label</li>
<li>Train on transformed data</li>
<li>
<p>VERY widely used</p>
<p>.....</p>
</li>
</ul>
<ol>
<li>Horizontal flips</li>
<li>Random crops/scales</li>
<li>Color jitter</li>
</ol>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>Transfer learning</p>
<p>이미지넷의 클래스와 관련있는 데이터라면 사전학습시 성능이 좋아지는게 이해가되는데 관련없는 이미지 (e.g. mri같은 의료이미지)의 경우도 성능이 좋아지는데 그 이유는 무엇인가?</p>
<p>-&gt; 앞단에선 엣지, 컬러같은 low level의 feature를 인식, 뒤로갈수록 상위레벨을 인식. lowlevel을 미리 학습해놓는다는 것은 그 어떤 이미지를 분석할 때도 도움이된다!</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>How to stack convolutions:</p>
<ul>
<li>Replace large convolutions (5x5, 7x7) with stacks of 3x3 convolutions</li>
<li>1x1 "bottleneck" convolutions are very efficient</li>
<li>Can factor NxN convolutions into 1xN and Nx1</li>
<li>
<p>All of the above give fewer parameters, less compute, more nonlinearity</p>
<p>더 적은 파라미터, 더 적은 컴퓨팅연산, 더 많은 nonlinearity(필터 사이사이 ReLU등이 들어가기에)</p>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Computing Convolutions:<ul>
<li>im2col : Easy to implement, but big memory overhead.</li>
<li>FFT : Big speedups for small kernels</li>
<li>"Fast Algorithms" : seem promising, not widely used yet</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="Segmentaion">
<a class="anchor" href="#Segmentaion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Segmentaion<a class="anchor-link" href="#Segmentaion"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Semantic Segmentation<ul>
<li>Classify all pixels</li>
<li>Fully convolutional models, downsample then upsample</li>
<li>Learnable upsampling: fractionally strided convolution</li>
<li>Skip connections can help</li>
</ul>
</li>
</ul>
<p>...</p>
<ul>
<li>Instance Segmentation<ul>
<li>Detect instance, generate mask</li>
<li>Similar pipelines to object detection</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="star77sa/TIL-Blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/TIL-Blog/cnn/2022/01/03/cs231n.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/TIL-Blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/TIL-Blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/TIL-Blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>TIL-Blog</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/star77sa" target="_blank" title="star77sa"><svg class="svg-icon grey"><use xlink:href="/TIL-Blog/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
